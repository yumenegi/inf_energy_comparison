2025-04-28 00:45:59,219 - Log file for this run: /home/lutet/78k/ai8x-training/logs/2025.04.28-004559/2025.04.28-004559.log
2025-04-28 00:45:59,219 - The open file limit is 1024. Please raise the limit (see documentation).
2025-04-28 00:45:59,219 - Configuring device: MAX78000, simulate=False.
2025-04-28 00:45:59,220 - No CUDA, ROCm, or MPS hardware acceleration, training will be slow
2025-04-28 00:45:59,220 - Creating model with num_classes=20, dimensions=(80, 80), bias=True
2025-04-28 00:45:59,238 - Optimizer Type: <class 'torch.optim.adam.Adam'>
2025-04-28 00:45:59,238 - Optimizer Args: {'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0.0, 'amsgrad': False, 'maximize': False, 'foreach': None, 'capturable': False, 'differentiable': False, 'fused': None}
2025-04-28 00:45:59,238 - Initializing FunnyImageNetOriginal with root: data/FunnyImageNet
2025-04-28 00:46:00,625 - Splitting data with split=0.2
2025-04-28 00:46:01,248 - Loaded train split. Samples: 8939
2025-04-28 00:46:01,252 - Initializing FunnyImageNetOriginal with root: data/FunnyImageNet
2025-04-28 00:46:02,667 - Splitting data with split=0.2
2025-04-28 00:46:03,291 - Loaded test split. Samples: 2245
2025-04-28 00:46:03,317 - Reading compression schedule from: policies/schedule-cifar-nas.yaml
2025-04-28 00:46:03,319 - torch.compile() not available, using "eager" mode
2025-04-28 00:46:03,319 - Dataset sizes:
	training=8939
	validation=2245
	test=2245
2025-04-28 00:46:03,319 - 

2025-04-28 00:46:03,320 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:46:25,766 - Epoch: [0][   90/   90]    Overall Loss 2.277790    Objective Loss 2.277790    Top1 41.007194    Top5 82.733813    LR 0.001000    Time 0.249362    
2025-04-28 00:46:25,781 - --- validate (epoch=0)-----------
2025-04-28 00:46:25,782 - 2245 samples (100 per mini-batch)
2025-04-28 00:46:27,995 - Epoch: [0][   23/   23]    Loss 2.132616    Top1 34.476615    Top5 71.536748    
2025-04-28 00:46:28,012 - ==> Top1: 34.477    Top5: 71.537    Loss: 2.133

2025-04-28 00:46:28,013 - ==> Confusion:
[[  4   0   1  45   6   0  17   0  15   2   0   0   0   2   0   2   0   0   0   8]
 [  0   0   1  19  14   0   3  11   4  14   1  12   0  12   0  21   1   1   3   3]
 [  0   0  17   3  10   0  16   0  47   1   0   1   1   2   0   0   0   0   0   5]
 [  0   0   0  62  13   0   6  10  14   2   0   8   0  11   0  21   0   0   1   1]
 [  0   0   1  12 128   0   2   2   1   4   0   3   1   7   0  26   0   3   3   5]
 [  0   0   0  17  17   0   3   0   6   3   0   5   0   5   1   8   2   3   5  13]
 [  0   0   1   7   4   0  49   0  60   0   1   0   0   0   1   0   1   0   0   4]
 [  0   0   0   6   5   0   2  34   1  12   0  10   0   8   0  23   0   0   1   0]
 [  0   0   0   0   0   0   4   0 211   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0   7   9   0   0   2   2  22   0   5   0  20   0  13   0   2   3   1]
 [  0   0   1   8  21   0  15   0  12   3  14   3   0   5   0  13   3  10   1   5]
 [  0   0   0   6   5   0   0   3   0   2   0  16   0  10   0  34   0   3   1   1]
 [  0   0   4   5  44   0   0   0   1   1   0   0  11   0   2   0   1   3   2   9]
 [  0   0   0   7  10   0   0   5   2   3   0   6   0  66   0  13   0   1   2   0]
 [  0   0   2   5  23   0   5   0   3   0   0   1   6   0   3   1   0   2   1   7]
 [  0   0   0   4   2   0   0   2   3   3   0   1   0   2   0  81   0   0   0   0]
 [  0   0   0   3  14   0   1   1   2   2   0   7   0   7   0  14   3   5   1   3]
 [  0   0   0  13  11   0   4   2   7   6   5   7   0   7   0  15   0  15   2   3]
 [  0   1   1  13  21   0   3   3   8   8   3   1   0   8   0  11   0   3  12   8]
 [  0   0   0  24  14   0   8   0  43   2   1   1   0   3   0   6   1   7   3  26]]

2025-04-28 00:46:28,016 - ==> Best [Top1: 34.477   Top5: 71.537   Params: 306880 on epoch: 0]
2025-04-28 00:46:28,016 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:46:28,025 - 

2025-04-28 00:46:28,025 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:46:50,306 - Epoch: [1][   90/   90]    Overall Loss 1.825220    Objective Loss 1.825220    Top1 44.604317    Top5 81.294964    LR 0.001000    Time 0.247535    
2025-04-28 00:46:50,337 - --- validate (epoch=1)-----------
2025-04-28 00:46:50,338 - 2245 samples (100 per mini-batch)
2025-04-28 00:46:52,613 - Epoch: [1][   23/   23]    Loss 2.017299    Top1 39.643653    Top5 77.861915    
2025-04-28 00:46:52,635 - ==> Top1: 39.644    Top5: 77.862    Loss: 2.017

2025-04-28 00:46:52,635 - ==> Confusion:
[[  4   7   1   0  57   0   1   1   0   1   1   0   0   0   0   3  11   9   3   3]
 [  1  42   0   1  32   0   0   3   1   8   3   7   0   1   0  10   7   2   1   1]
 [  1   0  32   1  31   0  15   0   5   0   6   0   4   0   2   0   2   0   1   3]
 [  0  28   0  23  29   0   1  24   0   3   1   7   0   4   0  16   5   4   0   4]
 [  0   1   0   0 178   0   0   1   0   0   1   1   0   0   1  10   5   0   0   0]
 [  0   8   0   2  41   1   0   0   1   1   2   2   0   0   0   5  20   1   3   1]
 [  1   1   6   2  27   0  58   1   3   0   5   0   0   0   2   0   7   2   3  10]
 [  0  17   0   0  20   0   0  45   0   7   0   0   0   0   0  12   0   1   0   0]
 [  4   0  11   0   2   1  13   0 156   0   2   0   0   0   1   0   3   3   1  19]
 [  0   6   0   2  14   0   0   2   0  28   3   0   0  12   0   9   4   3   2   1]
 [  0   5   3   0  11   0   1   0   1   2  38   1   2   4   1   9  24   6   3   3]
 [  0  15   0   1   3   0   0   3   0   1   0  26   0   4   0  10  16   2   0   0]
 [  0   0   0   0  50   0   0   0   0   0   0   1  27   0   0   1   2   1   0   1]
 [  0   7   1   2   7   0   0   2   0   9   2   6   0  55   0  18   5   0   0   1]
 [  0   2   0   0  45   0   0   1   0   0   1   0   8   0   0   1   1   0   0   0]
 [  0   2   0   1  17   0   0   2   0   0   0   1   0   0   0  71   1   0   1   2]
 [  0   3   0   0   9   0   0   1   0   1   1   4   1   3   0   7  29   3   0   1]
 [  0   4   1   0  13   0   0   0   0   0   5   1   0   0   0   5  23  39   5   1]
 [  0   5   0   0  29   0   0   0   1   6   1   0   0   3   0  12  19  11  12   5]
 [  1   5   0   2  32   1   5   1   3   0   3   2   0   0   1   6  40   5   6  26]]

2025-04-28 00:46:52,637 - ==> Best [Top1: 39.644   Top5: 77.862   Params: 306880 on epoch: 1]
2025-04-28 00:46:52,637 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:46:52,648 - 

2025-04-28 00:46:52,648 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:47:15,210 - Epoch: [2][   90/   90]    Overall Loss 1.599252    Objective Loss 1.599252    Top1 53.237410    Top5 89.928058    LR 0.001000    Time 0.250661    
2025-04-28 00:47:15,234 - --- validate (epoch=2)-----------
2025-04-28 00:47:15,234 - 2245 samples (100 per mini-batch)
2025-04-28 00:47:17,597 - Epoch: [2][   23/   23]    Loss 1.528528    Top1 52.204900    Top5 86.414254    
2025-04-28 00:47:17,621 - ==> Top1: 52.205    Top5: 86.414    Loss: 1.529

2025-04-28 00:47:17,622 - ==> Confusion:
[[ 52   4   3   1   5   2   9   1   2   0   1   0   0   1   2   0   0   2   3  14]
 [  0  39   1   0   9   5   8   6   1  12   4  22   0   4   1   0   1   1   3   3]
 [  1   2  53   0   6   0  28   0   6   1   0   0   3   0   0   0   0   0   1   2]
 [  2  11   0  45   9   8  10   9   2   2   0  12   0  24   0   0   1   2   3   9]
 [  0   4   1   0 167   1   4   0   0   0   1   5  13   0   1   0   0   0   0   1]
 [  1   4   0   1  22  12   8   1   0   1   0   3   1   1   1   0   1   3   2  26]
 [  2   0   5   0   3   1 103   0   5   1   1   0   0   0   1   0   0   0   0   6]
 [  1   8   0   0   8   2   0  42   0   7   1  23   1   4   0   2   0   1   0   2]
 [  0   0   5   0   0   0  11   0 195   1   0   0   0   0   0   0   0   1   0   3]
 [  1   3   0   1   3   2   0   0   1  38   2   6   0  21   1   0   0   2   3   2]
 [  3   2   4   0   2   3  10   0   6  12  42   5   5   8   1   0   1   2   3   5]
 [  0   3   0   0   0   3   0   1   0   0   0  59   0   9   0   1   2   1   1   1]
 [  1   0   2   0  12   2   1   0   0   0   0   0  51   0   6   0   0   0   1   7]
 [  1   4   1   2   2   0   2   2   0   7   1  13   0  79   0   0   0   1   0   0]
 [  0   0   0   0  11   0   3   0   0   0   1   1  15   0  24   0   0   0   0   4]
 [  0   4   0   2  28   6   0   5   1   1   0  11   1   4   0  32   0   0   0   3]
 [  0   5   0   0  14   3   1   0   0   1   2  11   1  10   0   1   5   5   1   3]
 [  2   4   1   1   7   2   2   0   0   7   7   4   0   2   1   0   1  47   2   7]
 [  7   2   2   0  13   3   3   2   2  13   1   4   4   4   2   1   0   5  26  10]
 [  2   0   8   0  15   6  34   0   4   3   3   1   0   0   0   0   0   0   2  61]]

2025-04-28 00:47:17,624 - ==> Best [Top1: 52.205   Top5: 86.414   Params: 306880 on epoch: 2]
2025-04-28 00:47:17,624 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:47:17,635 - 

2025-04-28 00:47:17,635 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:47:40,964 - Epoch: [3][   90/   90]    Overall Loss 1.445681    Objective Loss 1.445681    Top1 53.237410    Top5 88.489209    LR 0.001000    Time 0.259189    
2025-04-28 00:47:40,997 - --- validate (epoch=3)-----------
2025-04-28 00:47:40,997 - 2245 samples (100 per mini-batch)
2025-04-28 00:47:43,378 - Epoch: [3][   23/   23]    Loss 1.362784    Top1 58.173719    Top5 89.265033    
2025-04-28 00:47:43,400 - ==> Top1: 58.174    Top5: 89.265    Loss: 1.363

2025-04-28 00:47:43,401 - ==> Confusion:
[[ 67   0   2   1   5   3   2   0   0   0   4   0   0   0   1   0   0   6   4   7]
 [  1  37   1  15   9   1   2   2   1   8  13   8   2   2   0   3   2   5   4   4]
 [  2   1  65   1   8   0   9   0   3   1   3   0   5   0   0   0   1   2   0   2]
 [  6   0   1 113   6   1   4   0   1   3   1   2   1   2   0   1   0   2   3   2]
 [  0   1   2   0 177   2   0   0   0   1   3   0  11   0   0   0   0   0   1   0]
 [  1   2   0   4  30  10   5   0   1   1   3   0   2   0   0   2   4   3   2  18]
 [  4   0  14   1   2   0  92   0   3   0   2   0   2   0   0   0   0   0   0   8]
 [  1   1   0  13   8   0   0  59   0   7   3   1   0   2   0   6   0   0   1   0]
 [  5   0  19   1   0   1  12   0 166   0   1   0   0   0   0   0   0   3   1   7]
 [  1   1   0   6   1   2   0   0   1  49   8   1   0   6   0   4   1   1   3   1]
 [  1   1   1   6   5   1   6   0   1   2  62   1   2   2   0   2   5   7   6   3]
 [  0   2   0  13   4   0   0   0   0   2   0  27   0   4   0  10  14   4   0   1]
 [  1   0   1   0   8   0   0   0   0   0   2   0  64   0   1   0   1   0   1   4]
 [  1   0   1  13   7   0   1   0   0   7   3   2   0  67   0   5   3   3   2   0]
 [  4   1   1   0  10   0   2   0   0   0   0   0  35   0   4   0   0   0   1   1]
 [  0   0   0   9  11   0   0   2   0   0   0   0   0   0   0  73   0   0   2   1]
 [  0   0   0   5  19   0   0   0   0   0   5   1   0   2   0   5  18   7   1   0]
 [  2   1   1   2   4   2   0   0   1   2   5   0   1   0   0   2   9  57   3   5]
 [  6   0   1   0  12   1   2   1   1   4  11   0   4   1   2   3   2   9  39   5]
 [  6   3  10   5  13   7  15   0   3   1   2   1   2   0   0   1   1   2   7  60]]

2025-04-28 00:47:43,403 - ==> Best [Top1: 58.174   Top5: 89.265   Params: 306880 on epoch: 3]
2025-04-28 00:47:43,403 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:47:43,414 - 

2025-04-28 00:47:43,414 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:48:07,183 - Epoch: [4][   90/   90]    Overall Loss 1.332022    Objective Loss 1.332022    Top1 60.431655    Top5 89.928058    LR 0.001000    Time 0.264071    
2025-04-28 00:48:07,209 - --- validate (epoch=4)-----------
2025-04-28 00:48:07,209 - 2245 samples (100 per mini-batch)
2025-04-28 00:48:09,719 - Epoch: [4][   23/   23]    Loss 1.518017    Top1 53.051225    Top5 86.146993    
2025-04-28 00:48:09,743 - ==> Top1: 53.051    Top5: 86.147    Loss: 1.518

2025-04-28 00:48:09,744 - ==> Confusion:
[[ 38   3   1  18   2   1   0   0   1   0   0   0   0   0   0   1  17   6   0  14]
 [  0  30   1  11   0   1   0   2   1   2   1  22   0  10   0   5  23   2   1   8]
 [  1   1  33   1   2   4  15   0   9   1  12   0   0   0   0   0   3   1   0  20]
 [  0   1   0  82   0   2   0   2   0   0   0  17   0  12   0   3  21   0   1   8]
 [  0   4   0   0 133   7   0   0   0   0   1   6   1   1   1  33   6   0   1   4]
 [  0   4   0   4   5  19   1   2   1   0   0   4   0   1   0   3  16   4   0  24]
 [  2   0   5  12   0   2  57   0   3   0   1   1   0   0   0   0   3   4   0  38]
 [  0   2   0  13   0   0   0  49   0   3   0  10   0   6   0  12   2   1   0   4]
 [  0   0   3   5   0   0   5   0 192   1   1   0   0   0   0   0   1   0   0   8]
 [  0   2   0   7   0   0   0   0   0  38   2   1   0  24   0   0  10   0   0   2]
 [  1   1   0   4   0   0   1   1   4   6  47   3   0   4   0   2  27   3   2   8]
 [  0   0   0   4   0   0   0   0   0   0   1  50   0   3   0   1  18   1   0   3]
 [  0   2   0   0   8   1   0   0   0   0   7   0  47   0   3   2   5   1   0   7]
 [  0   0   0   5   1   0   0   1   0   1   1   9   0  79   0   1  14   1   0   2]
 [  3   4   0   1   5   2   0   2   0   0   3   0   8   0  15   4   4   0   0   8]
 [  0   0   0   4   2   1   0   1   1   0   0   4   0   1   0  79   4   0   0   1]
 [  0   3   0   1   3   0   0   0   0   0   1   7   0   1   0   5  40   2   0   0]
 [  0   1   0   1   0   0   0   0   1   2   1   4   0   0   0   1  21  57   3   5]
 [  1   3   1   7   4   4   0   2   1   5   2   3   0   7   0   2  26  14  12  10]
 [  0   1   1   6   2   3   1   0   6   0   2   3   0   0   0   1  16   3   0  94]]

2025-04-28 00:48:09,746 - ==> Best [Top1: 58.174   Top5: 89.265   Params: 306880 on epoch: 3]
2025-04-28 00:48:09,746 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:48:09,753 - 

2025-04-28 00:48:09,753 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:48:32,839 - Epoch: [5][   90/   90]    Overall Loss 1.240448    Objective Loss 1.240448    Top1 70.503597    Top5 95.683453    LR 0.001000    Time 0.256483    
2025-04-28 00:48:32,864 - --- validate (epoch=5)-----------
2025-04-28 00:48:32,864 - 2245 samples (100 per mini-batch)
2025-04-28 00:48:35,337 - Epoch: [5][   23/   23]    Loss 1.353954    Top1 57.951002    Top5 89.888641    
2025-04-28 00:48:35,361 - ==> Top1: 57.951    Top5: 89.889    Loss: 1.354

2025-04-28 00:48:35,362 - ==> Confusion:
[[ 66   7   1   0   1   1   0   5   0   1   1   0   2   1   2   1   0   3   1   9]
 [  1  65   0   0   1   3   0   6   1  10   2  10   0   2   1  14   0   1   1   2]
 [  0   3  55   0   2   1   1   1  10   0   2   0   5   0   2   3   0   0   0  18]
 [  4   9   0  80   0   5   0  13   0   3   1   7   1  10   0  10   0   0   1   5]
 [  0   9   0   0 132   2   0   1   0   0   0   4  13   0   5  31   0   0   0   1]
 [  4   5   0   1   5  21   0   1   0   2   1   2   4   1   1   7   0   2   1  30]
 [  2   9  32   2   1   0  20   0   2   3   2   0   2   0   8   2   0   1   0  42]
 [  2   3   0   0   0   0   0  76   0   1   0   0   1   2   0  14   0   1   2   0]
 [  4   1   6   0   0   0   4   0 183   1   1   0   0   0   1   1   0   0   3  11]
 [  2   5   1   0   0   0   0   2   1  59   1   2   2   4   0   3   0   1   2   1]
 [  3   8   7   0   2   1   0   1   1   7  44   3   7   6   0  12   1   1   4   6]
 [  1   5   0   4   0   1   0   0   0   3   0  54   0   6   0   5   2   0   0   0]
 [  1   1   0   0   3   1   0   1   0   1   0   0  69   0   0   0   0   1   0   5]
 [  0   2   0   4   1   1   0   4   0   8   0   3   0  77   1   8   1   1   2   2]
 [  1   1   1   0   8   0   0   1   0   0   0   0  26   0  17   0   1   0   0   3]
 [  0   1   0   1   0   0   0   0   0   1   0   1   0   0   0  91   0   0   1   2]
 [  0  10   0   0   1   2   0   2   0   0   1   7   0   8   0   9  16   4   2   1]
 [  1   4   0   0   2   2   0   3   1   2   3   4   0   0   1   5   4  52   7   6]
 [  9   5   1   0   0   3   0   5   1   2   0   1   6   1   4  12   3   5  35  11]
 [  9  11   4   2   4  11   0   0   2   2   1   0   2   0   0   1   0   0   1  89]]

2025-04-28 00:48:35,364 - ==> Best [Top1: 58.174   Top5: 89.265   Params: 306880 on epoch: 3]
2025-04-28 00:48:35,364 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:48:35,374 - 

2025-04-28 00:48:35,374 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:48:58,677 - Epoch: [6][   90/   90]    Overall Loss 1.161533    Objective Loss 1.161533    Top1 64.028777    Top5 93.525180    LR 0.001000    Time 0.258897    
2025-04-28 00:48:58,702 - --- validate (epoch=6)-----------
2025-04-28 00:48:58,702 - 2245 samples (100 per mini-batch)
2025-04-28 00:49:01,085 - Epoch: [6][   23/   23]    Loss 1.253759    Top1 61.113586    Top5 90.556793    
2025-04-28 00:49:01,109 - ==> Top1: 61.114    Top5: 90.557    Loss: 1.254

2025-04-28 00:49:01,110 - ==> Confusion:
[[ 75   1   0   0   1   0   7   7   0   0   1   0   0   1   0   0   0   1   0   8]
 [  6  55   1   0   0   0   2  22   1   1   1   5   0   5   0   1   2   1   8   9]
 [  2   1  25   0   0   0  56   1   4   0   4   0   0   0   0   0   0   0   0  10]
 [  3   4   0  92   0   1   5  17   1   0   1   3   0  13   0   0   0   0   5   4]
 [  2   3   3   0 129   8   7  10   0   0   2   1   9   2   3   2   0   1   6  10]
 [  6   6   1   2   4  12   4   3   1   1   1   0   2   3   1   0   2   2   2  35]
 [  4   3   0   0   1   0 111   0   1   0   2   0   0   0   0   0   0   0   0   6]
 [  1   0   2   2   0   0   0  90   1   0   1   0   0   3   0   1   0   0   1   0]
 [  2   0   0   0   0   0  18   1 187   0   2   3   0   0   0   0   0   0   1   2]
 [  3   6   0   1   0   0   0  11   1  33   3   2   1  19   0   0   0   0   5   1]
 [  2   2   2   1   0   1   6   2   1   1  77   2   1   3   0   1   2   0   8   2]
 [  1   5   0   2   0   0   0   4   0   0   1  55   0   8   0   1   1   1   0   2]
 [  6   1   3   0   3   0   2   1   0   0   0   0  55   0   3   0   1   0   1   7]
 [  2   1   0   8   1   0   1   4   0   1   3   3   0  85   0   0   1   2   3   0]
 [  7   0   2   0   0   0  11   1   0   0   0   0  11   0  22   0   0   0   1   4]
 [  0   2   0   4   2   0   0  16   1   0   0   1   1   1   0  64   0   0   4   2]
 [  0   3   1   0   2   0   0   2   0   0  13   8   0   6   0   2  12   6   5   3]
 [  5   2   0   0   0   0   2   3   1   0  12   0   1   0   0   1   2  51  11   6]
 [  6   0   3   4   4   1   2   6   2   0   8   2   0   2   0   1   1   4  53   5]
 [ 13   4   1   4   1   1  16   0   2   0   2   0   0   0   0   2   3   0   1  89]]

2025-04-28 00:49:01,111 - ==> Best [Top1: 61.114   Top5: 90.557   Params: 306880 on epoch: 6]
2025-04-28 00:49:01,112 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:49:01,122 - 

2025-04-28 00:49:01,122 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:49:25,208 - Epoch: [7][   90/   90]    Overall Loss 1.085261    Objective Loss 1.085261    Top1 64.028777    Top5 90.647482    LR 0.001000    Time 0.267594    
2025-04-28 00:49:25,235 - --- validate (epoch=7)-----------
2025-04-28 00:49:25,236 - 2245 samples (100 per mini-batch)
2025-04-28 00:49:27,747 - Epoch: [7][   23/   23]    Loss 1.117573    Top1 65.167038    Top5 92.071269    
2025-04-28 00:49:27,769 - ==> Top1: 65.167    Top5: 92.071    Loss: 1.118

2025-04-28 00:49:27,769 - ==> Confusion:
[[ 66   5   1   3   2   1   2   0   0   0   1   0   0   1   2   0   0   3   0  15]
 [  0  70   3   2   0   1   5   1   0   2   3  23   0   0   0   2   7   1   0   0]
 [  0   2  69   0   2   0  14   0   2   0   1   0   0   0   5   1   0   1   0   6]
 [  2   2   0 108   0   4   3   0   0   1   1  11   1   8   0   0   3   1   0   4]
 [  0   8   3   0 148   9   0   0   0   1   0   6  14   0   3   4   1   0   0   1]
 [  2   9   1   2   3  28   1   0   0   1   0   3   3   1   1   1   7   2   0  23]
 [  1   1   4   1   1   0 101   0   1   0   1   0   0   0   4   0   0   1   0  12]
 [  0   7   1   7   0   3   0  65   0   2   1   9   0   2   0   5   0   0   0   0]
 [  4   0   4   0   0   0  12   0 175   0   4   0   0   0   0   0   0   3   0  14]
 [  1  10   0   6   0   0   0   0   1  45   5   3   0  12   0   0   1   1   0   1]
 [  4   3   5   0   2   0   5   0   1   0  63   6   1   3   0   2  11   4   1   3]
 [  0   1   0   4   0   0   1   0   0   0   0  67   0   1   0   0   7   0   0   0]
 [  1   1   0   0   0   1   0   0   0   0   0   1  72   0   1   0   1   0   0   5]
 [  1   3   0   4   1   0   0   0   0   0   1  18   0  83   0   0   1   1   1   1]
 [  0   2   1   0   2   1   1   0   0   0   0   0  22   0  27   0   0   1   0   2]
 [  0   0   0   3   7   3   0   2   1   0   0   2   0   2   0  72   4   0   1   1]
 [  0   7   0   2   2   2   0   0   0   0   1   6   1   3   0   2  32   5   0   0]
 [  0   7   2   2   0   2   1   1   0   2   5   1   0   0   0   1   5  60   1   7]
 [  7   6   2   2   9   7   0   2   1   1   2   1   5   3   4   2   5  13  19  13]
 [  5   7   3   3   3   7   5   0   1   1   1   2   2   1   0   0   4   1   0  93]]

2025-04-28 00:49:27,771 - ==> Best [Top1: 65.167   Top5: 92.071   Params: 306880 on epoch: 7]
2025-04-28 00:49:27,771 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:49:27,782 - 

2025-04-28 00:49:27,782 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:49:51,761 - Epoch: [8][   90/   90]    Overall Loss 1.044478    Objective Loss 1.044478    Top1 65.467626    Top5 94.964029    LR 0.001000    Time 0.266403    
2025-04-28 00:49:51,785 - --- validate (epoch=8)-----------
2025-04-28 00:49:51,786 - 2245 samples (100 per mini-batch)
2025-04-28 00:49:54,179 - Epoch: [8][   23/   23]    Loss 1.252661    Top1 63.028953    Top5 91.848552    
2025-04-28 00:49:54,197 - ==> Top1: 63.029    Top5: 91.849    Loss: 1.253

2025-04-28 00:49:54,197 - ==> Confusion:
[[ 48   0   0   4   1   0  21   0  20   0   1   0   0   0   1   0   0   0   2   4]
 [  1  53   0   3   0   1  10   1   3  18   7   8   0   2   0   2   1   1   7   2]
 [  1   0  49   1   0   1  36   0   6   1   5   0   0   0   0   0   1   0   0   2]
 [  0   0   1  96   0   0   9   0   9  15   0   1   0  12   0   0   0   0   5   1]
 [  1   1   0   3 148   1   7   0   1   2   3   3   3   1   2  12   1   1   8   0]
 [  2   3   1   4   7  10  16   0   4   5   5   0   2   1   0   2   4   3  10   9]
 [  0   0   1   2   1   0 118   0   2   0   4   0   0   0   0   0   0   0   0   0]
 [  0   1   0   7   0   0   0  75   1   8   1   0   0   1   0   5   0   0   3   0]
 [  0   0   0   0   0   0   7   0 209   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   1   0   0   0   1   1   1  77   0   1   0   0   0   0   0   0   1   2]
 [  0   0   0   1   0   0   8   0   8   8  74   2   0   3   0   0   4   0   4   2]
 [  1   2   0   9   0   0   0   0   1  10   1  49   0   4   0   1   2   1   0   0]
 [  1   1   1   0   2   0   3   0   0   2   4   0  63   0   2   0   0   1   1   2]
 [  0   0   0   5   1   0   2   1   2  21   3   1   0  77   0   1   0   0   1   0]
 [  1   0   4   0   0   0   9   0   1   1   3   0  16   0  21   0   1   0   2   0]
 [  0   1   0  10   0   0   1   2   3   4   1   1   0   0   0  73   0   0   2   0]
 [  0   1   0   1   3   1   2   0   2   8  10   3   0   5   0   3  16   3   5   0]
 [  1   0   1   2   0   0   2   1   3   5   6   0   0   1   0   0   2  58  12   3]
 [  2   0   5   1   1   0   2   0   5   8  11   0   0   1   0   1   2   3  60   2]
 [  1   0   9   4   5   2  46   0  15   1   5   1   0   0   0   1   0   1   7  41]]

2025-04-28 00:49:54,200 - ==> Best [Top1: 65.167   Top5: 92.071   Params: 306880 on epoch: 7]
2025-04-28 00:49:54,200 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:49:54,207 - 

2025-04-28 00:49:54,207 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:50:18,170 - Epoch: [9][   90/   90]    Overall Loss 0.975160    Objective Loss 0.975160    Top1 65.467626    Top5 93.525180    LR 0.001000    Time 0.266217    
2025-04-28 00:50:18,196 - --- validate (epoch=9)-----------
2025-04-28 00:50:18,196 - 2245 samples (100 per mini-batch)
2025-04-28 00:50:20,537 - Epoch: [9][   23/   23]    Loss 1.102714    Top1 66.414254    Top5 91.492205    
2025-04-28 00:50:20,561 - ==> Top1: 66.414    Top5: 91.492    Loss: 1.103

2025-04-28 00:50:20,562 - ==> Confusion:
[[ 82   1   3   0   1   1   1   0   0   0   0   0   0   0   2   0   0   3   1   7]
 [  1  79   5   0   0   2   2   1   1   8   2   0   3   0   0   0   1  10   0   5]
 [  1   0  85   0   3   1   2   0   1   1   1   0   0   0   3   0   0   1   2   2]
 [  8   6   4  61   2  10   2   3   1  11   1   0   1  15   0   3   2   1   5  13]
 [  0   0   2   0 181   2   0   0   0   1   0   0   4   0   7   0   1   0   0   0]
 [  2   6   6   0   8  23   1   4   0   1   1   0   4   0   4   0   0   5   0  23]
 [  4   0  26   1   0   0  82   0   2   0   4   0   0   0   1   0   0   2   1   5]
 [  1   2   0   0   7   0   0  80   0   2   1   0   2   2   0   1   0   3   0   1]
 [  3   0  11   0   0   0   3   0 195   0   0   0   0   0   0   0   0   3   0   1]
 [  1   2   2   0   0   3   0   0   1  60   3   0   1   3   0   0   0   4   3   3]
 [  4   0   5   0   3   3   1   0   1   1  74   0   0   1   1   0   1  12   5   2]
 [  1  20   1   2   2   2   0   1   0   8   0  16   0   4   0   2  12   8   0   2]
 [  2   0   2   0   3   0   0   0   0   0   1   0  65   0   3   0   0   0   0   7]
 [  1   5   1   1   4   0   1   1   1  11   2   0   0  71   0   0   2   6   3   5]
 [  0   0   3   0   4   0   0   0   0   0   0   0   8   0  42   0   0   0   0   2]
 [  0   1   0   1  19   2   0   2   0   1   0   0   1   0   0  67   0   0   3   1]
 [  0   5   0   0   5   4   0   0   0   0   5   1   2   3   1   1  20  13   3   0]
 [  1   2   2   0   0   0   0   1   0   0   3   0   0   0   3   0   1  75   6   3]
 [  5   3   4   0   8   2   1   1   1   0   4   0   0   0   6   0   1  12  45  11]
 [  5   3  19   0   2   0   5   0   2   2   4   0   2   0   1   0   0   3   3  88]]

2025-04-28 00:50:20,564 - ==> Best [Top1: 66.414   Top5: 91.492   Params: 306880 on epoch: 9]
2025-04-28 00:50:20,564 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:50:20,574 - 

2025-04-28 00:50:20,574 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:50:43,818 - Epoch: [10][   90/   90]    Overall Loss 0.949099    Objective Loss 0.949099    Top1 68.345324    Top5 96.402878    LR 0.001000    Time 0.258232    
2025-04-28 00:50:43,845 - --- validate (epoch=10)-----------
2025-04-28 00:50:43,845 - 2245 samples (100 per mini-batch)
2025-04-28 00:50:46,161 - Epoch: [10][   23/   23]    Loss 1.007815    Top1 69.131403    Top5 93.006682    
2025-04-28 00:50:46,181 - ==> Top1: 69.131    Top5: 93.007    Loss: 1.008

2025-04-28 00:50:46,182 - ==> Confusion:
[[ 85   3   1   0   3   0   0   1   2   0   0   0   0   1   0   0   0   3   1   2]
 [  0 100   0   0   0   0   0   3   2   1   0   1   0   4   2   2   0   2   3   0]
 [  1   3  77   0   4   0   4   0   2   1   1   2   2   1   2   0   0   1   2   0]
 [  6   5   1  88   0   1   1   5   1   2   0   6   0  29   0   1   0   0   2   1]
 [  0   6   0   0 168   5   0   2   0   0   0   1   2   1   0  10   0   0   3   0]
 [  3  21   0   1   8  30   1   5   1   1   0   1   2   0   1   1   3   4   1   4]
 [  6   5   8   0   1   0  85   1   7   0   2   0   1   0   4   0   0   1   4   3]
 [  1   3   0   0   0   1   0  84   0   3   0   0   0   4   0   3   0   1   2   0]
 [  0   1   7   0   0   0   0   0 207   0   0   0   0   0   1   0   0   0   0   0]
 [  1   3   1   1   0   0   0   1   0  66   0   2   0   8   0   0   0   1   1   1]
 [  2  15   1   0   0   0   3   1   3  22  35   2   4   7   0   4   5   3   6   1]
 [  1   5   0   3   0   0   0   2   0   0   0  60   0   8   0   1   1   0   0   0]
 [  1   2   0   0   4   2   0   0   0   0   0   0  67   0   3   1   0   2   1   0]
 [  1   4   0   1   1   0   0   0   1   1   0   4   0 101   0   0   1   0   0   0]
 [  2   0   0   0   9   0   0   0   0   1   0   0  16   0  29   1   0   0   1   0]
 [  0   2   0   0   0   0   0   6   2   0   0   2   0   0   0  83   0   0   2   1]
 [  0  14   0   1   2   0   0   0   0   1   0   8   2   7   0   1  22   0   5   0]
 [  1   9   2   1   0   0   0   2   0   4   0   2   0   0   1   0   6  58  10   1]
 [  4   4   1   1   1   3   0   1   3   6   0   3   2   3   3   0   2   6  61   0]
 [  7  14   5   2   8  17   3   1   9   3   0   4   4   0   1   1   5   5   4  46]]

2025-04-28 00:50:46,184 - ==> Best [Top1: 69.131   Top5: 93.007   Params: 306880 on epoch: 10]
2025-04-28 00:50:46,184 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:50:46,195 - 

2025-04-28 00:50:46,195 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:51:10,347 - Epoch: [11][   90/   90]    Overall Loss 0.899798    Objective Loss 0.899798    Top1 63.309353    Top5 92.086331    LR 0.001000    Time 0.268324    
2025-04-28 00:51:10,375 - --- validate (epoch=11)-----------
2025-04-28 00:51:10,375 - 2245 samples (100 per mini-batch)
2025-04-28 00:51:12,932 - Epoch: [11][   23/   23]    Loss 1.010095    Top1 67.928731    Top5 93.763920    
2025-04-28 00:51:12,957 - ==> Top1: 67.929    Top5: 93.764    Loss: 1.010

2025-04-28 00:51:12,957 - ==> Confusion:
[[ 94   0   0   2   0   1   0   2   1   0   0   0   0   0   1   0   0   0   1   0]
 [  3  80   0   2   0   4   0  14   0   2   3   4   2   1   0   0   0   0   4   1]
 [  5   2  27   1   4   2  11   1   8   0  15   0   2   0   5   0   1   0   1  18]
 [  4   2   0 120   0   0   0  11   0   0   1   2   0   6   0   1   0   0   2   0]
 [  2   2   0   2 159   7   0   8   0   0   1   1   5   0   1   5   1   1   2   1]
 [  5   4   0   7   2  34   0   5   0   1   2   0   1   0   0   1   5   2   4  15]
 [ 14   3   1   5   1   1  76   0   3   0   4   0   0   0   2   0   0   1   3  14]
 [  2   0   0   4   0   0   0  91   0   0   1   0   0   0   0   4   0   0   0   0]
 [ 23   0   0   0   0   1   1   0 185   0   5   0   0   0   0   0   0   0   0   1]
 [  0   7   0  10   0   1   0   6   0  51   4   0   0   4   0   0   0   0   2   1]
 [  3   2   0   2   0   1   0   1   1   0  87   1   0   2   0   0   3   2   5   4]
 [  0   4   0   8   0   0   0   2   0   2   0  61   0   2   0   1   1   0   0   0]
 [  2   0   0   0   3   1   0   2   0   1   3   0  63   0   2   0   1   0   2   3]
 [  0   4   0  15   0   0   0   5   0   2   3   2   0  80   0   0   1   0   2   1]
 [  9   0   0   1   1   1   0   0   0   0   0   0  12   0  28   0   0   0   2   5]
 [  2   0   0   3   1   0   0  20   0   0   1   1   0   0   0  68   0   0   2   0]
 [  0   5   0   2   1   3   0   3   0   0   7   4   0   3   0   3  29   1   2   0]
 [  6   4   0   2   0   0   0   3   1   0   8   1   0   0   0   1   4  52  13   2]
 [  7   2   0   5   2   2   0   4   1   3   4   1   1   1   0   1   1   2  64   3]
 [ 21   2   0   6   1  12   1   0   1   0   4   0   2   1   0   0   2   1   9  76]]

2025-04-28 00:51:12,959 - ==> Best [Top1: 69.131   Top5: 93.007   Params: 306880 on epoch: 10]
2025-04-28 00:51:12,959 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:51:12,968 - 

2025-04-28 00:51:12,968 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:51:37,169 - Epoch: [12][   90/   90]    Overall Loss 0.861738    Objective Loss 0.861738    Top1 65.467626    Top5 95.683453    LR 0.001000    Time 0.268874    
2025-04-28 00:51:37,194 - --- validate (epoch=12)-----------
2025-04-28 00:51:37,194 - 2245 samples (100 per mini-batch)
2025-04-28 00:51:39,556 - Epoch: [12][   23/   23]    Loss 0.991928    Top1 69.398664    Top5 93.897550    
2025-04-28 00:51:39,580 - ==> Top1: 69.399    Top5: 93.898    Loss: 0.992

2025-04-28 00:51:39,581 - ==> Confusion:
[[ 92   1   0   0   0   0   1   0   3   0   0   0   0   0   0   0   0   3   0   2]
 [  0  69   0   4   0   1   1   1   1  12   1   4   0  15   0   1   3   2   2   3]
 [  0   1  45   2   0   2  22   0  10   0   6   0   0   2   0   0   1   0   0  12]
 [  2   0   0 114   0   2   1   0   0   7   1   0   0  18   0   0   0   0   3   1]
 [  5   1   0   3 138  12   2   0   0   3   1   1   5   5   2   1   1   0   3  15]
 [  4   2   0   7   0  27   1   2   0   3   1   1   0   2   0   0   3   0   0  35]
 [  2   0   0   1   0   0 108   0   7   1   1   0   0   0   0   0   0   0   0   8]
 [  1   2   0  12   0   1   0  73   0   3   1   0   0   5   0   1   1   0   1   1]
 [  0   0   0   0   0   0   1   0 210   0   1   0   0   1   0   0   0   0   0   3]
 [  0   0   0   2   0   0   0   1   1  70   0   0   0  12   0   0   0   0   0   0]
 [  2   2   0   2   0   1   3   0   1   8  69   1   0   6   0   0   6   4   3   6]
 [  1   2   0  11   0   0   0   0   0   3   0  47   0  15   0   0   1   0   0   1]
 [  2   1   0   0   2   4   0   0   0   4   2   0  61   0   1   0   0   0   0   6]
 [  1   0   0   7   0   0   0   0   0   3   0   1   0 101   0   0   0   1   1   0]
 [  5   0   0   0   0   0   6   0   0   1   1   0  10   0  26   0   0   0   0  10]
 [  0   0   0  21   1   1   0   3   0   2   0   1   0   1   0  64   0   0   3   1]
 [  0   3   0   3   1   1   0   1   0   4   4   2   0   8   0   0  31   2   1   2]
 [  2   3   0   5   0   0   0   1   0   1   2   2   0   1   0   0   8  60   7   5]
 [  5   0   0   2   0   3   2   1   2   9   5   1   1   6   0   0   2   4  50  11]
 [  7   1   1   8   1   5   4   0   2   2   2   1   0   1   0   0   0   0   1 103]]

2025-04-28 00:51:39,583 - ==> Best [Top1: 69.399   Top5: 93.898   Params: 306880 on epoch: 12]
2025-04-28 00:51:39,583 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:51:39,595 - 

2025-04-28 00:51:39,595 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:52:03,978 - Epoch: [13][   90/   90]    Overall Loss 0.811910    Objective Loss 0.811910    Top1 69.784173    Top5 94.244604    LR 0.001000    Time 0.270888    
2025-04-28 00:52:04,009 - --- validate (epoch=13)-----------
2025-04-28 00:52:04,010 - 2245 samples (100 per mini-batch)
2025-04-28 00:52:06,477 - Epoch: [13][   23/   23]    Loss 1.014909    Top1 67.349666    Top5 94.788419    
2025-04-28 00:52:06,504 - ==> Top1: 67.350    Top5: 94.788    Loss: 1.015

2025-04-28 00:52:06,504 - ==> Confusion:
[[ 96   0   0   1   0   0   0   1   1   0   0   0   0   0   1   1   0   0   1   0]
 [  7  84   0   3   0   4   0   5   0   6   0   1   0   0   0   1   3   1   3   2]
 [  9   0  54   0   1   2  13   1   6   0   5   0   0   0   7   0   1   0   3   1]
 [  5   0   1 119   0   0   1   6   0   6   1   0   0   5   0   2   0   0   3   0]
 [  5   2   0   2 152   6   0   7   1   2   0   0   4   0   2   7   1   1   6   0]
 [ 13   5   0   2   2  36   1   4   0   2   1   0   3   0   2   2   2   2   4   7]
 [ 24   1   1   2   0   2  84   0   0   0   3   0   0   0   7   0   0   0   1   3]
 [  1   2   0   4   0   0   0  89   0   1   1   0   0   0   0   3   0   0   1   0]
 [ 23   0   1   2   0   0   8   0 174   0   2   0   0   1   0   0   0   0   2   3]
 [  3   1   0   5   0   0   0   2   0  72   0   1   0   1   0   0   0   0   1   0]
 [  3   2   0   3   1   0   1   2   1   5  83   1   1   1   0   0   4   0   6   0]
 [  2   1   0  17   1   0   0   6   0   8   0  39   0   2   1   1   3   0   0   0]
 [  6   1   0   0   3   0   0   0   0   1   4   0  65   0   2   0   0   0   1   0]
 [  1   2   0  19   1   0   0   7   0  17   1   0   0  66   0   0   0   0   1   0]
 [ 10   0   0   0   2   0   0   0   0   1   0   0  16   0  29   0   0   0   1   0]
 [  0   1   0   3   1   0   0  10   0   0   0   0   0   0   0  81   0   0   2   0]
 [  1  10   0   5   1   1   0   1   0   3   3   3   0   3   0   3  23   0   6   0]
 [  6   2   0   4   1   0   0   1   1   3   2   2   1   0   0   0   4  50  18   2]
 [  9   2   0   2   2   1   0   4   0   9   2   0   2   1   3   1   1   0  64   1]
 [ 35   1   1   5   2  18   3   0   1   4   1   1   4   0   2   0   1   0   8  52]]

2025-04-28 00:52:06,507 - ==> Best [Top1: 69.399   Top5: 93.898   Params: 306880 on epoch: 12]
2025-04-28 00:52:06,507 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:52:06,515 - 

2025-04-28 00:52:06,516 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:52:30,573 - Epoch: [14][   90/   90]    Overall Loss 0.765827    Objective Loss 0.765827    Top1 78.417266    Top5 94.964029    LR 0.001000    Time 0.267280    
2025-04-28 00:52:30,598 - --- validate (epoch=14)-----------
2025-04-28 00:52:30,599 - 2245 samples (100 per mini-batch)
2025-04-28 00:52:33,024 - Epoch: [14][   23/   23]    Loss 1.026456    Top1 69.131403    Top5 94.075724    
2025-04-28 00:52:33,047 - ==> Top1: 69.131    Top5: 94.076    Loss: 1.026

2025-04-28 00:52:33,048 - ==> Confusion:
[[ 84   0   0   0   1   0   2   0   1   0   0   0   0   0   1   0   0   0   0  13]
 [  1  56   0   0   3   3   7   0   0   8   6   5   1   4   1   1   3   2   2  17]
 [  1   0  34   0   1   0  37   0   6   0   6   0   1   0   6   0   0   0   0  11]
 [  5   0   1  82   0   3   8   0   1   7   2   3   0   9   1   0   0   0   4  23]
 [  0   0   0   0 175   0   2   0   1   1   0   0   2   0  14   0   1   0   0   2]
 [  1   0   0   1  10  12   2   0   0   0   1   0   4   0   3   2   1   1   1  49]
 [  1   0   0   0   1   0 112   0   3   0   0   0   0   0   2   0   0   0   0   9]
 [  1   0   0   2   5   1   0  68   1   3   4   1   0   2   2   6   0   0   2   4]
 [  2   0   0   0   0   1   6   0 203   0   4   0   0   0   0   0   0   0   0   0]
 [  1   0   0   0   0   0   0   0   0  70   2   2   0   4   1   0   1   0   0   5]
 [  1   0   0   0   0   0   8   0   2   0  93   0   0   0   0   0   2   0   0   8]
 [  0   1   0   2   1   1   0   0   0   2   6  53   0   1   0   0   2   2   0  10]
 [  1   0   0   0   1   0   3   0   0   0   0   0  70   0   4   0   0   0   0   4]
 [  0   0   0   3   3   2   0   0   1   4   4   1   0  86   0   0   0   1   1   9]
 [  0   0   0   0   1   0   3   0   0   0   0   0   6   0  46   0   0   0   0   3]
 [  0   1   0   2  13   2   3   0   2   0   1   0   2   0   2  66   0   1   1   2]
 [  0   1   0   1   4   0   3   0   1   2  16   2   2   1   1   0  19   4   2   4]
 [  1   1   0   0   2   1   5   0   1   0   9   0   0   0   3   0   3  58   6   7]
 [  5   0   0   1   5   0   7   0   1   4   7   0   1   2   4   0   1   4  51  11]
 [  2   0   0   0   2   2  13   0   1   0   1   0   1   0   2   0   0   0   1 114]]

2025-04-28 00:52:33,050 - ==> Best [Top1: 69.399   Top5: 93.898   Params: 306880 on epoch: 12]
2025-04-28 00:52:33,050 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:52:33,058 - 

2025-04-28 00:52:33,058 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:52:57,080 - Epoch: [15][   90/   90]    Overall Loss 0.734499    Objective Loss 0.734499    Top1 76.978417    Top5 94.964029    LR 0.001000    Time 0.266882    
2025-04-28 00:52:57,106 - --- validate (epoch=15)-----------
2025-04-28 00:52:57,106 - 2245 samples (100 per mini-batch)
2025-04-28 00:52:59,516 - Epoch: [15][   23/   23]    Loss 0.804198    Top1 74.565702    Top5 95.501114    
2025-04-28 00:52:59,542 - ==> Top1: 74.566    Top5: 95.501    Loss: 0.804

2025-04-28 00:52:59,542 - ==> Confusion:
[[ 91   0   0   3   0   2   0   0   2   0   0   0   0   0   0   0   0   1   0   3]
 [  1  82   0   2   0   2   0   4   2   2   2   3   0   5   0   0  10   4   0   1]
 [  0   1  65   4   1   1   4   0  16   0   2   0   0   2   0   0   1   0   0   6]
 [  1   0   0 129   0   1   0   1   0   2   1   0   0  13   0   0   0   0   1   0]
 [  1   1   0   2 167   4   0   1   0   0   1   3   4   1   1   2   2   0   0   8]
 [  1   4   0   8   1  32   0   1   0   0   1   0   0   1   1   0   4   2   0  32]
 [  6   1   3   9   0   0  75   0  12   1   4   0   0   0   0   1   0   2   1  13]
 [  0   0   0   8   0   2   0  80   0   3   1   0   0   4   0   2   0   0   1   1]
 [  0   0   1   0   0   0   0   0 214   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   4   0   1   0   0   0  68   0   3   0   7   0   0   1   1   0   0]
 [  2   1   0   2   0   0   1   1   6   0  78   0   0   4   0   0   7   3   4   5]
 [  0   1   0   8   0   0   0   0   0   1   0  54   0  11   0   0   3   2   0   1]
 [  1   1   0   0   3   1   0   0   0   0   3   0  67   0   0   0   1   0   0   6]
 [  1   0   0   8   0   0   0   0   0   2   0   2   0  99   0   0   1   1   0   1]
 [  2   0   1   0   4   1   0   0   0   0   0   0   9   0  31   0   1   0   0  10]
 [  1   1   0   7   3   3   0   3   1   0   0   2   0   0   0  75   1   0   1   0]
 [  0   0   0   2   0   1   0   0   1   0   3   6   0   3   0   0  42   4   0   1]
 [  2   1   0   3   0   0   0   1   1   0   1   0   0   1   0   0   4  76   4   3]
 [  1   2   0   7   3   2   0   1   1   4   2   0   1   5   2   1   3  10  52   7]
 [  8   2   2  13   0   5   1   0   4   0   3   0   0   0   0   0   0   3   1  97]]

2025-04-28 00:52:59,544 - ==> Best [Top1: 74.566   Top5: 95.501   Params: 306880 on epoch: 15]
2025-04-28 00:52:59,544 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:52:59,555 - 

2025-04-28 00:52:59,555 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:53:23,185 - Epoch: [16][   90/   90]    Overall Loss 0.705118    Objective Loss 0.705118    Top1 77.697842    Top5 97.841727    LR 0.001000    Time 0.262526    
2025-04-28 00:53:23,213 - --- validate (epoch=16)-----------
2025-04-28 00:53:23,214 - 2245 samples (100 per mini-batch)
2025-04-28 00:53:25,574 - Epoch: [16][   23/   23]    Loss 0.866955    Top1 71.937639    Top5 96.258352    
2025-04-28 00:53:25,595 - ==> Top1: 71.938    Top5: 96.258    Loss: 0.867

2025-04-28 00:53:25,595 - ==> Confusion:
[[ 46   0   1   3   2   3   7   0   1   0   0   0   0   0   7   0   0   1   0  31]
 [  0  88   0   0   0   4   1   0   0   2   2   4   0   1   3   1   1   2   2   9]
 [  0   0  83   0   3   0   7   0   0   0   0   0   0   0   3   0   0   0   0   7]
 [  0   1   0 112   0   2   1   0   0   1   1   2   0  11   1   3   1   0   6   7]
 [  0   1   1   0 179   7   1   0   0   0   0   0   2   0   4   0   0   0   0   3]
 [  0   0   0   1   1  36   1   0   0   0   1   0   0   0   1   2   1   2   1  41]
 [  0   0   9   0   1   1  83   0   0   0   1   0   0   0   1   1   0   0   0  31]
 [  0   7   0   5   1   5   0  59   0   4   1   2   0   0   1  11   0   0   4   2]
 [  0   0  41   0   0   1  12   0 139   0   1   0   0   0   0   0   0   0   0  22]
 [  0   0   0   0   0   3   0   1   0  72   0   0   0   4   0   0   3   0   0   3]
 [  0   0   4   0   1   3   1   0   1   3  82   0   0   2   2   0   0   1   5   9]
 [  0   2   0   2   0   3   0   0   0   2   1  60   0   4   0   0   1   1   0   5]
 [  0   0   0   0   0   0   0   0   0   1   0   0  66   0   8   0   0   0   0   8]
 [  0   1   0   3   1   3   0   0   0   3   1   0   0  97   1   1   0   0   2   2]
 [  0   0   0   0   1   1   0   0   0   0   0   0   6   0  48   0   0   0   0   3]
 [  0   2   0   2   2   3   0   1   0   0   0   1   0   0   0  84   0   0   2   1]
 [  0   1   0   1   6   5   0   0   0   2   5   3   2   3   0   0  25   5   1   4]
 [  0   1   0   0   2   1   0   1   0   1   1   0   0   0   2   0   0  75   5   8]
 [  0   0   2   0   1   3   3   0   0   5   2   0   3   2   5   1   1   6  57  13]
 [  0   0   4   1   1   3   2   0   0   0   0   0   1   0   3   0   0   0   0 124]]

2025-04-28 00:53:25,597 - ==> Best [Top1: 74.566   Top5: 95.501   Params: 306880 on epoch: 15]
2025-04-28 00:53:25,597 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:53:25,605 - 

2025-04-28 00:53:25,605 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:53:49,298 - Epoch: [17][   90/   90]    Overall Loss 0.660519    Objective Loss 0.660519    Top1 71.942446    Top5 95.683453    LR 0.001000    Time 0.263222    
2025-04-28 00:53:49,323 - --- validate (epoch=17)-----------
2025-04-28 00:53:49,324 - 2245 samples (100 per mini-batch)
2025-04-28 00:53:51,691 - Epoch: [17][   23/   23]    Loss 0.836983    Top1 73.273942    Top5 95.723831    
2025-04-28 00:53:51,715 - ==> Top1: 73.274    Top5: 95.724    Loss: 0.837

2025-04-28 00:53:51,716 - ==> Confusion:
[[ 82   1   0   1   1   0   0   2   1   0   1   0   0   0   0   0   1   1   9   2]
 [  1  66   1   3   1   1   0   6   1   0   5   7   0   5   0   1   6   2  14   0]
 [  0   1  57   5   3   1   8   1   9   1   5   0   0   0   0   0   2   2   6   2]
 [  0   0   0 101   0   1   0   4   0   0   2   2   0  15   0   6   3   0  15   0]
 [  0   0   0   0 177   0   0   2   0   2   1   0   0   1   0   4   1   1   9   0]
 [  2   1   1   3   8  34   0   4   0   0   5   0   0   0   0   3   4   3  10  10]
 [  0   1   2   9   1   0  79   1   8   0  11   0   0   0   0   1   0   1   5   9]
 [  0   1   0   0   0   0   0  89   0   0   2   0   0   2   0   2   0   0   6   0]
 [  0   0   0   0   0   0   1   0 205   0   3   1   0   0   0   0   0   0   5   1]
 [  0   1   0   3   0   0   0   1   0  62   4   1   0   8   0   0   2   0   3   1]
 [  0   0   0   0   0   0   0   1   0   0  96   0   0   1   0   0   5   1  10   0]
 [  0   0   0   4   0   0   0   2   0   0   1  49   0   6   0   1  11   4   3   0]
 [  1   1   0   0   8   0   0   0   0   1   4   0  57   0   0   2   2   0   6   1]
 [  0   0   0   4   0   0   0   2   0   0   2   0   0 100   0   0   2   0   5   0]
 [  2   0   2   0   7   1   0   0   0   0   0   0  11   0  24   1   1   0   8   2]
 [  0   0   0   1   0   1   0   3   2   0   0   1   0   0   0  84   0   0   6   0]
 [  0   0   0   0   2   1   0   1   0   0   5   2   0   3   0   2  39   4   4   0]
 [  0   0   1   0   0   0   0   0   1   0   1   0   0   0   0   0   5  71  17   1]
 [  1   0   0   1   0   1   0   0   1   2   2   1   0   1   0   0   1   4  86   3]
 [  5   2   2   7   2   5   3   1   1   1   6   1   0   1   0   0   1   3  11  87]]

2025-04-28 00:53:51,718 - ==> Best [Top1: 74.566   Top5: 95.501   Params: 306880 on epoch: 15]
2025-04-28 00:53:51,718 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:53:51,727 - 

2025-04-28 00:53:51,727 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:54:15,262 - Epoch: [18][   90/   90]    Overall Loss 0.656340    Objective Loss 0.656340    Top1 82.733813    Top5 97.841727    LR 0.001000    Time 0.261471    
2025-04-28 00:54:15,288 - --- validate (epoch=18)-----------
2025-04-28 00:54:15,288 - 2245 samples (100 per mini-batch)
2025-04-28 00:54:17,701 - Epoch: [18][   23/   23]    Loss 0.702403    Top1 77.728285    Top5 96.837416    
2025-04-28 00:54:17,723 - ==> Top1: 77.728    Top5: 96.837    Loss: 0.702

2025-04-28 00:54:17,723 - ==> Confusion:
[[ 96   1   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   1   0   2]
 [  1  94   0   1   0   2   0   1   1  10   2   0   0   2   0   0   3   2   0   1]
 [  0   2  75   0   1   0  10   0   5   0   5   0   0   0   0   0   0   0   0   5]
 [  3   1   0 120   0   0   0   0   0   3   1   0   0  16   0   0   3   0   1   1]
 [  4   1   1   2 165   2   0   0   0   2   3   1   4   2   0   0   1   2   3   5]
 [ 10  10   0   3   0  31   1   3   0   0   2   0   0   0   1   0   2   2   3  20]
 [  2   1   2   3   0   0 109   0   3   0   4   0   0   0   0   0   0   1   0   3]
 [  1   1   0   3   0   1   0  84   0   3   1   0   0   6   0   2   0   0   0   0]
 [  1   0   3   0   0   0   0   0 211   0   0   0   0   0   0   0   0   1   0   0]
 [  1   1   0   1   0   0   0   0   0  74   1   0   0   4   0   0   3   0   1   0]
 [  1   2   0   0   0   0   1   0   1   0  95   1   0   0   0   0   4   5   3   1]
 [  2   8   0   9   0   0   0   0   0   1   0  38   0  10   0   0  10   2   0   1]
 [  2   1   1   0   3   0   1   0   0   0   4   0  62   0   3   0   1   1   0   4]
 [  1   1   0   6   0   0   0   0   1   2   0   0   0 102   0   0   1   0   1   0]
 [  2   0   3   0   3   0   2   0   0   1   0   0   9   0  35   0   0   0   1   3]
 [  0   1   0   5   0   2   0   9   2   1   2   0   0   4   0  67   0   2   3   0]
 [  1   2   0   0   2   0   0   0   0   2   3   2   0   1   0   0  43   5   1   1]
 [  3   0   1   0   2   0   0   1   1   0   2   0   0   0   0   0   2  78   5   2]
 [  6   1   3   0   1   1   0   0   1   5   4   1   0   1   0   0   1   7  66   6]
 [ 12   0   1   3   2   2   3   0   6   3   4   0   0   0   0   0   0   3   0 100]]

2025-04-28 00:54:17,725 - ==> Best [Top1: 77.728   Top5: 96.837   Params: 306880 on epoch: 18]
2025-04-28 00:54:17,725 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:54:17,736 - 

2025-04-28 00:54:17,736 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:54:41,035 - Epoch: [19][   90/   90]    Overall Loss 0.636448    Objective Loss 0.636448    Top1 83.453237    Top5 97.841727    LR 0.001000    Time 0.258841    
2025-04-28 00:54:41,065 - --- validate (epoch=19)-----------
2025-04-28 00:54:41,065 - 2245 samples (100 per mini-batch)
2025-04-28 00:54:43,528 - Epoch: [19][   23/   23]    Loss 0.728403    Top1 76.213808    Top5 96.971047    
2025-04-28 00:54:43,551 - ==> Top1: 76.214    Top5: 96.971    Loss: 0.728

2025-04-28 00:54:43,551 - ==> Confusion:
[[ 87   0   0   1   2   0   0   0   3   0   1   1   0   1   1   0   0   2   1   2]
 [  0  63   1   1   1   5   2   0   0   4   8  21   0   5   0   1   6   0   1   1]
 [  0   1  67   2   5   1  17   0   8   0   1   0   0   0   0   0   0   0   1   0]
 [  2   0   0 116   1   0   0   0   0   4   2  12   0   9   0   0   0   0   1   2]
 [  0   0   0   0 194   0   0   0   0   1   0   2   1   0   0   0   0   0   0   0]
 [  0   1   1   1  11  48   1   1   0   1   1   3   2   2   1   2   3   1   2   6]
 [  0   0   2   0   3   1 109   0   4   0   1   1   1   0   2   1   0   0   0   3]
 [  0   2   0   4   1   3   0  75   0   1   1   6   0   6   0   2   0   0   1   0]
 [  2   0   0   1   0   1   1   0 208   0   2   0   0   0   0   0   0   0   0   1]
 [  0   0   0   1   0   1   0   0   1  75   2   2   0   3   0   0   1   0   0   0]
 [  0   0   0   0   0   0   3   0   3   4  94   2   1   1   1   0   1   0   2   2]
 [  1   0   0   0   0   0   0   0   0   0   1  74   0   5   0   0   0   0   0   0]
 [  0   0   1   0   6   0   0   0   0   2   1   0  69   0   2   0   0   0   0   2]
 [  0   0   0   4   1   0   0   0   0   1   0   8   0 100   0   0   1   0   0   0]
 [  0   0   0   0   6   0   1   0   0   1   0   0  17   0  33   0   0   0   0   1]
 [  0   0   0   7  16   2   0   1   1   0   0   7   0   1   0  61   0   1   1   0]
 [  0   0   0   2   4   1   0   0   0   2   6  18   1   3   0   0  25   1   0   0]
 [  0   1   0   3   1   2   0   1   0   2  10   3   0   0   0   0   8  60   4   2]
 [  2   0   1   2   5   5   0   0   0   6   3   2   0   2   2   0   5   3  63   3]
 [  5   0   5   2   4  16   5   0   2   1   6   3   0   0   0   0   0   0   0  90]]

2025-04-28 00:54:43,554 - ==> Best [Top1: 77.728   Top5: 96.837   Params: 306880 on epoch: 18]
2025-04-28 00:54:43,554 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:54:43,562 - 

2025-04-28 00:54:43,562 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:55:07,029 - Epoch: [20][   90/   90]    Overall Loss 0.613086    Objective Loss 0.613086    Top1 75.539568    Top5 96.402878    LR 0.001000    Time 0.260723    
2025-04-28 00:55:07,055 - --- validate (epoch=20)-----------
2025-04-28 00:55:07,055 - 2245 samples (100 per mini-batch)
2025-04-28 00:55:09,236 - Epoch: [20][   23/   23]    Loss 0.669395    Top1 78.440980    Top5 96.926503    
2025-04-28 00:55:09,258 - ==> Top1: 78.441    Top5: 96.927    Loss: 0.669

2025-04-28 00:55:09,259 - ==> Confusion:
[[ 95   0   0   0   0   0   0   1   0   0   1   0   0   0   1   0   0   1   1   2]
 [  3  69   0   4   0   5   0  12   0   0   2  13   0   1   0   2   2   2   4   1]
 [  0   0  74   0   5   0  10   0   5   0   2   0   0   0   2   0   1   0   2   2]
 [  3   0   0 137   0   0   0   2   0   0   1   1   0   3   1   0   0   0   0   1]
 [  2   0   0   1 185   0   0   2   0   0   0   1   0   1   1   2   0   0   1   2]
 [  6   0   1   0   9  42   1   3   0   0   0   1   2   1   0   1   0   0   2  19]
 [  5   0   1   0   1   0 112   0   0   0   1   0   0   0   5   0   0   0   0   3]
 [  1   1   0   5   0   1   0  86   0   1   1   0   0   2   0   3   0   0   1   0]
 [  4   1   1   1   0   0   8   0 195   0   1   0   0   0   0   0   0   0   0   5]
 [  0   0   0   7   0   1   0   3   0  63   0   2   0   7   0   0   1   0   1   1]
 [  4   0   0   4   0   0   4   2   2   0  84   2   0   1   1   0   1   2   6   1]
 [  1   1   0  10   0   2   0   1   0   0   0  63   0   2   0   1   0   0   0   0]
 [  0   0   0   0   3   1   0   1   0   0   0   0  67   0   9   0   0   0   0   2]
 [  1   0   0  15   0   0   0   2   0   0   1   1   0  94   0   0   0   0   0   1]
 [  3   0   0   0   3   0   0   0   0   0   0   0   5   0  48   0   0   0   0   0]
 [  0   1   0   8   4   0   0   5   0   0   0   2   0   0   0  74   0   0   2   2]
 [  0   0   0   3   5   2   0   0   1   0   5  11   0   1   0   4  30   0   1   0]
 [  2   0   0   3   1   0   0   0   0   0   2   2   0   1   2   1   1  69  10   3]
 [  3   0   2   4   1   3   0   1   0   0   1   0   1   3   3   2   1   5  68   6]
 [  8   0   2   5   3   5   5   0   0   0   0   1   0   0   2   0   0   0   2 106]]

2025-04-28 00:55:09,261 - ==> Best [Top1: 78.441   Top5: 96.927   Params: 306880 on epoch: 20]
2025-04-28 00:55:09,261 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:55:09,271 - 

2025-04-28 00:55:09,271 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:55:32,736 - Epoch: [21][   90/   90]    Overall Loss 0.569570    Objective Loss 0.569570    Top1 85.611511    Top5 99.280576    LR 0.001000    Time 0.260690    
2025-04-28 00:55:32,773 - --- validate (epoch=21)-----------
2025-04-28 00:55:32,773 - 2245 samples (100 per mini-batch)
2025-04-28 00:55:35,170 - Epoch: [21][   23/   23]    Loss 0.658492    Top1 79.732739    Top5 96.525612    
2025-04-28 00:55:35,195 - ==> Top1: 79.733    Top5: 96.526    Loss: 0.658

2025-04-28 00:55:35,196 - ==> Confusion:
[[ 97   0   0   0   0   0   0   0   2   0   0   0   0   0   1   0   0   0   0   2]
 [  4  77   1   4   1   2   4   3   3   2   0   1   1   0   2   0   7   0   7   1]
 [  1   0  83   0   2   1   4   0   3   0   2   0   0   0   3   0   0   0   2   2]
 [  3   0   0 131   0   3   2   0   0   1   1   0   0   1   0   0   1   0   3   3]
 [  2   0   0   0 176   3   0   0   0   0   0   0   9   0   5   1   1   0   1   0]
 [  7   2   0   2   6  47   2   2   0   0   0   0   2   0   2   0   1   1   0  14]
 [  3   0   3   0   0   0 115   0   1   0   0   0   0   0   3   0   0   0   1   2]
 [  1   2   1   5   2   0   0  84   0   0   1   1   0   0   0   2   0   0   3   0]
 [  0   0   1   0   0   0   1   0 213   0   0   0   0   0   0   0   0   0   0   1]
 [  3   0   1   6   0   0   1   3   0  67   0   0   0   0   0   0   2   0   2   1]
 [  6   1   1   1   1   0   5   0   4   0  73   0   0   0   0   0   5   2  11   4]
 [  2   2   0  12   1   2   0   0   0   2   1  43   0   3   1   0  10   0   0   2]
 [  2   0   0   0   1   1   0   0   0   0   0   0  70   0   6   0   0   0   0   3]
 [  0   0   0  13   2   1   0   0   1   4   0   1   0  84   0   0   2   1   5   1]
 [  3   0   0   0   1   0   1   0   0   0   0   0   5   0  49   0   0   0   0   0]
 [  0   1   0   5   2   1   0   3   2   0   0   0   2   0   0  79   0   0   3   0]
 [  0   0   0   5   5   1   0   0   0   0   2   1   2   1   0   0  39   1   6   0]
 [  4   0   1   2   0   0   0   0   0   0   0   0   1   0   1   0   2  77   7   2]
 [  3   0   2   2   1   1   1   0   1   1   1   0   1   1   2   0   5   1  76   5]
 [ 12   0   1   1   1   7   2   0   2   0   1   0   0   0   0   0   0   0   2 110]]

2025-04-28 00:55:35,198 - ==> Best [Top1: 79.733   Top5: 96.526   Params: 306880 on epoch: 21]
2025-04-28 00:55:35,198 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:55:35,208 - 

2025-04-28 00:55:35,208 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:55:59,069 - Epoch: [22][   90/   90]    Overall Loss 0.546389    Objective Loss 0.546389    Top1 74.820144    Top5 97.122302    LR 0.001000    Time 0.265089    
2025-04-28 00:55:59,099 - --- validate (epoch=22)-----------
2025-04-28 00:55:59,099 - 2245 samples (100 per mini-batch)
2025-04-28 00:56:01,424 - Epoch: [22][   23/   23]    Loss 0.922117    Top1 72.293987    Top5 95.545657    
2025-04-28 00:56:01,446 - ==> Top1: 72.294    Top5: 95.546    Loss: 0.922

2025-04-28 00:56:01,446 - ==> Confusion:
[[ 73   0   0   0   7   5   0   0   1   0   0   1   0   1   0   0   1   1   2  10]
 [  0  51   0   3   2  12   0   2   0   0   0  27   0   4   0   2  17   0   0   0]
 [  0   0  49   0  11   5   2   0  15   1   0   0   0   0   3   1   2   2   0  12]
 [  0   0   0 131   0   2   0   0   1   0   0   5   0   5   0   0   0   0   3   2]
 [  0   0   0   0 193   3   0   0   0   0   0   0   0   0   0   0   1   0   0   1]
 [  0   1   0   2   8  58   0   1   1   0   0   0   0   1   0   1   5   0   0  10]
 [  0   0   2   3   7  11  53   0  10   0   0   2   1   1   3   1   1   1   0  32]
 [  0   0   0   7   4   1   0  79   0   1   0   3   0   2   0   4   0   0   1   0]
 [  0   0   0   0   0   0   0   0 213   0   0   0   0   0   0   0   0   0   1   2]
 [  0   0   0  10   0   2   0   1   0  65   0   2   0   3   0   0   3   0   0   0]
 [  1   0   1   3   4   3   0   1   1   4  61   2   0   1   0   0  17   1   7   7]
 [  0   0   0   2   0   1   0   0   0   0   0  69   0   5   0   0   4   0   0   0]
 [  0   0   0   0  20   4   0   0   0   0   0   0  54   0   1   0   2   0   0   2]
 [  0   0   0   9   4   0   0   0   0   0   0  10   0  88   0   0   3   0   0   1]
 [  0   0   0   0  29   0   0   0   0   0   0   0   7   0  20   0   0   0   0   3]
 [  0   0   0   3   8   2   0   1   1   0   0   6   0   0   0  73   3   0   1   0]
 [  0   0   0   2   3   2   0   0   0   0   0   6   1   1   0   0  47   0   1   0]
 [  0   0   0   1   6   0   0   1   1   0   1   2   0   0   0   0  12  63   9   1]
 [  0   0   0   2  10   5   0   0   2   0   1   1   1   2   0   1   5   0  71   3]
 [  0   0   1   1   8  12   0   0   2   0   0   0   1   0   0   0   1   0   1 112]]

2025-04-28 00:56:01,448 - ==> Best [Top1: 79.733   Top5: 96.526   Params: 306880 on epoch: 21]
2025-04-28 00:56:01,448 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:56:01,456 - 

2025-04-28 00:56:01,456 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:56:25,186 - Epoch: [23][   90/   90]    Overall Loss 0.521789    Objective Loss 0.521789    Top1 78.417266    Top5 98.561151    LR 0.001000    Time 0.263635    
2025-04-28 00:56:25,214 - --- validate (epoch=23)-----------
2025-04-28 00:56:25,214 - 2245 samples (100 per mini-batch)
2025-04-28 00:56:27,596 - Epoch: [23][   23/   23]    Loss 0.596416    Top1 80.668151    Top5 97.327394    
2025-04-28 00:56:27,618 - ==> Top1: 80.668    Top5: 97.327    Loss: 0.596

2025-04-28 00:56:27,618 - ==> Confusion:
[[ 97   0   0   0   1   0   1   1   0   0   0   0   0   0   0   0   0   0   0   2]
 [  2  74   0   4   2   5   3   3   1   3   2   3   0   6   0   2   2   1   0   7]
 [  0   0  57   1   2   2  27   0   4   0   3   0   0   1   1   0   0   0   1   4]
 [  1   0   0 137   0   0   0   0   0   2   0   1   0   8   0   0   0   0   0   0]
 [  1   0   0   2 185   2   1   2   0   0   0   0   0   0   1   0   1   0   2   1]
 [  3   0   1   3   4  49   2   2   1   1   0   0   0   1   0   1   0   1   2  17]
 [  1   0   0   0   1   0 122   0   1   0   0   0   0   0   0   0   0   0   0   3]
 [  1   0   0   6   1   2   0  88   0   0   1   0   0   1   0   2   0   0   0   0]
 [  0   0   2   0   0   0   5   0 206   0   0   0   0   0   0   0   0   0   1   2]
 [  0   0   0   5   0   0   2   0   0  71   0   0   0   5   0   0   3   0   0   0]
 [  3   1   0   1   0   1   4   0   1   1  91   0   0   4   0   0   0   2   2   3]
 [  2   0   0  11   1   0   0   0   0   0   0  58   0   5   0   0   2   0   0   2]
 [  2   0   1   0   7   1   0   0   0   0   2   0  53   0  14   1   0   0   0   2]
 [  1   0   0  10   0   1   0   0   0   1   1   0   0 100   0   0   1   0   0   0]
 [  3   0   1   0   1   0   6   0   0   0   0   0   1   0  44   0   0   0   1   2]
 [  0   1   0   9   4   1   0   1   1   0   0   0   0   0   0  80   0   0   1   0]
 [  0   0   0   4   3   2   1   0   1   1   3   1   0   4   0   0  41   1   1   0]
 [  4   0   0   2   0   0   1   0   1   0   2   0   0   0   1   0   1  79   3   3]
 [  6   0   0   2   2   1   1   1   1   4   1   1   0   3   2   1   3   2  68   5]
 [  6   0   0   3   2   3   6   0   0   1   3   0   0   0   1   0   0   1   2 111]]

2025-04-28 00:56:27,620 - ==> Best [Top1: 80.668   Top5: 97.327   Params: 306880 on epoch: 23]
2025-04-28 00:56:27,621 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:56:27,631 - 

2025-04-28 00:56:27,631 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:56:51,008 - Epoch: [24][   90/   90]    Overall Loss 0.492827    Objective Loss 0.492827    Top1 79.856115    Top5 97.841727    LR 0.001000    Time 0.259717    
2025-04-28 00:56:51,033 - --- validate (epoch=24)-----------
2025-04-28 00:56:51,033 - 2245 samples (100 per mini-batch)
2025-04-28 00:56:53,470 - Epoch: [24][   23/   23]    Loss 0.729851    Top1 76.659243    Top5 96.258352    
2025-04-28 00:56:53,494 - ==> Top1: 76.659    Top5: 96.258    Loss: 0.730

2025-04-28 00:56:53,495 - ==> Confusion:
[[ 88   0   0   0   1   0   0   0   0   0   1   0   0   0   0   0   0   4   5   3]
 [  1 105   1   0   0   0   2   0   0   2   0   0   0   1   0   1   2   4   1   0]
 [  0   0  89   0   2   0   2   0   4   0   0   0   0   0   0   0   0   3   1   2]
 [  3   7   3  98   1   5   3   0   0   4   4   1   0  11   0   0   2   0   5   2]
 [  0   0   0   0 187   1   0   0   0   1   1   0   0   0   0   0   0   2   6   0]
 [  5   2   2   0  10  41   2   0   0   0   3   0   0   0   0   1   1   4   4  13]
 [  2   1  14   0   1   1  98   0   1   0   3   0   0   0   0   1   0   2   1   3]
 [  1   3   0   1   2   1   0  81   0   1   4   0   0   2   0   0   0   1   5   0]
 [  3   0   4   0   0   1   0   0 201   0   0   0   0   0   0   0   0   1   4   2]
 [  3   1   1   1   0   0   0   1   0  70   2   1   0   1   0   0   3   1   0   1]
 [  2   1   0   0   0   0   0   0   2   0  96   0   0   0   0   0   1   9   3   0]
 [  0   8   0   1   0   1   0   0   0   4   9  30   0  10   0   0  10   6   0   2]
 [  1   0   2   0  12   0   0   0   0   1   1   0  55   0   1   0   0   5   2   3]
 [  1   3   0   1   0   1   0   0   0   4   3   0   0  97   0   0   1   1   2   1]
 [  2   0   7   0  15   1   1   0   0   0   1   0   1   0  23   0   1   1   4   2]
 [  0   2   0   0   3   1   0   2   0   1   0   0   0   3   0  70   4   2  10   0]
 [  0   6   0   0   4   1   0   0   0   1   8   0   1   0   0   0  35   6   1   0]
 [  3   0   0   0   0   0   0   0   1   0   1   0   0   0   0   0   1  86   4   1]
 [  3   2   2   1   1   4   0   0   0   0   1   0   0   0   0   0   1   9  77   3]
 [  9   0   8   0   3   5   5   0   3   1   3   0   0   0   1   0   0   6   1  94]]

2025-04-28 00:56:53,497 - ==> Best [Top1: 80.668   Top5: 97.327   Params: 306880 on epoch: 23]
2025-04-28 00:56:53,497 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:56:53,505 - 

2025-04-28 00:56:53,505 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:57:17,048 - Epoch: [25][   90/   90]    Overall Loss 0.507885    Objective Loss 0.507885    Top1 74.820144    Top5 97.841727    LR 0.001000    Time 0.261567    
2025-04-28 00:57:17,071 - --- validate (epoch=25)-----------
2025-04-28 00:57:17,072 - 2245 samples (100 per mini-batch)
2025-04-28 00:57:19,409 - Epoch: [25][   23/   23]    Loss 0.694143    Top1 77.728285    Top5 97.594655    
2025-04-28 00:57:19,429 - ==> Top1: 77.728    Top5: 97.595    Loss: 0.694

2025-04-28 00:57:19,429 - ==> Confusion:
[[ 75   1   2   2   2   4   2   1   1   0   0   1   0   0   0   0   1   2   1   7]
 [  0  78   1   0   1   3   1  10   0   0   0  20   0   1   0   1   3   0   1   0]
 [  0   2  84   0   4   0   7   0   4   0   1   0   0   0   0   0   0   0   0   1]
 [  0   0   0 109   0   2   2   5   1   0   0  21   0   4   0   1   0   0   2   2]
 [  0   2   0   0 190   1   0   2   0   0   0   1   1   0   0   0   1   0   0   0]
 [  0   2   0   0   3  66   0   3   1   0   1   1   0   0   0   0   2   0   0   9]
 [  0   3   6   0   1   2 104   0   2   0   1   1   0   0   1   0   0   0   1   6]
 [  0   1   0   1   0   2   0  93   0   0   1   2   0   0   0   1   0   1   0   0]
 [  0   0   3   0   0   0   2   0 210   0   0   0   0   0   0   0   0   0   0   1]
 [  0   1   0   5   0   0   0   6   0  69   0   4   0   0   0   0   1   0   0   0]
 [  0   1   0   0   1   1   3   0   3   0  91   8   0   0   0   0   4   1   0   1]
 [  0   1   0   1   0   1   0   0   0   0   0  78   0   0   0   0   0   0   0   0]
 [  0   1   0   0   1   3   0   0   0   0   0   0  73   0   3   0   1   1   0   0]
 [  0   0   0   8   4   0   0   5   0   2   0  43   0  51   0   0   1   1   0   0]
 [  0   0   4   0   4   2   1   1   0   0   0   0   8   0  39   0   0   0   0   0]
 [  0   0   0   2   6   4   0   5   0   0   0   4   0   0   0  76   0   0   0   1]
 [  0   1   0   0   3   1   0   2   0   0   0  10   1   0   0   0  43   0   2   0]
 [  0   2   1   1   1   5   0   1   0   1   2   4   0   0   1   0   8  63   5   2]
 [  0   1   0   0   7   8   1   2   1   2   1   4   1   1   2   1   8   5  59   0]
 [  1   2   4   1   3  21   2   0   4   1   1   2   1   0   1   0   0   0   1  94]]

2025-04-28 00:57:19,431 - ==> Best [Top1: 80.668   Top5: 97.327   Params: 306880 on epoch: 23]
2025-04-28 00:57:19,432 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:57:19,439 - 

2025-04-28 00:57:19,439 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:57:42,965 - Epoch: [26][   90/   90]    Overall Loss 0.472480    Objective Loss 0.472480    Top1 83.453237    Top5 97.841727    LR 0.001000    Time 0.261370    
2025-04-28 00:57:42,998 - --- validate (epoch=26)-----------
2025-04-28 00:57:42,998 - 2245 samples (100 per mini-batch)
2025-04-28 00:57:45,292 - Epoch: [26][   23/   23]    Loss 0.555168    Top1 82.004454    Top5 97.683742    
2025-04-28 00:57:45,314 - ==> Top1: 82.004    Top5: 97.684    Loss: 0.555

2025-04-28 00:57:45,315 - ==> Confusion:
[[ 76   1   1   2   0   2   1   0   4   1   1   0   0   0   4   0   0   1   2   6]
 [  0 105   0   0   0   2   1   1   0   1   1   0   1   0   0   1   3   1   0   3]
 [  0   2  83   1   3   1   2   0   3   0   2   0   0   0   3   0   0   0   0   3]
 [  0   5   1 117   0   1   1   0   0   3   1   2   0   4   0   1   6   0   5   2]
 [  0   1   0   0 182   3   0   0   0   0   0   0   3   0   2   2   3   0   1   1]
 [  1   7   0   0   2  49   0   2   0   0   1   0   3   0   1   1   0   0   0  21]
 [  1   3   4   0   1   0 100   0   2   0   6   0   0   0   4   1   0   0   0   6]
 [  0   7   0   2   0   0   0  86   0   2   2   1   0   0   0   1   0   0   1   0]
 [  0   0   3   0   0   0   1   0 209   0   2   0   0   0   0   0   0   0   1   0]
 [  0   2   0   1   0   0   0   0   0  79   1   0   0   0   0   0   3   0   0   0]
 [  0   0   1   0   0   0   0   0   1   1 105   0   0   0   0   1   3   1   1   0]
 [  0  12   0   2   0   1   0   0   0   1   4  49   0   0   0   0  10   1   0   1]
 [  0   0   0   0   2   1   0   0   0   0   0   0  73   0   4   0   0   0   1   2]
 [  0  12   0   6   0   1   0   0   1   7   2   2   0  82   0   0   2   0   0   0]
 [  0   0   0   0   1   0   0   0   0   1   0   0   7   0  50   0   0   0   0   0]
 [  0   1   0   0   3   2   0   0   1   1   0   0   1   0   0  86   1   0   2   0]
 [  0   4   0   0   0   2   0   0   1   1   1   0   2   0   0   0  51   1   0   0]
 [  0   1   2   0   0   2   0   0   1   1   3   0   0   0   2   0   4  77   2   2]
 [  0   3   1   0   1   5   1   0   2   5   6   0   4   1   4   1   2   3  64   1]
 [  1   1   1   0   2   6   3   0   1   3   3   0   0   0   0   0   0   0   0 118]]

2025-04-28 00:57:45,316 - ==> Best [Top1: 82.004   Top5: 97.684   Params: 306880 on epoch: 26]
2025-04-28 00:57:45,317 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:57:45,328 - 

2025-04-28 00:57:45,328 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:58:08,903 - Epoch: [27][   90/   90]    Overall Loss 0.451092    Objective Loss 0.451092    Top1 79.856115    Top5 97.841727    LR 0.001000    Time 0.261922    
2025-04-28 00:58:08,928 - --- validate (epoch=27)-----------
2025-04-28 00:58:08,929 - 2245 samples (100 per mini-batch)
2025-04-28 00:58:11,304 - Epoch: [27][   23/   23]    Loss 0.545069    Top1 83.474388    Top5 97.772829    
2025-04-28 00:58:11,327 - ==> Top1: 83.474    Top5: 97.773    Loss: 0.545

2025-04-28 00:58:11,327 - ==> Confusion:
[[ 80   0   0   8   0   3   1   2   2   0   0   0   0   0   0   0   0   0   1   5]
 [  0  94   0   1   0   9   1   3   0   0   0   8   0   2   0   1   1   0   0   0]
 [  0   0  84   3   4   2   4   1   1   0   2   0   0   0   0   0   0   0   0   2]
 [  0   0   0 142   0   1   0   0   0   0   1   0   0   3   0   1   0   0   1   0]
 [  0   0   0   0 194   1   0   0   0   0   0   0   1   0   1   0   0   0   0   1]
 [  1   0   0   1   5  62   0   4   0   0   0   0   1   0   0   0   3   0   0  11]
 [  0   0   0   1   1   3 108   0   1   0   1   0   1   0   1   1   0   0   0  10]
 [  0   0   0   2   0   1   0  97   0   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   1   0   0   1   1   0 210   0   0   0   0   0   0   0   0   0   0   3]
 [  0   0   0   7   0   2   0   1   0  73   0   1   0   1   0   0   1   0   0   0]
 [  0   2   0   2   1   3   0   0   0   0  98   1   0   0   0   0   1   1   0   5]
 [  0   1   0  11   0   1   0   0   0   0   0  62   0   4   0   0   1   0   0   1]
 [  0   1   0   0   4   1   0   0   0   1   0   0  70   0   2   0   0   0   0   4]
 [  0   0   0  17   2   1   0   0   0   2   0   0   0  92   0   0   1   0   0   0]
 [  0   0   0   0   3   0   0   0   0   0   0   0   9   0  43   0   0   0   1   3]
 [  0   0   0   4   5   4   0   7   0   0   0   0   0   0   0  77   0   0   1   0]
 [  0   0   0   3   7   4   0   1   0   1   4   6   0   1   0   0  32   1   2   1]
 [  0   0   0   3   3   2   0   2   0   0   2   0   1   1   0   0   2  70   6   5]
 [  1   0   2   3   6   4   0   0   1   2   3   0   1   2   0   1   0   5  71   2]
 [  0   1   0   4   3  12   1   0   0   0   2   0   0   1   0   0   0   0   0 115]]

2025-04-28 00:58:11,329 - ==> Best [Top1: 83.474   Top5: 97.773   Params: 306880 on epoch: 27]
2025-04-28 00:58:11,329 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:58:11,340 - 

2025-04-28 00:58:11,340 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:58:35,272 - Epoch: [28][   90/   90]    Overall Loss 0.418649    Objective Loss 0.418649    Top1 87.050360    Top5 99.280576    LR 0.001000    Time 0.265880    
2025-04-28 00:58:35,302 - --- validate (epoch=28)-----------
2025-04-28 00:58:35,302 - 2245 samples (100 per mini-batch)
2025-04-28 00:58:37,659 - Epoch: [28][   23/   23]    Loss 0.597549    Top1 81.425390    Top5 98.040089    
2025-04-28 00:58:37,677 - ==> Top1: 81.425    Top5: 98.040    Loss: 0.598

2025-04-28 00:58:37,677 - ==> Confusion:
[[ 91   0   0   0   0   0   3   0   3   0   0   0   0   0   0   0   0   1   0   4]
 [  0  92   0   0   0   2   1   2   2   0   5   1   0   2   0   0   4   1   2   6]
 [  1   0  76   0   3   0   8   0   7   0   0   0   0   0   0   0   0   0   1   7]
 [  4   2   0  83   0   4   4   1   1   1   1   6   0  13   0   0   3   0   5  21]
 [  0   0   0   0 187   1   0   0   0   0   1   0   1   0   0   0   0   0   2   6]
 [  1   0   1   0   1  44   0   2   0   0   0   0   1   0   0   1   0   0   1  36]
 [  0   1   0   0   0   0 108   0   3   0   1   0   0   0   0   0   0   0   0  15]
 [  2   0   0   0   0   2   0  92   0   1   3   0   0   0   0   1   0   0   0   1]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   2   0   0   0   1   0   1   0  69   3   0   0   3   0   1   3   0   0   2]
 [  0   1   0   0   0   0   2   0   4   0  97   0   0   0   0   0   0   0   1   9]
 [  1   2   0   0   0   0   0   0   0   0   5  63   0   3   0   0   4   0   0   3]
 [  3   0   1   0   3   1   0   0   0   0   0   0  66   0   2   0   1   0   0   6]
 [  2   2   0   0   1   0   0   0   0   1   3   2   0  99   0   0   0   0   2   3]
 [  0   0   0   0   6   0   0   0   0   0   1   0   4   0  40   0   0   0   1   7]
 [  0   1   0   0   5   2   0   1   1   0   2   1   0   0   0  80   0   1   2   2]
 [  1   1   1   0   3   1   0   0   0   0   2   2   0   0   0   0  43   1   4   4]
 [  4   1   0   0   0   0   0   0   1   0   2   0   0   0   0   0   1  77   6   5]
 [  1   0   1   0   4   3   1   0   2   0   5   0   0   0   0   0   0   3  75   9]
 [  2   0   1   0   1   2   2   0   1   0   0   0   0   0   0   0   0   0   0 130]]

2025-04-28 00:58:37,679 - ==> Best [Top1: 83.474   Top5: 97.773   Params: 306880 on epoch: 27]
2025-04-28 00:58:37,679 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:58:37,687 - 

2025-04-28 00:58:37,687 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:59:01,238 - Epoch: [29][   90/   90]    Overall Loss 0.417652    Objective Loss 0.417652    Top1 86.330935    Top5 99.280576    LR 0.001000    Time 0.261653    
2025-04-28 00:59:01,265 - --- validate (epoch=29)-----------
2025-04-28 00:59:01,266 - 2245 samples (100 per mini-batch)
2025-04-28 00:59:03,647 - Epoch: [29][   23/   23]    Loss 0.544967    Top1 82.538976    Top5 98.129176    
2025-04-28 00:59:03,667 - ==> Top1: 82.539    Top5: 98.129    Loss: 0.545

2025-04-28 00:59:03,668 - ==> Confusion:
[[ 95   0   0   1   0   0   1   0   3   0   0   0   0   0   0   0   0   1   0   1]
 [  0  96   0   2   0   3   0   2   1   0   0   4   0   1   0   3   8   0   0   0]
 [  0   0  55   1   5   1  22   0  12   0   0   0   0   0   0   1   1   1   0   4]
 [  1   0   0 136   0   0   0   1   0   0   1   1   0   3   0   5   0   0   1   0]
 [  0   0   0   0 191   3   0   0   0   0   0   0   1   0   0   1   1   0   0   1]
 [  6   2   0   3   4  61   1   2   0   0   0   1   1   0   0   2   0   0   0   5]
 [  3   0   0   0   0   0 117   0   1   0   2   0   1   0   0   0   0   0   1   3]
 [  0   0   1   5   0   0   0  89   0   0   1   0   0   0   0   5   0   0   1   0]
 [  1   0   0   0   0   0   0   0 213   0   0   0   0   0   0   0   0   0   0   2]
 [  2   0   0  10   0   0   0   2   0  65   2   1   0   3   0   0   1   0   0   0]
 [  1   1   1   1   0   0   2   0   3   0  95   0   0   0   0   0   4   2   4   0]
 [  1   1   0   6   1   0   0   1   0   0   1  62   0   1   0   0   6   1   0   0]
 [  2   1   0   0   7   1   0   0   0   0   1   0  68   0   0   0   0   0   1   2]
 [  2   0   0   9   0   0   0   0   0   0   0   4   0  96   0   0   2   1   1   0]
 [  3   0   1   1   9   0   1   1   0   0   0   0   7   0  34   0   0   0   1   1]
 [  0   1   0   3   3   0   0   3   1   0   0   0   0   0   0  86   1   0   0   0]
 [  0   1   0   1   0   1   0   0   1   0   2   5   0   0   0   2  49   1   0   0]
 [  2   0   0   2   1   0   0   0   1   0   1   0   0   0   0   0   2  80   8   0]
 [  9   0   0   2   1   4   0   1   3   0   3   1   1   1   0   1   0   3  74   0]
 [ 16   1   0   7   0  11   5   0   2   0   1   1   0   1   1   0   0   1   1  91]]

2025-04-28 00:59:03,670 - ==> Best [Top1: 83.474   Top5: 97.773   Params: 306880 on epoch: 27]
2025-04-28 00:59:03,670 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:59:03,677 - 

2025-04-28 00:59:03,677 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:59:27,002 - Epoch: [30][   90/   90]    Overall Loss 0.392828    Objective Loss 0.392828    Top1 82.014388    Top5 99.280576    LR 0.001000    Time 0.259136    
2025-04-28 00:59:27,034 - --- validate (epoch=30)-----------
2025-04-28 00:59:27,034 - 2245 samples (100 per mini-batch)
2025-04-28 00:59:29,413 - Epoch: [30][   23/   23]    Loss 0.488337    Top1 84.320713    Top5 98.173719    
2025-04-28 00:59:29,434 - ==> Top1: 84.321    Top5: 98.174    Loss: 0.488

2025-04-28 00:59:29,434 - ==> Confusion:
[[ 94   0   0   1   0   0   0   0   0   0   1   0   0   0   0   0   0   3   2   1]
 [  0  95   0   0   2   4   1   5   0   0   4   3   0   1   0   2   1   1   1   0]
 [  0   0  82   1   2   0   1   0   5   0   7   0   0   1   0   0   0   0   2   2]
 [  0   0   0 136   0   0   0   5   0   1   1   1   0   3   0   1   0   0   1   0]
 [  0   0   0   0 180   4   0   1   0   0   0   0   9   0   0   0   0   0   3   1]
 [  2   1   0   1   2  63   0   3   0   0   2   0   2   0   0   0   1   1   1   9]
 [  0   0   6   0   1   4  99   0   2   0   5   0   1   0   0   1   0   0   2   7]
 [  0   0   0   1   0   1   0  98   0   0   1   0   0   0   0   1   0   0   0   0]
 [  0   0   2   0   1   0   0   0 213   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   3   0   1   0   3   0  78   0   1   0   0   0   0   0   0   0   0]
 [  1   0   1   0   0   0   0   0   0   3 104   0   1   0   0   0   0   1   0   3]
 [  0   1   0   5   0   0   0   4   0   2   1  65   0   1   0   0   0   1   0   1]
 [  1   0   0   0   1   2   0   0   0   0   1   0  77   0   0   0   1   0   0   0]
 [  0   0   0  23   1   2   0   5   0   2   1   2   0  76   0   0   0   1   2   0]
 [  2   0   1   0   0   0   0   1   0   0   0   0  17   0  34   0   0   0   3   1]
 [  0   1   0   2   1   2   0   7   0   0   0   0   1   0   0  83   0   1   0   0]
 [  0   1   0   0   3   2   0   1   0   1   5   4   2   3   0   1  34   1   4   1]
 [  2   0   1   0   0   1   0   2   0   1   2   0   0   0   0   0   0  85   3   0]
 [  1   0   0   1   0   3   0   3   0   4   1   0   3   1   0   1   1   3  82   0]
 [  4   0   0   1   0   9   1   0   0   1   3   1   1   0   0   1   0   2   0 115]]

2025-04-28 00:59:29,436 - ==> Best [Top1: 84.321   Top5: 98.174   Params: 306880 on epoch: 30]
2025-04-28 00:59:29,436 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:59:29,447 - 

2025-04-28 00:59:29,447 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 00:59:53,078 - Epoch: [31][   90/   90]    Overall Loss 0.393140    Objective Loss 0.393140    Top1 81.294964    Top5 100.000000    LR 0.001000    Time 0.262536    
2025-04-28 00:59:53,104 - --- validate (epoch=31)-----------
2025-04-28 00:59:53,104 - 2245 samples (100 per mini-batch)
2025-04-28 00:59:55,459 - Epoch: [31][   23/   23]    Loss 0.554445    Top1 82.182628    Top5 97.817372    
2025-04-28 00:59:55,484 - ==> Top1: 82.183    Top5: 97.817    Loss: 0.554

2025-04-28 00:59:55,485 - ==> Confusion:
[[ 72   0   3   0   1   1   4   0   0   0   3   0   0   0   0   0   1   3   7   7]
 [  0  95   0   0   0   3   1   1   0   0   5   0   0   0   0   1   6   2   5   1]
 [  0   0  89   0   1   0   2   0   1   0   5   0   1   0   0   0   1   0   1   2]
 [  0   2   2 114   0   4   4   0   0   0   1   0   0   2   0   3   2   0  12   3]
 [  0   1   0   0 183   4   1   0   0   0   1   0   2   0   3   1   1   0   0   1]
 [  0   0   1   1   0  54   1   0   1   0   2   0   3   0   0   1   1   4   4  15]
 [  0   0   4   0   0   0 112   0   1   0   3   0   0   0   1   0   0   0   1   6]
 [  0   0   2   5   0   2   0  80   0   0   1   0   0   0   1   3   0   1   6   1]
 [  0   0   2   0   1   0   0   0 211   0   0   0   0   0   0   0   0   0   1   1]
 [  0   0   0   0   0   2   1   2   0  64   8   0   1   0   0   1   4   0   2   1]
 [  0   0   1   0   0   1   1   0   0   0 107   0   0   0   0   0   2   0   1   1]
 [  0   4   0   3   0   3   0   0   0   0   3  49   0   0   0   1  12   2   1   3]
 [  0   0   0   0   0   0   0   0   0   0   1   0  75   0   2   0   1   0   2   2]
 [  0   1   0  13   0   0   0   0   0   1   5   2   0  80   0   2   4   1   4   2]
 [  0   0   1   0   3   0   0   0   0   0   1   0   4   0  47   0   0   0   1   2]
 [  0   2   0   0   5   5   0   1   0   0   0   0   0   0   0  82   0   0   3   0]
 [  0   0   0   0   1   2   0   1   0   0   5   1   1   0   0   0  46   2   4   0]
 [  0   0   0   0   0   0   0   0   0   0   3   0   0   0   0   0   1  81  11   1]
 [  0   0   0   0   1   3   0   0   1   0   6   0   2   1   0   0   3   1  85   1]
 [  0   0   3   0   1   5   1   0   1   0   2   1   0   0   0   0   0   3   3 119]]

2025-04-28 00:59:55,487 - ==> Best [Top1: 84.321   Top5: 98.174   Params: 306880 on epoch: 30]
2025-04-28 00:59:55,487 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 00:59:55,495 - 

2025-04-28 00:59:55,495 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:00:19,216 - Epoch: [32][   90/   90]    Overall Loss 0.374139    Objective Loss 0.374139    Top1 86.330935    Top5 98.561151    LR 0.001000    Time 0.263539    
2025-04-28 01:00:19,242 - --- validate (epoch=32)-----------
2025-04-28 01:00:19,242 - 2245 samples (100 per mini-batch)
2025-04-28 01:00:21,604 - Epoch: [32][   23/   23]    Loss 0.593764    Top1 81.737194    Top5 97.461024    
2025-04-28 01:00:21,626 - ==> Top1: 81.737    Top5: 97.461    Loss: 0.594

2025-04-28 01:00:21,627 - ==> Confusion:
[[ 68   0   0   0   2   2   7   0   8   0   0   0   0   0   1   0   0   2   4   8]
 [  0  84   0   1   0   9   2   3   2   1   2   1   0   3   0   1   3   0   8   0]
 [  0   0  84   0   2   0   9   0   2   0   0   0   0   0   0   0   0   1   0   5]
 [  0   0   0 107   0  12   5   1   0   0   1   0   0   6   0   0   0   0  10   7]
 [  0   0   0   0 187   3   0   0   0   0   0   0   0   0   2   0   0   0   4   2]
 [  0   0   0   0   1  64   0   0   1   1   0   0   0   0   0   2   0   0   3  16]
 [  0   0   1   0   1   0 116   0   3   0   1   0   0   0   1   0   0   0   1   4]
 [  0   0   1   0   0   1   0  90   0   0   2   0   0   0   0   2   0   0   6   0]
 [  0   0   0   0   0   1   0   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   1   0   1   1   1   0  74   1   0   0   2   0   0   2   0   2   1]
 [  0   1   1   0   0   3   2   0   2   0  95   0   0   2   0   0   3   0   3   2]
 [  0   0   0   7   1  11   0   0   1   0   0  46   0   6   0   1   3   0   2   3]
 [  1   0   0   0   3   0   0   0   0   0   0   0  71   0   7   0   0   0   0   1]
 [  0   0   0   0   0   2   0   0   1   1   0   1   0 102   0   0   1   0   4   3]
 [  0   0   0   0   1   0   0   0   0   0   1   0   2   0  53   0   0   0   1   1]
 [  0   1   0   0   3   4   0   1   0   0   0   0   0   0   1  83   0   0   5   0]
 [  0   0   0   0   1   2   1   0   1   1   3   2   0   0   0   0  33   1  17   1]
 [  0   0   2   0   3   1   0   0   2   0   3   0   0   0   0   0   3  63  18   2]
 [  0   0   1   0   1   5   0   0   2   1   5   0   0   1   3   0   1   2  81   1]
 [  0   0   1   0   1   6   2   0   6   0   0   0   0   0   0   0   0   0   4 119]]

2025-04-28 01:00:21,629 - ==> Best [Top1: 84.321   Top5: 98.174   Params: 306880 on epoch: 30]
2025-04-28 01:00:21,629 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:00:21,636 - 

2025-04-28 01:00:21,636 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:00:45,055 - Epoch: [33][   90/   90]    Overall Loss 0.369353    Objective Loss 0.369353    Top1 80.575540    Top5 99.280576    LR 0.001000    Time 0.260183    
2025-04-28 01:00:45,081 - --- validate (epoch=33)-----------
2025-04-28 01:00:45,081 - 2245 samples (100 per mini-batch)
2025-04-28 01:00:47,435 - Epoch: [33][   23/   23]    Loss 0.523495    Top1 83.786192    Top5 98.574610    
2025-04-28 01:00:47,461 - ==> Top1: 83.786    Top5: 98.575    Loss: 0.523

2025-04-28 01:00:47,462 - ==> Confusion:
[[ 68   0   2   0   0   1   1   0   0   0   7   0   0   0   0   0   3   9   1  10]
 [  0 110   0   0   0   0   1   2   0   0   1   0   0   0   0   0   3   1   2   0]
 [  0   0  93   0   2   0   2   0   2   0   1   0   0   0   0   0   0   2   0   1]
 [  0   1   0 121   0   4   0   2   0   5   1   3   0   0   0   0   5   0   5   2]
 [  0   0   0   0 187   1   0   0   0   0   0   0   6   0   0   0   0   0   4   0]
 [  0   3   0   0   1  62   0   2   0   0   1   0   3   0   1   1   3   1   1   9]
 [  0   1   7   0   1   1 101   0   1   0   6   0   1   0   1   1   0   0   0   7]
 [  0   3   0   1   1   0   0  94   0   0   1   0   0   0   0   0   0   1   1   0]
 [  1   0   5   0   0   0   2   0 207   0   0   0   0   0   0   0   0   1   0   0]
 [  0   2   0   0   0   1   0   1   0  76   1   1   0   0   0   0   3   1   0   0]
 [  0   0   0   0   0   0   0   0   0   1 105   0   0   0   0   0   5   0   2   1]
 [  0   8   0   1   0   0   0   0   0   3   0  60   0   1   0   0   6   0   0   2]
 [  0   0   2   0   0   0   0   0   0   0   0   0  78   0   0   0   2   0   0   1]
 [  0   5   0   6   1   1   0   1   0   6   1   5   0  81   0   0   5   0   2   1]
 [  0   0   4   0   2   0   0   1   0   1   0   0  19   0  31   0   0   0   1   0]
 [  0   2   0   2  10   5   0   3   1   0   0   0   1   0   0  72   1   0   1   0]
 [  0   1   0   0   0   1   0   0   0   1   1   1   1   0   0   0  56   1   0   0]
 [  0   3   1   0   0   1   0   0   0   0   3   0   0   0   0   0   6  78   5   0]
 [  0   1   1   0   2   2   0   1   0   1   2   0   2   1   0   0   3   4  83   1]
 [  0   0   1   0   1   9   1   0   1   0   4   0   0   0   0   0   1   2   1 118]]

2025-04-28 01:00:47,464 - ==> Best [Top1: 84.321   Top5: 98.174   Params: 306880 on epoch: 30]
2025-04-28 01:00:47,464 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:00:47,471 - 

2025-04-28 01:00:47,471 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:01:10,988 - Epoch: [34][   90/   90]    Overall Loss 0.338800    Objective Loss 0.338800    Top1 87.769784    Top5 99.280576    LR 0.001000    Time 0.261271    
2025-04-28 01:01:11,015 - --- validate (epoch=34)-----------
2025-04-28 01:01:11,015 - 2245 samples (100 per mini-batch)
2025-04-28 01:01:13,380 - Epoch: [34][   23/   23]    Loss 0.684335    Top1 78.574610    Top5 97.505568    
2025-04-28 01:01:13,405 - ==> Top1: 78.575    Top5: 97.506    Loss: 0.684

2025-04-28 01:01:13,406 - ==> Confusion:
[[ 65   1   5   0   0   5   2   0   0   0   1   0   0   0   2   0   0   6   3  12]
 [  0 110   0   0   1   1   1   0   0   0   0   2   0   1   0   1   3   0   0   0]
 [  0   1  94   0   4   2   0   0   1   0   0   0   0   0   0   0   0   0   0   1]
 [  0   6   1  75   0  10   0   0   1   0   1  36   0   6   0   2   5   0   4   2]
 [  0   2   0   0 189   4   0   0   0   0   0   0   1   0   0   0   0   0   1   1]
 [  0   0   1   0   3  69   0   0   0   0   0   1   0   0   0   2   0   0   0  12]
 [  0   4  21   0   0   3  90   0   1   0   2   0   0   0   1   0   0   0   0   6]
 [  0   7   1   0   2   2   0  71   0   0   1   7   0   2   0   5   1   1   1   1]
 [  0   0  17   0   0   1   3   0 195   0   0   0   0   0   0   0   0   0   0   0]
 [  0   6   0   2   0   3   0   0   0  55   4   1   0   5   0   0   8   2   0   0]
 [  0   2   4   0   0   1   0   0   1   0  97   0   1   0   0   0   3   1   0   4]
 [  0   1   0   0   0   0   0   0   0   0   1  76   0   0   0   0   2   1   0   0]
 [  0   0   1   0   5   2   0   0   0   0   0   0  71   0   1   0   1   1   0   1]
 [  0   3   0   1   1   0   0   0   0   0   0  17   0  88   0   1   2   1   0   1]
 [  0   0   5   0  11   2   0   0   0   0   1   0   4   0  32   0   2   0   0   2]
 [  0   2   0   0  12   2   0   1   1   0   0   1   0   0   0  78   0   1   0   0]
 [  0   3   0   0   2   2   0   0   0   0   0   2   1   0   0   0  53   0   0   0]
 [  0   2   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1  91   0   2]
 [  0   1   3   0   7   6   0   0   1   0   0   2   0   0   2   0   8  13  54   7]
 [  0   2   5   0   0  13   2   0   2   0   1   0   2   0   0   0   0   1   0 111]]

2025-04-28 01:01:13,408 - ==> Best [Top1: 84.321   Top5: 98.174   Params: 306880 on epoch: 30]
2025-04-28 01:01:13,408 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:01:13,416 - 

2025-04-28 01:01:13,416 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:01:36,868 - Epoch: [35][   90/   90]    Overall Loss 0.325655    Objective Loss 0.325655    Top1 89.208633    Top5 99.280576    LR 0.001000    Time 0.260552    
2025-04-28 01:01:36,894 - --- validate (epoch=35)-----------
2025-04-28 01:01:36,894 - 2245 samples (100 per mini-batch)
2025-04-28 01:01:39,240 - Epoch: [35][   23/   23]    Loss 0.490346    Top1 84.766147    Top5 98.351893    
2025-04-28 01:01:39,265 - ==> Top1: 84.766    Top5: 98.352    Loss: 0.490

2025-04-28 01:01:39,266 - ==> Confusion:
[[ 88   1   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   2   9   1]
 [  0  98   0   0   1   0   1   3   0   1   0   2   0   3   0   1   2   0   8   0]
 [  0   0  87   0   2   0   2   0   3   0   2   0   0   0   0   0   0   1   5   1]
 [  0   1   1 119   0   0   0   2   0   0   0   6   0  10   0   2   0   0   8   0]
 [  0   0   1   0 188   1   0   0   0   0   0   0   1   0   3   0   0   0   3   1]
 [  3   1   2   1   1  50   0   1   0   0   2   1   3   0   1   1   2   1   8  10]
 [  2   2  10   0   0   2  98   0   2   0   2   0   0   0   1   0   0   2   2   5]
 [  0   1   0   0   1   0   0  93   0   0   3   0   0   0   0   1   0   1   2   0]
 [  3   0   2   0   0   1   1   0 204   0   0   0   0   0   0   0   0   1   2   2]
 [  0   0   0   1   0   0   0   1   0  74   2   1   0   1   1   0   2   1   2   0]
 [  0   0   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   0   2   0]
 [  1   1   0   0   0   0   0   1   0   0   0  71   0   3   0   0   2   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   3   0  77   0   1   0   0   0   2   0]
 [  1   0   0   3   0   1   0   1   0   4   1   5   0  95   0   0   0   0   4   0]
 [  0   0   1   0   3   0   0   0   0   0   2   0   7   0  43   0   0   0   2   1]
 [  0   2   0   1   7   0   0   4   1   0   1   0   0   0   1  78   0   0   3   0]
 [  0   2   0   0   4   0   0   1   0   0   4   0   0   1   0   0  44   1   6   0]
 [  0   2   0   0   0   0   0   0   1   0   2   0   0   0   0   0   0  79  12   1]
 [  0   1   0   0   0   2   0   0   0   0   2   0   0   1   0   0   1   1  93   3]
 [  4   2   5   0   2   4   0   0   0   0   3   0   1   0   0   0   0   1   5 112]]

2025-04-28 01:01:39,268 - ==> Best [Top1: 84.766   Top5: 98.352   Params: 306880 on epoch: 35]
2025-04-28 01:01:39,268 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:01:39,279 - 

2025-04-28 01:01:39,279 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:02:02,686 - Epoch: [36][   90/   90]    Overall Loss 0.335607    Objective Loss 0.335607    Top1 85.611511    Top5 100.000000    LR 0.001000    Time 0.260045    
2025-04-28 01:02:02,715 - --- validate (epoch=36)-----------
2025-04-28 01:02:02,715 - 2245 samples (100 per mini-batch)
2025-04-28 01:02:05,096 - Epoch: [36][   23/   23]    Loss 0.483287    Top1 84.498886    Top5 98.351893    
2025-04-28 01:02:05,117 - ==> Top1: 84.499    Top5: 98.352    Loss: 0.483

2025-04-28 01:02:05,118 - ==> Confusion:
[[ 44   1   5   0   2   4   9   0   9   0   4   0   0   1   0   0   1   1   8  13]
 [  0  91   1   0   0   3   1   1   0   0   0  11   0   4   0   1   6   0   0   1]
 [  0   0  86   0   3   0   7   0   5   0   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0 131   0   1   1   0   0   0   1   4   0   5   0   0   0   0   6   0]
 [  0   0   1   0 192   2   0   0   0   0   0   0   0   1   1   0   0   0   1   0]
 [  0   0   1   0   7  56   0   2   1   0   0   0   0   0   0   1   1   0   0  19]
 [  0   0   0   0   1   0 118   0   2   0   1   0   0   0   1   0   0   0   0   5]
 [  0   0   1   5   1   1   0  83   0   0   2   2   0   3   1   1   0   0   2   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   6   0   2   1   0   0  70   1   1   0   3   0   0   1   0   1   0]
 [  0   1   1   0   0   0   0   0   0   0 111   0   0   1   0   0   0   0   0   0]
 [  0   0   0   1   1   1   0   0   0   0   1  74   0   1   0   0   1   0   0   1]
 [  0   0   3   0   7   2   1   0   0   0   1   0  63   0   5   0   0   1   0   0]
 [  0   0   0   3   1   0   0   0   0   1   0   3   0 103   0   0   0   1   2   1]
 [  0   0   7   0   3   0   0   0   0   0   0   0   1   1  45   0   0   0   0   2]
 [  0   1   0   2   5   1   0   2   1   0   0   0   0   1   0  84   0   0   1   0]
 [  0   1   0   1   4   0   0   0   0   0   1   3   0   2   0   0  47   1   2   1]
 [  0   0   1   1   1   1   1   0   1   0   1   0   0   0   0   0   5  79   5   1]
 [  0   0   0   0   3   4   1   0   1   0   2   0   0   2   0   0   2   5  82   2]
 [  0   0   3   1   4   2   3   0   1   0   2   0   0   0   0   0   0   1   0 122]]

2025-04-28 01:02:05,120 - ==> Best [Top1: 84.766   Top5: 98.352   Params: 306880 on epoch: 35]
2025-04-28 01:02:05,120 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:02:05,128 - 

2025-04-28 01:02:05,128 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:02:28,800 - Epoch: [37][   90/   90]    Overall Loss 0.313706    Objective Loss 0.313706    Top1 87.769784    Top5 99.280576    LR 0.001000    Time 0.262997    
2025-04-28 01:02:28,826 - --- validate (epoch=37)-----------
2025-04-28 01:02:28,827 - 2245 samples (100 per mini-batch)
2025-04-28 01:02:31,141 - Epoch: [37][   23/   23]    Loss 0.413901    Top1 87.082405    Top5 98.752784    
2025-04-28 01:02:31,163 - ==> Top1: 87.082    Top5: 98.753    Loss: 0.414

2025-04-28 01:02:31,163 - ==> Confusion:
[[ 91   0   0   0   0   1   3   0   1   0   0   0   0   1   0   0   0   1   0   4]
 [  0 110   0   0   0   2   1   1   0   0   0   0   0   2   0   1   1   1   0   1]
 [  0   1  87   0   2   0   6   0   7   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0 131   0   2   2   0   1   0   0   1   0   5   0   1   1   0   1   3]
 [  0   0   1   0 187   2   0   0   0   0   0   0   2   0   1   1   0   0   1   3]
 [  0   0   1   0   6  55   1   1   3   0   0   1   0   0   0   2   0   0   0  18]
 [  0   0   3   0   0   0 116   0   2   0   1   0   0   0   1   1   1   0   0   3]
 [  0   2   0   0   0   0   0  95   1   0   1   0   0   1   0   1   0   1   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   4   0   1   0   2   1   0   0  71   0   1   0   1   0   0   3   0   1   0]
 [  2   0   0   0   0   0   1   0   4   1  99   1   0   2   0   0   0   0   2   2]
 [  0   2   0   1   0   1   0   0   0   0   0  66   0   6   0   0   2   1   0   2]
 [  1   1   0   0   1   1   0   0   1   0   2   0  66   0  10   0   0   0   0   0]
 [  0   0   0   4   1   0   0   0   0   0   0   3   0 107   0   0   0   0   0   0]
 [  0   0   3   0   0   0   2   1   0   0   0   0   1   0  52   0   0   0   0   0]
 [  1   1   0   2   3   1   0   1   1   0   0   0   0   0   0  85   1   2   0   0]
 [  0   4   0   1   3   3   0   0   1   0   0   5   0   0   0   0  44   1   1   0]
 [  0   2   1   1   1   1   0   1   1   1   0   0   0   0   0   0   1  83   4   0]
 [  0   0   3   1   1   2   0   0   3   1   2   0   0   3   0   0   3   3  78   4]
 [  3   1   5   0   1   3   3   0   5   0   1   0   0   0   0   0   0   1   0 116]]

2025-04-28 01:02:31,166 - ==> Best [Top1: 87.082   Top5: 98.753   Params: 306880 on epoch: 37]
2025-04-28 01:02:31,166 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:02:31,176 - 

2025-04-28 01:02:31,176 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:02:54,570 - Epoch: [38][   90/   90]    Overall Loss 0.293426    Objective Loss 0.293426    Top1 82.014388    Top5 99.280576    LR 0.001000    Time 0.259904    
2025-04-28 01:02:54,597 - --- validate (epoch=38)-----------
2025-04-28 01:02:54,598 - 2245 samples (100 per mini-batch)
2025-04-28 01:02:56,906 - Epoch: [38][   23/   23]    Loss 0.566810    Top1 84.276169    Top5 98.040089    
2025-04-28 01:02:56,932 - ==> Top1: 84.276    Top5: 98.040    Loss: 0.567

2025-04-28 01:02:56,933 - ==> Confusion:
[[ 98   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   2]
 [  2 106   0   0   1   1   1   3   0   1   0   1   0   1   0   0   2   0   0   1]
 [  5   1  72   0   2   1  10   0   2   0   0   0   0   0   1   0   1   2   0   6]
 [  6   0   0 124   0   5   0   1   1   0   0   0   0   6   0   0   0   0   4   2]
 [  1   1   0   0 193   1   0   1   0   0   0   0   0   0   0   0   0   0   0   1]
 [  2   1   0   0   4  65   0   1   0   0   0   0   0   0   0   1   0   0   1  13]
 [  5   1   0   0   1   1 114   0   0   0   0   0   0   0   0   0   0   0   0   6]
 [  1   0   0   2   1   2   0  88   0   1   0   0   0   2   0   2   0   1   2   0]
 [ 11   0   0   0   0   0   6   0 196   0   0   0   0   0   0   0   0   0   0   3]
 [  2   0   0   5   0   3   0   0   0  73   0   0   0   1   0   0   1   1   0   0]
 [ 11   3   0   1   0   2   0   0   2   0  85   0   0   1   0   1   0   2   0   6]
 [  2   4   0   2   0   2   0   1   0   1   1  53   0   4   0   2   3   2   0   4]
 [  1   0   0   0   3   1   0   0   0   0   0   0  76   0   2   0   0   0   0   0]
 [  4   0   0   4   2   0   0   1   0   1   0   0   0 102   0   0   0   0   0   1]
 [  4   0   0   0   3   0   1   0   0   0   0   0   7   0  41   0   0   0   1   2]
 [  1   1   0   2   4   0   0   1   0   0   0   0   0   0   0  88   0   0   0   1]
 [  0   2   0   0   5   4   1   0   0   0   2   0   2   2   0   1  43   1   0   0]
 [  3   1   0   0   0   2   0   0   0   0   1   0   0   0   0   1   0  87   1   1]
 [ 11   1   0   0   3   3   1   1   0   0   0   0   2   2   0   0   0   2  74   4]
 [ 11   0   2   0   2   4   4   0   0   0   0   0   1   0   0   1   0   0   0 114]]

2025-04-28 01:02:56,935 - ==> Best [Top1: 87.082   Top5: 98.753   Params: 306880 on epoch: 37]
2025-04-28 01:02:56,935 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:02:56,942 - 

2025-04-28 01:02:56,942 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:03:20,674 - Epoch: [39][   90/   90]    Overall Loss 0.276789    Objective Loss 0.276789    Top1 85.611511    Top5 100.000000    LR 0.001000    Time 0.263655    
2025-04-28 01:03:20,706 - --- validate (epoch=39)-----------
2025-04-28 01:03:20,706 - 2245 samples (100 per mini-batch)
2025-04-28 01:03:23,084 - Epoch: [39][   23/   23]    Loss 0.509125    Top1 83.964365    Top5 98.440980    
2025-04-28 01:03:23,106 - ==> Top1: 83.964    Top5: 98.441    Loss: 0.509

2025-04-28 01:03:23,107 - ==> Confusion:
[[ 62   1   7   2   2   0   6   0   0   1   2   0   0   1   8   0   3   1   0   6]
 [  0 111   0   0   0   0   1   1   0   1   0   1   1   0   0   1   3   0   0   0]
 [  0   2  91   0   2   0   2   0   0   0   1   0   1   0   3   0   1   0   0   0]
 [  0   2   0 112   0   1   0   1   0   6   0   9   0   9   2   0   3   0   2   2]
 [  0   0   0   0 186   0   0   0   0   0   1   0   6   0   2   0   3   0   0   0]
 [  0   6   2   0   5  49   2   0   0   2   0   1   2   0   0   1   7   1   3   7]
 [  0   2   2   0   0   1 112   0   0   0   3   0   1   0   3   1   0   0   0   3]
 [  0   2   0   1   0   0   0  92   0   1   1   1   0   1   0   2   1   0   0   0]
 [  0   1  13   0   1   1   5   0 192   0   0   0   0   0   0   0   2   0   0   1]
 [  0   1   0   1   0   0   0   0   0  80   0   1   0   1   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   1 101   1   1   3   0   0   5   0   1   0]
 [  0   1   0   0   0   1   0   0   0   1   0  71   0   3   0   0   4   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  82   0   1   0   0   0   0   0]
 [  0   2   0   2   0   0   0   0   0   3   0   3   0 103   0   0   0   0   1   1]
 [  0   0   0   0   0   0   0   0   0   1   0   0   8   0  50   0   0   0   0   0]
 [  0   1   0   1   1   1   0   1   0   0   0   0   1   0   0  90   1   0   1   0]
 [  0   2   0   0   0   0   0   0   0   2   0   1   2   0   0   0  55   0   1   0]
 [  0   5   2   1   3   0   0   0   0   1   2   0   0   0   1   0   6  72   4   0]
 [  0   1   1   1   2   2   1   1   0   2   1   0   4   4   5   1   5   4  69   0]
 [  0   0   6   0   6   6   2   0   0   2   2   1   0   0   1   1   4   2   1 105]]

2025-04-28 01:03:23,109 - ==> Best [Top1: 87.082   Top5: 98.753   Params: 306880 on epoch: 37]
2025-04-28 01:03:23,109 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:03:23,117 - 

2025-04-28 01:03:23,117 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:03:46,802 - Epoch: [40][   90/   90]    Overall Loss 0.274005    Objective Loss 0.274005    Top1 92.086331    Top5 99.280576    LR 0.001000    Time 0.263132    
2025-04-28 01:03:46,829 - --- validate (epoch=40)-----------
2025-04-28 01:03:46,829 - 2245 samples (100 per mini-batch)
2025-04-28 01:03:49,185 - Epoch: [40][   23/   23]    Loss 0.418510    Top1 87.750557    Top5 98.574610    
2025-04-28 01:03:49,208 - ==> Top1: 87.751    Top5: 98.575    Loss: 0.419

2025-04-28 01:03:49,209 - ==> Confusion:
[[ 97   0   0   2   0   0   0   0   1   0   0   0   0   0   0   0   1   0   0   1]
 [  0 106   1   0   1   2   1   2   0   0   3   1   0   0   0   0   1   1   0   1]
 [  0   0  91   0   3   0   2   0   5   0   0   0   0   0   0   0   0   1   0   1]
 [  0   1   0 132   0   0   0   2   0   1   1   3   0   4   0   0   1   0   4   0]
 [  0   0   0   0 191   2   0   1   0   0   0   0   1   0   0   1   0   0   0   2]
 [  1   0   0   0   5  73   0   1   0   0   0   0   1   0   0   1   1   1   0   4]
 [  2   0   4   0   0   1 107   0   4   0   2   0   1   0   1   1   0   1   0   4]
 [  0   0   0   1   1   2   0  93   0   1   2   0   0   0   0   2   0   0   0   0]
 [  0   0   0   0   1   0   0   0 214   0   0   0   0   0   0   0   0   0   0   1]
 [  0   2   0   2   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  1   1   0   0   0   1   0   0   1   0 106   0   0   0   0   0   1   2   0   1]
 [  1   1   0   2   1   1   0   0   0   0   1  67   0   1   0   0   3   2   0   1]
 [  1   0   2   0   5   2   0   0   0   1   0   0  70   0   0   0   0   0   0   2]
 [  1   2   0  12   4   1   0   0   0   2   2   3   0  85   0   0   2   0   1   0]
 [  3   0   1   0   4   1   0   1   0   0   0   0   3   0  44   0   0   0   1   1]
 [  0   1   0   1   2   2   0   3   0   0   0   0   0   0   0  89   0   0   0   0]
 [  0   1   0   0   4   2   0   0   0   0   3   0   0   0   0   1  52   0   0   0]
 [  2   2   0   0   1   0   0   0   0   0   3   0   0   0   0   0   1  86   1   1]
 [  1   0   0   0   7   5   0   0   1   2   4   0   1   0   0   1   0   3  77   2]
 [  4   0   3   0   2  14   2   0   0   0   1   0   0   0   0   0   0   1   0 112]]

2025-04-28 01:03:49,211 - ==> Best [Top1: 87.751   Top5: 98.575   Params: 306880 on epoch: 40]
2025-04-28 01:03:49,211 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:03:49,222 - 

2025-04-28 01:03:49,222 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:04:13,398 - Epoch: [41][   90/   90]    Overall Loss 0.287041    Objective Loss 0.287041    Top1 91.366906    Top5 99.280576    LR 0.001000    Time 0.268591    
2025-04-28 01:04:13,432 - --- validate (epoch=41)-----------
2025-04-28 01:04:13,432 - 2245 samples (100 per mini-batch)
2025-04-28 01:04:15,865 - Epoch: [41][   23/   23]    Loss 0.421250    Top1 87.616927    Top5 98.841871    
2025-04-28 01:04:15,887 - ==> Top1: 87.617    Top5: 98.842    Loss: 0.421

2025-04-28 01:04:15,888 - ==> Confusion:
[[ 82   1   0   1   0   2   5   0   0   0   0   0   0   0   1   0   1   1   1   7]
 [  0 110   1   0   0   3   2   1   0   0   1   0   0   1   0   1   0   0   0   0]
 [  0   0  86   0   3   0  10   0   0   0   3   0   0   0   0   0   0   0   0   1]
 [  0   4   0 127   0   1   4   1   0   0   0   3   0   7   0   0   0   0   2   0]
 [  0   1   0   0 191   4   0   0   0   0   0   0   1   0   1   0   0   0   0   0]
 [  0   1   0   0   0  74   0   0   0   0   0   0   1   0   0   0   1   0   1  10]
 [  0   1   1   0   0   1 118   0   1   0   3   0   0   0   1   0   0   0   0   2]
 [  0   6   0   1   3   3   0  84   1   0   1   0   0   0   0   1   0   1   1   0]
 [  0   0   4   0   0   0   2   0 209   0   0   0   0   0   0   0   0   0   1   0]
 [  0   4   0   3   0   2   0   0   0  72   2   1   0   1   0   0   0   1   0   0]
 [  0   2   0   1   1   1   0   0   0   0 104   1   0   1   0   0   0   1   1   1]
 [  0   1   0   2   0   2   0   0   0   1   0  72   0   1   0   0   2   0   0   0]
 [  0   0   1   0   1   4   0   0   0   0   1   0  72   0   4   0   0   0   0   0]
 [  0   5   0   2   0   2   0   0   1   2   0   4   0  98   0   0   0   0   0   1]
 [  0   0   0   0   1   0   1   0   0   0   0   0   2   0  54   0   0   0   0   1]
 [  0   3   0   0   5   6   0   3   0   0   0   1   0   0   0  78   0   1   1   0]
 [  0   2   0   0   4   1   0   0   0   0   0   2   1   1   0   0  51   0   1   0]
 [  0   3   0   1   1   1   0   0   0   0   3   0   0   0   0   0   2  85   1   0]
 [  0   0   0   1   2   6   1   0   0   0   0   1   2   3   2   0   2   4  79   1]
 [  0   0   0   1   1   9   2   0   0   0   1   0   0   0   2   0   0   2   0 121]]

2025-04-28 01:04:15,890 - ==> Best [Top1: 87.751   Top5: 98.575   Params: 306880 on epoch: 40]
2025-04-28 01:04:15,890 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:04:15,899 - 

2025-04-28 01:04:15,900 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:04:39,241 - Epoch: [42][   90/   90]    Overall Loss 0.253895    Objective Loss 0.253895    Top1 87.050360    Top5 99.280576    LR 0.001000    Time 0.259320    
2025-04-28 01:04:39,271 - --- validate (epoch=42)-----------
2025-04-28 01:04:39,271 - 2245 samples (100 per mini-batch)
2025-04-28 01:04:41,617 - Epoch: [42][   23/   23]    Loss 0.446474    Top1 86.681514    Top5 98.886414    
2025-04-28 01:04:41,639 - ==> Top1: 86.682    Top5: 98.886    Loss: 0.446

2025-04-28 01:04:41,640 - ==> Confusion:
[[ 95   0   0   0   0   0   0   0   1   0   1   0   0   0   0   0   0   1   0   4]
 [  0 111   0   0   0   0   0   1   0   0   0   1   0   1   0   1   3   1   0   1]
 [  0   0  87   0   2   0   5   0   2   1   3   0   1   0   0   0   0   1   0   1]
 [  0   1   0 105   0   0   0   0   0   7   0  12   0  11   0   5   4   0   3   1]
 [  0   1   1   0 188   1   0   0   0   0   0   0   1   0   1   2   0   0   1   2]
 [  1   4   0   1   3  40   1   1   0   0   3   0   0   0   0   3   3   4   2  22]
 [  1   1   2   1   0   0 113   0   1   0   3   0   0   0   1   1   0   1   0   3]
 [  0   3   0   2   0   0   0  85   0   0   1   1   0   1   0   8   0   1   0   0]
 [  1   0   2   0   0   1   0   0 212   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   0   0   0   1   0   0  79   1   0   0   0   0   0   3   0   0   0]
 [  0   2   0   0   0   0   1   0   0   0 100   1   0   0   0   1   3   6   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  72   0   1   0   1   4   1   0   1]
 [  1   0   0   0   0   0   0   0   0   0   3   1  77   0   1   0   0   0   0   0]
 [  1   1   0   2   0   0   0   1   0   5   1   2   0 100   0   0   1   0   1   0]
 [  0   0   2   0   1   0   1   0   0   1   1   0   7   0  45   0   0   0   0   1]
 [  0   1   0   1   0   0   0   1   1   0   0   0   0   0   0  91   1   2   0   0]
 [  0   1   0   0   1   1   0   0   0   2   1   0   0   0   0   1  55   1   0   0]
 [  0   0   1   0   0   0   0   0   1   0   1   0   0   0   0   0   1  91   1   1]
 [  0   1   0   0   0   1   0   0   0   5   1   0   1   1   0   0   2   7  84   1]
 [  2   0   4   0   0   2   2   0   1   2   6   0   0   0   1   0   0   2   1 116]]

2025-04-28 01:04:41,642 - ==> Best [Top1: 87.751   Top5: 98.575   Params: 306880 on epoch: 40]
2025-04-28 01:04:41,642 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:04:41,651 - 

2025-04-28 01:04:41,651 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:05:05,324 - Epoch: [43][   90/   90]    Overall Loss 0.249872    Objective Loss 0.249872    Top1 89.208633    Top5 99.280576    LR 0.001000    Time 0.263000    
2025-04-28 01:05:05,358 - --- validate (epoch=43)-----------
2025-04-28 01:05:05,358 - 2245 samples (100 per mini-batch)
2025-04-28 01:05:07,811 - Epoch: [43][   23/   23]    Loss 0.446686    Top1 87.438753    Top5 98.574610    
2025-04-28 01:05:07,833 - ==> Top1: 87.439    Top5: 98.575    Loss: 0.447

2025-04-28 01:05:07,834 - ==> Confusion:
[[ 92   0   0   0   0   0   1   0   0   0   3   0   0   0   0   0   1   1   2   2]
 [  1 101   0   0   1   2   1   2   0   3   4   3   0   0   0   0   2   0   0   0]
 [  0   0  94   0   2   0   3   0   1   0   1   0   0   0   0   0   0   1   0   1]
 [  2   0   0 109   0   1   2   3   0   3   2   7   0   7   0   1   0   0   5   7]
 [  0   0   0   0 192   0   0   0   0   1   1   0   1   0   0   0   0   0   2   1]
 [  2   0   1   0   8  55   0   0   0   0   5   0   0   0   0   1   3   1   0  12]
 [  0   0   8   0   3   0 106   0   0   0   3   0   0   0   1   1   0   0   0   6]
 [  1   0   0   0   0   0   0  94   0   1   2   0   0   0   1   0   0   1   2   0]
 [  1   0   9   0   0   0   2   0 202   0   0   0   0   0   0   0   0   0   0   2]
 [  0   0   0   1   0   0   0   0   0  76   3   2   0   1   0   0   1   0   1   1]
 [  0   0   0   0   0   0   0   0   0   0 113   0   0   0   0   0   0   0   1   0]
 [  1   1   0   0   0   0   0   0   0   1   1  75   0   0   0   0   0   0   0   2]
 [  1   0   0   0   2   0   0   0   0   0   3   0  74   0   1   0   1   0   1   0]
 [  0   0   0   0   1   0   0   0   0   3   1   7   0 100   0   0   0   1   1   1]
 [  2   0   1   0   2   0   0   0   0   0   2   0   2   0  49   0   0   0   1   0]
 [  0   1   0   0   4   1   0   2   1   0   0   0   0   0   0  87   0   0   2   0]
 [  0   0   0   1   2   0   0   0   0   1   3   2   0   0   0   0  51   1   2   0]
 [  1   0   0   0   0   0   0   0   1   1   3   0   0   0   0   0   0  86   3   2]
 [  4   0   0   0   3   1   0   0   0   0   4   0   0   0   0   0   2   1  89   0]
 [  2   0   1   0   6   1   1   0   0   1   6   0   1   0   0   0   0   1   1 118]]

2025-04-28 01:05:07,836 - ==> Best [Top1: 87.751   Top5: 98.575   Params: 306880 on epoch: 40]
2025-04-28 01:05:07,836 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:05:07,845 - 

2025-04-28 01:05:07,845 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:05:31,960 - Epoch: [44][   90/   90]    Overall Loss 0.263775    Objective Loss 0.263775    Top1 89.928058    Top5 99.280576    LR 0.001000    Time 0.267913    
2025-04-28 01:05:31,988 - --- validate (epoch=44)-----------
2025-04-28 01:05:31,988 - 2245 samples (100 per mini-batch)
2025-04-28 01:05:34,445 - Epoch: [44][   23/   23]    Loss 0.397405    Top1 88.017817    Top5 98.886414    
2025-04-28 01:05:34,467 - ==> Top1: 88.018    Top5: 98.886    Loss: 0.397

2025-04-28 01:05:34,468 - ==> Confusion:
[[ 86   0   0   0   0   3   0   0   1   0   2   0   0   1   0   0   0   1   1   7]
 [  0 106   0   0   0   1   1   2   0   1   2   0   0   1   0   2   1   1   0   2]
 [  0   0  93   0   0   0   1   0   2   0   1   0   0   0   0   1   0   0   0   5]
 [  0   1   0 136   0   1   0   0   0   0   0   0   0   8   0   0   0   0   2   1]
 [  0   0   0   0 179   2   0   1   0   0   0   0   5   1   3   0   1   0   1   5]
 [  0   0   0   0   0  58   0   0   1   0   1   0   1   0   0   1   1   1   1  23]
 [  0   1   2   0   0   0 108   0   2   0   2   0   0   0   1   1   0   0   0  11]
 [  0   0   0   1   0   2   0  92   0   0   1   0   0   3   0   3   0   0   0   0]
 [  1   0   1   0   0   1   1   0 210   0   0   0   0   0   0   0   0   0   0   2]
 [  2   3   0   1   0   1   0   1   0  72   1   0   0   2   0   0   0   0   2   1]
 [  0   3   0   1   0   0   0   0   0   1 106   0   0   0   0   0   0   2   0   1]
 [  0   4   0   2   0   1   0   0   0   0   1  67   0   5   0   0   0   0   0   1]
 [  0   0   0   0   0   1   0   0   0   0   1   0  77   1   2   0   0   0   0   1]
 [  0   1   0   2   0   1   0   0   0   2   1   1   0 106   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   1   0   3   0  52   0   0   0   0   3]
 [  0   1   0   2   1   1   0   3   0   0   0   0   1   0   0  89   0   0   0   0]
 [  0   1   0   0   1   3   0   0   0   1   5   2   1   0   0   0  46   0   1   2]
 [  1   0   0   1   0   1   0   0   1   0   3   0   0   0   0   0   0  87   1   2]
 [  0   3   0   0   0   6   1   0   0   2   1   2   1   2   0   1   0   3  77   5]
 [  0   0   0   0   0   5   1   0   1   0   2   0   0   0   0   1   0   0   0 129]]

2025-04-28 01:05:34,470 - ==> Best [Top1: 88.018   Top5: 98.886   Params: 306880 on epoch: 44]
2025-04-28 01:05:34,470 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:05:34,482 - 

2025-04-28 01:05:34,482 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:05:58,379 - Epoch: [45][   90/   90]    Overall Loss 0.226245    Objective Loss 0.226245    Top1 92.086331    Top5 100.000000    LR 0.001000    Time 0.265501    
2025-04-28 01:05:58,404 - --- validate (epoch=45)-----------
2025-04-28 01:05:58,404 - 2245 samples (100 per mini-batch)
2025-04-28 01:06:00,861 - Epoch: [45][   23/   23]    Loss 0.398603    Top1 89.220490    Top5 98.797327    
2025-04-28 01:06:00,888 - ==> Top1: 89.220    Top5: 98.797    Loss: 0.399

2025-04-28 01:06:00,888 - ==> Confusion:
[[ 92   0   0   0   0   1   2   0   1   0   2   0   0   0   0   0   0   1   0   3]
 [  0 110   0   0   0   1   0   1   0   0   2   1   0   0   0   1   2   1   0   1]
 [  0   1  77   0   0   2   6   0  10   0   3   0   0   0   0   1   0   1   0   2]
 [  0   0   0 132   0   1   2   0   0   1   0   0   0   7   0   0   0   0   4   2]
 [  0   0   0   0 180   5   0   0   0   0   2   0   5   0   1   1   1   0   1   2]
 [  0   0   0   0   1  68   1   0   1   0   3   0   2   0   0   1   0   1   0  10]
 [  0   0   0   0   0   0 121   0   1   0   2   0   0   0   1   1   0   0   0   2]
 [  0   0   1   0   0   0   0  98   0   0   1   0   0   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  0   1   0   1   0   1   0   1   0  71   6   1   0   2   0   0   0   0   2   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   0   1   0]
 [  0   4   0   2   0   0   0   1   0   0   2  60   0   5   0   1   1   2   0   3]
 [  0   0   0   0   0   0   0   0   0   0   2   0  78   0   1   0   1   0   1   0]
 [  0   0   0   3   0   0   0   1   0   1   1   0   0 109   0   0   0   0   0   0]
 [  0   0   1   0   0   0   2   0   0   0   2   0   3   0  50   0   0   0   1   0]
 [  0   1   0   0   1   1   0   4   1   0   0   0   0   0   0  88   0   1   1   0]
 [  0   3   0   0   1   1   0   1   0   0   6   0   0   1   0   0  46   1   3   0]
 [  1   0   1   0   0   1   0   0   2   0   3   0   0   0   0   0   0  86   2   1]
 [  1   1   0   0   0   4   1   0   0   0   3   0   1   1   0   0   0   3  89   0]
 [  2   0   2   0   0   5   3   0   3   0   2   0   0   0   1   0   0   0   0 121]]

2025-04-28 01:06:00,890 - ==> Best [Top1: 89.220   Top5: 98.797   Params: 306880 on epoch: 45]
2025-04-28 01:06:00,890 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:06:00,901 - 

2025-04-28 01:06:00,901 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:06:24,339 - Epoch: [46][   90/   90]    Overall Loss 0.226920    Objective Loss 0.226920    Top1 88.489209    Top5 100.000000    LR 0.001000    Time 0.260390    
2025-04-28 01:06:24,372 - --- validate (epoch=46)-----------
2025-04-28 01:06:24,372 - 2245 samples (100 per mini-batch)
2025-04-28 01:06:26,856 - Epoch: [46][   23/   23]    Loss 0.380322    Top1 88.953229    Top5 98.663697    
2025-04-28 01:06:26,882 - ==> Top1: 88.953    Top5: 98.664    Loss: 0.380

2025-04-28 01:06:26,883 - ==> Confusion:
[[ 89   0   1   0   0   3   1   0   0   1   0   0   0   0   2   0   0   1   1   3]
 [  0 112   1   0   0   1   0   1   0   0   1   1   0   0   0   1   1   1   0   0]
 [  0   0  95   0   1   0   2   0   3   0   0   0   0   0   0   0   0   1   0   1]
 [  0   1   2 132   0   1   0   1   0   1   1   1   0   5   0   0   0   1   2   1]
 [  0   3   1   0 177   4   0   0   0   0   0   0   6   0   3   0   1   0   1   2]
 [  0   2   2   0   0  67   0   0   2   0   0   1   0   0   2   1   2   2   0   7]
 [  0   1   5   0   0   0 111   1   3   0   2   0   0   0   1   0   0   0   0   4]
 [  0   1   0   1   0   0   0  97   0   1   0   0   0   0   0   0   0   0   2   0]
 [  0   0   2   0   0   0   0   0 213   0   0   0   0   0   0   0   0   0   0   1]
 [  0   4   0   1   0   0   0   0   0  76   2   2   0   0   0   0   1   0   0   0]
 [  0   3   1   0   0   0   2   0   1   0 101   0   0   0   0   0   1   2   1   2]
 [  0   1   0   1   0   1   0   0   0   0   0  74   0   3   0   0   0   0   0   1]
 [  0   1   0   0   0   1   0   0   0   0   1   0  75   0   2   0   0   0   1   2]
 [  0   1   0   1   0   0   0   0   0   4   0   3   0 105   0   0   0   1   0   0]
 [  0   0   2   0   0   0   1   0   0   0   0   0   5   0  51   0   0   0   0   0]
 [  0   2   0   0   3   2   0   4   1   0   0   2   0   0   0  82   0   1   1   0]
 [  0   4   0   0   0   1   0   0   0   1   0   1   0   0   0   0  53   1   2   0]
 [  0   0   0   0   0   0   1   0   1   0   1   0   0   0   0   0   3  90   1   0]
 [  0   2   2   0   0   0   2   0   1   2   0   1   0   1   1   0   0   7  83   2]
 [  1   1   3   1   0   8   4   0   4   0   1   0   0   0   0   0   0   1   1 114]]

2025-04-28 01:06:26,885 - ==> Best [Top1: 89.220   Top5: 98.797   Params: 306880 on epoch: 45]
2025-04-28 01:06:26,885 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:06:26,894 - 

2025-04-28 01:06:26,894 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:06:50,563 - Epoch: [47][   90/   90]    Overall Loss 0.236941    Objective Loss 0.236941    Top1 92.086331    Top5 100.000000    LR 0.001000    Time 0.262965    
2025-04-28 01:06:50,593 - --- validate (epoch=47)-----------
2025-04-28 01:06:50,593 - 2245 samples (100 per mini-batch)
2025-04-28 01:06:52,988 - Epoch: [47][   23/   23]    Loss 0.429480    Top1 87.706013    Top5 98.485523    
2025-04-28 01:06:53,012 - ==> Top1: 87.706    Top5: 98.486    Loss: 0.429

2025-04-28 01:06:53,013 - ==> Confusion:
[[ 98   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   2]
 [  1 111   0   0   0   2   1   1   0   1   0   0   0   0   0   1   1   0   0   1]
 [  0   0  95   0   3   1   3   0   0   0   0   0   0   0   0   0   0   1   0   0]
 [  1   1   0 125   0   8   0   0   0   0   1   2   0   4   0   1   2   0   0   4]
 [  1   0   0   0 189   4   0   0   0   0   0   0   1   0   0   0   1   0   1   1]
 [  0   0   1   0   0  76   0   0   0   0   0   0   0   0   0   1   1   0   0   9]
 [  1   0   4   0   0   0 116   0   1   0   1   0   0   0   1   0   0   0   0   4]
 [  0   6   1   0   2   2   0  88   0   1   1   0   0   0   1   0   0   0   0   0]
 [  1   0   8   0   1   0   3   0 202   0   0   0   0   0   0   0   0   0   0   1]
 [  1   3   0   0   0   2   0   0   0  75   1   0   0   1   0   0   3   0   0   0]
 [  0   2   0   0   0   1   1   0   0   0 107   0   0   0   0   0   1   0   1   1]
 [  1   4   0   0   0   2   0   0   0   0   0  70   0   1   0   0   2   0   0   1]
 [  2   0   0   0   1   1   0   0   0   0   0   0  75   0   3   0   0   0   0   1]
 [  1   9   0   3   1   3   0   1   0   4   0   8   0  80   0   0   4   0   0   1]
 [  0   0   0   0   0   1   0   0   0   0   0   0   1   0  57   0   0   0   0   0]
 [  0   2   0   0  11   3   0   2   0   1   0   0   0   0   0  77   1   1   0   0]
 [  0   2   0   0   0   4   0   0   0   0   1   1   0   0   0   0  55   0   0   0]
 [  2   2   0   0   1   1   0   0   1   0   1   0   0   0   0   0   1  85   1   2]
 [  4   2   1   0   4   8   0   0   0   2   0   0   0   0   0   0   0   5  77   1]
 [  5   0   3   0   2  12   3   0   2   0   1   0   0   0   0   0   0   0   0 111]]

2025-04-28 01:06:53,015 - ==> Best [Top1: 89.220   Top5: 98.797   Params: 306880 on epoch: 45]
2025-04-28 01:06:53,015 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:06:53,022 - 

2025-04-28 01:06:53,023 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:07:17,084 - Epoch: [48][   90/   90]    Overall Loss 0.234139    Objective Loss 0.234139    Top1 94.964029    Top5 99.280576    LR 0.001000    Time 0.267315    
2025-04-28 01:07:17,114 - --- validate (epoch=48)-----------
2025-04-28 01:07:17,114 - 2245 samples (100 per mini-batch)
2025-04-28 01:07:19,518 - Epoch: [48][   23/   23]    Loss 0.474180    Top1 85.746102    Top5 98.530067    
2025-04-28 01:07:19,543 - ==> Top1: 85.746    Top5: 98.530    Loss: 0.474

2025-04-28 01:07:19,543 - ==> Confusion:
[[ 60   0   1   2   0   0   3   0   3   0   4   0   0   0   0   0   0   0   6  23]
 [  0  93   2   0   1   1   0   2   0   2   4   5   1   0   0   8   1   0   0   0]
 [  0   0  96   0   0   0   2   0   1   0   2   0   0   0   0   1   0   0   0   1]
 [  0   0   0 141   0   0   1   0   0   1   0   1   0   1   0   2   0   0   2   0]
 [  0   0   1   0 186   0   0   0   0   0   0   0   1   0   0   7   0   0   2   1]
 [  0   1   2   1   5  46   0   0   1   0   2   0   2   0   0   4   0   0   2  22]
 [  0   1   5   0   0   1 111   0   1   0   3   0   0   0   0   1   0   0   0   5]
 [  0   0   0   3   0   0   0  79   0   1   2   0   0   0   0  15   0   0   2   0]
 [  0   0   3   0   0   0   1   0 211   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0   4   0   0   1   0   0  80   0   1   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 113   0   0   0   0   0   0   1   0   0]
 [  0   1   0   5   0   0   0   0   0   0   1  69   0   2   0   2   0   0   0   1]
 [  0   0   1   0   2   0   0   0   0   0   1   0  76   0   0   1   0   0   1   1]
 [  0   0   1   9   1   0   0   0   0   3   1   1   0  96   0   1   0   1   1   0]
 [  0   0  10   0   3   0   0   0   0   0   2   0  10   0  29   0   0   0   0   5]
 [  0   0   0   2   0   1   0   0   0   0   0   0   0   0   0  94   0   0   1   0]
 [  0   0   0   0   2   1   0   0   0   2   5   5   0   0   0   4  38   3   2   1]
 [  0   1   0   0   0   1   0   0   0   0   3   0   0   0   0   2   0  84   3   3]
 [  0   0   0   0   0   1   0   1   0   1   3   0   1   1   0   0   0   3  92   1]
 [  0   0   1   1   1   2   1   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 01:07:19,545 - ==> Best [Top1: 89.220   Top5: 98.797   Params: 306880 on epoch: 45]
2025-04-28 01:07:19,546 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:07:19,554 - 

2025-04-28 01:07:19,554 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:07:43,297 - Epoch: [49][   90/   90]    Overall Loss 0.228234    Objective Loss 0.228234    Top1 92.805755    Top5 100.000000    LR 0.001000    Time 0.263775    
2025-04-28 01:07:43,331 - --- validate (epoch=49)-----------
2025-04-28 01:07:43,332 - 2245 samples (100 per mini-batch)
2025-04-28 01:07:45,702 - Epoch: [49][   23/   23]    Loss 0.474281    Top1 86.102450    Top5 98.841871    
2025-04-28 01:07:45,728 - ==> Top1: 86.102    Top5: 98.842    Loss: 0.474

2025-04-28 01:07:45,728 - ==> Confusion:
[[ 93   0   0   0   0   0   0   2   0   0   0   0   0   0   0   0   2   1   2   2]
 [  0 111   1   0   0   0   0   2   0   1   0   2   0   0   0   1   1   0   1   0]
 [  0   2  79   0   1   1   4   0   5   0   2   0   0   0   2   0   0   0   5   2]
 [  1   1   0 107   0   2   0   1   0  14   2   4   0   5   2   0   0   0   7   3]
 [  0   3   0   0 187   3   0   0   0   0   0   0   0   0   0   0   1   0   3   1]
 [  0   1   1   0   4  65   0   0   0   2   0   0   0   0   0   1   2   0   2  10]
 [  0   4   3   0   2   1  99   0   3   0   3   0   1   0   2   1   1   0   0   8]
 [  0   1   0   1   0   0   0  97   0   0   2   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   1 211   0   0   0   0   0   0   0   0   1   2   1]
 [  0   1   0   1   0   0   0   1   0  80   0   1   0   0   0   1   1   0   0   0]
 [  0   1   0   0   1   1   0   0   2   3  99   1   0   0   0   0   0   0   5   1]
 [  0   3   0   0   0   2   0   0   0   4   1  66   0   1   0   0   1   1   1   1]
 [  0   0   0   0   2   0   0   0   0   1   0   0  73   0   1   0   0   0   5   1]
 [  0   0   0   1   0   1   0   0   0   7   0   2   0 102   0   0   0   0   2   0]
 [  0   0   0   0   3   0   0   1   0   1   0   0   4   0  48   0   0   0   2   0]
 [  0   2   0   2   5   3   0   4   0   1   1   0   0   0   0  74   2   0   3   1]
 [  0   2   0   0   2   0   0   0   0   3   0   2   0   0   0   0  51   0   3   0]
 [  1   1   1   0   0   2   0   0   0   0   3   0   0   0   1   0   6  72  10   0]
 [  0   0   0   0   1   1   0   2   0   3   1   0   0   1   0   0   0   2  93   0]
 [  1   1   0   0   1   4   1   0   0   1   1   0   0   0   1   0   1   0   1 126]]

2025-04-28 01:07:45,731 - ==> Best [Top1: 89.220   Top5: 98.797   Params: 306880 on epoch: 45]
2025-04-28 01:07:45,731 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:07:45,738 - 

2025-04-28 01:07:45,739 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:08:09,807 - Epoch: [50][   90/   90]    Overall Loss 0.215835    Objective Loss 0.215835    Top1 92.805755    Top5 100.000000    LR 0.001000    Time 0.267399    
2025-04-28 01:08:09,836 - --- validate (epoch=50)-----------
2025-04-28 01:08:09,836 - 2245 samples (100 per mini-batch)
2025-04-28 01:08:12,208 - Epoch: [50][   23/   23]    Loss 0.488342    Top1 86.191537    Top5 98.663697    
2025-04-28 01:08:12,233 - ==> Top1: 86.192    Top5: 98.664    Loss: 0.488

2025-04-28 01:08:12,233 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   2]
 [  1 109   0   0   0   0   0   2   0   2   0   0   1   0   0   1   3   0   0   1]
 [  0   0  96   0   1   1   1   0   0   0   1   0   0   0   0   0   0   0   0   3]
 [  0   0   0 129   0   0   0   0   0   2   1   2   0   2   0   2   0   0   8   3]
 [  3   0   1   0 176   3   0   0   0   0   0   0   7   0   0   0   1   2   0   5]
 [  2   2   2   0   1  52   0   2   0   1   2   0   1   0   0   1   1   1   0  20]
 [  1   2  14   0   0   0  96   0   1   0   0   0   1   0   0   1   0   1   0  11]
 [  0   1   0   1   0   0   0  97   0   1   0   0   0   0   0   1   0   0   0   1]
 [  9   0  10   0   0   0   0   0 196   0   0   0   0   0   0   0   0   0   0   1]
 [  1   0   0   1   0   1   0   0   0  79   0   0   0   0   0   0   3   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0 106   0   0   0   0   0   0   3   0   5]
 [  1   2   0   2   0   1   0   0   0   2   3  58   0   2   0   0   8   1   0   1]
 [  1   0   0   0   1   1   0   0   0   0   1   0  78   0   0   0   0   0   1   0]
 [  0   1   0   8   0   0   0   0   0   6   1   1   0  94   0   0   1   0   1   2]
 [  3   0   1   0   1   0   0   0   0   1   2   0  15   0  31   0   0   0   2   3]
 [  0   1   0   1   4   1   0   3   0   0   0   0   0   0   0  86   0   0   2   0]
 [  0   0   0   0   0   2   0   0   0   2   2   0   1   0   0   0  50   4   1   1]
 [  2   0   0   0   0   0   0   0   1   1   2   0   0   0   0   0   1  88   1   1]
 [  1   0   1   0   0   1   0   1   0   2   2   0   1   1   0   0   0   1  87   6]
 [  2   0   1   0   2   3   0   0   0   0   2   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:08:12,235 - ==> Best [Top1: 89.220   Top5: 98.797   Params: 306880 on epoch: 45]
2025-04-28 01:08:12,235 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:08:12,243 - 

2025-04-28 01:08:12,243 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:08:35,654 - Epoch: [51][   90/   90]    Overall Loss 0.203957    Objective Loss 0.203957    Top1 87.050360    Top5 100.000000    LR 0.001000    Time 0.260092    
2025-04-28 01:08:35,683 - --- validate (epoch=51)-----------
2025-04-28 01:08:35,683 - 2245 samples (100 per mini-batch)
2025-04-28 01:08:37,962 - Epoch: [51][   23/   23]    Loss 0.414527    Top1 88.151448    Top5 98.930958    
2025-04-28 01:08:37,985 - ==> Top1: 88.151    Top5: 98.931    Loss: 0.415

2025-04-28 01:08:37,985 - ==> Confusion:
[[ 80   0   0   0   0   5   0   0   1   0   0   0   0   0   2   0   0   0   0  14]
 [  0  97   2   1   0   8   2   1   1   1   1   1   0   0   0   3   1   0   1   0]
 [  0   0  93   0   1   1   2   0   3   0   0   0   0   0   0   1   0   0   0   2]
 [  0   0   0 132   0   2   0   0   0   0   1   0   0   4   0   4   0   0   2   4]
 [  0   0   0   0 186   5   0   0   0   0   0   0   2   0   2   1   0   0   0   2]
 [  0   0   0   0   1  71   0   0   1   0   0   0   1   0   0   1   1   0   0  12]
 [  0   0   2   0   0   3 105   0   2   0   1   0   0   0   2   1   0   0   0  12]
 [  0   2   1   0   0   2   0  83   0   2   2   0   0   1   0   9   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   0   1]
 [  1   0   0   2   0   2   0   0   0  79   0   1   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   2   1 104   1   0   0   0   1   0   0   1   4]
 [  0   1   0   0   0   2   0   0   0   0   1  73   0   2   0   1   0   0   0   1]
 [  0   0   1   0   1   3   0   0   0   0   0   0  74   0   2   0   0   0   1   1]
 [  0   0   0   3   0   2   0   0   0   2   1   2   0 105   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   1   0  54   0   0   0   0   4]
 [  0   1   0   3   3   0   0   0   0   0   0   0   0   0   0  91   0   0   0   0]
 [  0   0   0   0   0   4   0   0   0   1   3   2   0   0   0   0  52   1   0   0]
 [  0   1   0   0   3   3   0   0   1   0   3   0   0   0   1   1   1  80   1   2]
 [  0   0   1   0   2   7   0   0   0   1   8   0   1   2   2   0   1   4  74   1]
 [  0   0   1   0   1   4   0   0   1   0   1   0   0   0   0   0   0   0   0 131]]

2025-04-28 01:08:37,987 - ==> Best [Top1: 89.220   Top5: 98.797   Params: 306880 on epoch: 45]
2025-04-28 01:08:37,987 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:08:37,995 - 

2025-04-28 01:08:37,995 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:09:00,807 - Epoch: [52][   90/   90]    Overall Loss 0.194453    Objective Loss 0.194453    Top1 94.244604    Top5 100.000000    LR 0.001000    Time 0.253445    
2025-04-28 01:09:00,836 - --- validate (epoch=52)-----------
2025-04-28 01:09:00,836 - 2245 samples (100 per mini-batch)
2025-04-28 01:09:03,169 - Epoch: [52][   23/   23]    Loss 0.378121    Top1 89.844098    Top5 98.663697    
2025-04-28 01:09:03,191 - ==> Top1: 89.844    Top5: 98.664    Loss: 0.378

2025-04-28 01:09:03,191 - ==> Confusion:
[[ 94   0   0   3   0   1   0   1   1   0   0   0   0   0   1   0   0   0   0   1]
 [  0 103   0   1   0   1   2   1   0   1   0   3   0   2   0   2   2   0   0   2]
 [  0   1  93   1   0   0   2   0   3   0   1   0   0   0   1   1   0   0   0   0]
 [  0   0   0 143   0   0   0   0   0   0   0   2   0   4   0   0   0   0   0   0]
 [  0   1   0   2 184   3   1   0   0   0   0   1   1   0   2   0   1   0   0   2]
 [  2   1   0   3   1  65   0   0   0   0   1   0   0   0   0   1   1   0   0  13]
 [  2   0   3   2   0   0 117   0   1   0   1   0   0   0   2   0   0   0   0   0]
 [  0   0   0   3   0   1   0  95   0   1   1   0   0   0   0   1   0   0   0   0]
 [  3   0   0   1   0   2   0   0 204   0   0   0   0   0   0   0   2   0   4   0]
 [  1   1   0   6   0   1   0   0   0  75   0   1   0   1   0   0   0   0   0   0]
 [  0   1   0   1   0   0   0   0   0   0 106   1   0   0   0   0   1   1   0   3]
 [  0   1   0   2   0   0   0   0   0   0   0  76   0   2   0   0   0   0   0   0]
 [  1   0   0   0   2   1   0   0   0   0   2   0  75   0   2   0   0   0   0   0]
 [  0   0   0   7   0   0   0   0   0   2   0   3   0 103   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   3   2   1   0   0   0   0   0   0   0   0   0  89   1   0   1   0]
 [  0   1   0   0   0   0   1   0   0   0   0   7   0   0   0   0  52   0   0   2]
 [  3   1   0   1   0   0   0   1   1   1   1   0   0   0   0   0   2  86   0   0]
 [  2   0   1   2   0   2   0   0   0   1   3   0   1   2   0   0   2   2  84   2]
 [  7   0   0   4   0   5   2   0   0   0   3   0   0   0   1   0   1   0   0 116]]

2025-04-28 01:09:03,193 - ==> Best [Top1: 89.844   Top5: 98.664   Params: 306880 on epoch: 52]
2025-04-28 01:09:03,194 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:09:03,204 - 

2025-04-28 01:09:03,204 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:09:26,035 - Epoch: [53][   90/   90]    Overall Loss 0.207846    Objective Loss 0.207846    Top1 89.928058    Top5 100.000000    LR 0.001000    Time 0.253648    
2025-04-28 01:09:26,060 - --- validate (epoch=53)-----------
2025-04-28 01:09:26,060 - 2245 samples (100 per mini-batch)
2025-04-28 01:09:28,341 - Epoch: [53][   23/   23]    Loss 0.409950    Top1 88.151448    Top5 99.109131    
2025-04-28 01:09:28,367 - ==> Top1: 88.151    Top5: 99.109    Loss: 0.410

2025-04-28 01:09:28,367 - ==> Confusion:
[[100   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   0   0]
 [  0 112   1   0   0   0   0   1   0   0   1   0   0   1   0   2   2   0   0   0]
 [  0   1  94   0   1   0   3   0   1   0   2   0   0   0   0   0   0   1   0   0]
 [  1   1   2 133   0   2   2   0   0   3   0   1   0   1   0   0   0   0   3   0]
 [  0   3   1   0 184   1   0   0   0   0   1   0   3   0   1   1   1   1   1   0]
 [  1   8   0   0   2  58   1   0   0   2   1   1   0   0   0   1   2   3   0   8]
 [  0   1   3   1   0   1 116   0   1   0   3   0   0   0   0   1   0   0   0   1]
 [  1   1   1   0   0   0   0  98   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   4   0   0   0   1   0 208   0   1   0   0   0   0   0   0   2   0   0]
 [  1   1   0   1   0   0   0   0   0  80   0   1   0   0   0   0   2   0   0   0]
 [  0   2   0   1   0   0   0   0   0   3 103   0   0   0   0   1   0   4   0   0]
 [  1   4   0   2   0   0   0   0   0   1   1  69   0   2   0   0   1   0   0   0]
 [  1   1   0   0   0   1   0   0   0   0   1   0  79   0   0   0   0   0   0   0]
 [  0   2   0  10   0   0   0   0   0  11   0   0   0  91   0   0   1   0   0   0]
 [  0   0   1   0   0   0   1   0   0   1   1   0  21   0  33   0   0   0   1   0]
 [  0   3   0   3   1   0   0   3   0   0   0   0   0   0   0  87   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   1   0   1   1   0   0   0  53   3   2   0]
 [  1   2   0   0   0   0   0   0   1   0   1   0   0   0   0   0   1  88   3   0]
 [  2   2   0   0   0   1   0   0   0   2   0   0   1   1   0   0   0   3  91   1]
 [  7   3   6   1   2   9   3   0   1   0   3   0   0   0   0   0   0   1   1 102]]

2025-04-28 01:09:28,370 - ==> Best [Top1: 89.844   Top5: 98.664   Params: 306880 on epoch: 52]
2025-04-28 01:09:28,370 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:09:28,377 - 

2025-04-28 01:09:28,377 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:09:51,114 - Epoch: [54][   90/   90]    Overall Loss 0.198556    Objective Loss 0.198556    Top1 92.086331    Top5 100.000000    LR 0.001000    Time 0.252607    
2025-04-28 01:09:51,144 - --- validate (epoch=54)-----------
2025-04-28 01:09:51,144 - 2245 samples (100 per mini-batch)
2025-04-28 01:09:53,456 - Epoch: [54][   23/   23]    Loss 0.369530    Top1 89.265033    Top5 98.886414    
2025-04-28 01:09:53,482 - ==> Top1: 89.265    Top5: 98.886    Loss: 0.370

2025-04-28 01:09:53,482 - ==> Confusion:
[[ 90   0   0   0   1   2   0   1   1   0   1   0   0   1   0   0   0   1   0   4]
 [  0 104   2   0   0   1   0   1   0   0   1   2   0   4   0   3   1   1   0   0]
 [  0   0  95   0   3   0   1   0   2   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0 135   0   0   0   0   0   2   0   3   0   8   0   1   0   0   0   0]
 [  0   0   0   0 192   0   0   1   0   0   0   0   0   0   2   1   0   0   1   1]
 [  0   0   1   1   2  71   0   0   0   0   4   0   1   0   0   1   0   2   0   5]
 [  0   0   3   1   0   1 112   0   1   0   5   0   0   0   1   0   0   1   0   3]
 [  0   0   1   1   0   1   0  95   0   1   2   1   0   0   0   0   0   0   0   0]
 [  0   0   4   0   0   0   0   0 209   0   1   0   0   0   0   0   1   1   0   0]
 [  0   1   0   4   0   1   0   0   0  77   1   1   0   0   0   0   1   0   0   0]
 [  0   0   0   1   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   1   0   0   0   0   0   0   1  76   0   2   0   0   0   0   0   0]
 [  0   0   1   0   2   1   0   0   0   0   2   0  74   0   3   0   0   0   0   0]
 [  0   1   0   3   0   0   0   0   0   2   1   1   0 107   0   0   0   0   0   0]
 [  0   0   0   0   3   0   0   0   0   2   1   0   4   0  48   0   0   0   0   1]
 [  0   1   0   3   2   1   0   3   0   0   0   0   0   0   0  88   0   0   0   0]
 [  0   1   0   1   0   0   0   0   0   1   1   5   1   0   0   0  49   3   1   0]
 [  0   1   0   0   0   1   0   0   1   0   4   0   0   1   0   0   0  87   1   1]
 [  1   0   1   4   2   5   0   0   0   2   7   2   0   3   0   0   0   6  70   1]
 [  0   1   5   2   1   6   0   0   0   0  10   0   0   0   0   0   1   0   0 113]]

2025-04-28 01:09:53,484 - ==> Best [Top1: 89.844   Top5: 98.664   Params: 306880 on epoch: 52]
2025-04-28 01:09:53,484 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:09:53,492 - 

2025-04-28 01:09:53,492 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:10:16,220 - Epoch: [55][   90/   90]    Overall Loss 0.178376    Objective Loss 0.178376    Top1 94.964029    Top5 100.000000    LR 0.001000    Time 0.252514    
2025-04-28 01:10:16,251 - --- validate (epoch=55)-----------
2025-04-28 01:10:16,251 - 2245 samples (100 per mini-batch)
2025-04-28 01:10:18,581 - Epoch: [55][   23/   23]    Loss 0.419078    Top1 88.997773    Top5 98.574610    
2025-04-28 01:10:18,606 - ==> Top1: 88.998    Top5: 98.575    Loss: 0.419

2025-04-28 01:10:18,607 - ==> Confusion:
[[ 95   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   5]
 [  0 113   1   0   0   0   1   3   0   0   1   0   0   1   0   0   0   0   0   0]
 [  0   1  95   0   1   0   1   0   2   0   2   0   0   0   0   0   0   0   0   1]
 [  0   4   1 120   0   4   3   4   0   0   2   0   0   2   0   0   0   0   4   5]
 [  0   1   0   0 190   1   0   1   0   0   0   0   1   0   1   0   1   0   1   1]
 [  0   5   0   0   3  59   0   0   0   1   1   0   0   0   0   1   0   1   0  17]
 [  0   1   3   0   1   0 115   0   3   0   1   0   0   0   0   0   0   1   0   3]
 [  0   0   0   0   0   0   0  98   0   0   2   0   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   1   0   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   1   0   1   1   0   0  78   2   1   0   0   0   0   1   0   0   0]
 [  0   1   1   0   0   0   0   0   1   0 109   0   0   0   0   0   0   1   0   1]
 [  0   3   0   2   0   0   0   0   0   0   1  72   0   0   0   0   0   0   0   3]
 [  0   0   0   0   2   2   0   0   0   0   0   0  78   0   0   0   0   0   0   1]
 [  0   2   0   3   0   1   0   0   0   6   1   1   0  98   0   0   0   0   2   1]
 [  0   0   4   0   2   0   1   0   0   0   4   0   8   0  33   0   1   0   1   5]
 [  0   1   0   1   2   2   0   5   0   0   1   1   0   0   0  85   0   0   0   0]
 [  0   1   0   0   1   1   0   1   0   1   1   1   0   0   0   0  53   2   1   0]
 [  1   2   0   0   1   2   0   0   1   0   5   0   0   0   0   0   0  83   2   0]
 [  0   0   1   0   0   4   0   1   0   2   7   0   0   1   0   0   2   4  80   2]
 [  1   0   1   0   0   2   2   0   1   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:10:18,609 - ==> Best [Top1: 89.844   Top5: 98.664   Params: 306880 on epoch: 52]
2025-04-28 01:10:18,609 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:10:18,616 - 

2025-04-28 01:10:18,617 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:10:41,302 - Epoch: [56][   90/   90]    Overall Loss 0.184664    Objective Loss 0.184664    Top1 89.928058    Top5 100.000000    LR 0.001000    Time 0.252028    
2025-04-28 01:10:41,328 - --- validate (epoch=56)-----------
2025-04-28 01:10:41,328 - 2245 samples (100 per mini-batch)
2025-04-28 01:10:43,647 - Epoch: [56][   23/   23]    Loss 0.393448    Top1 89.265033    Top5 98.841871    
2025-04-28 01:10:43,669 - ==> Top1: 89.265    Top5: 98.842    Loss: 0.393

2025-04-28 01:10:43,670 - ==> Confusion:
[[ 94   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   2   1   3]
 [  0 110   0   0   0   0   0   2   0   0   1   0   0   1   0   0   5   0   0   1]
 [  0   0  95   0   3   0   2   0   1   0   0   0   0   0   1   0   0   0   1   0]
 [  0   1   0 131   0   1   0   0   0   0   0   1   0   9   0   0   0   0   5   1]
 [  0   0   0   0 195   0   0   0   0   0   0   0   1   0   0   0   1   0   1   0]
 [  0   1   0   0   4  71   0   0   0   1   0   0   0   0   0   0   1   1   0   9]
 [  0   1   0   1   1   2 110   0   1   0   1   0   0   0   1   1   0   0   0   9]
 [  0   1   0   2   0   1   0  95   0   1   0   0   0   1   0   0   0   0   1   0]
 [  2   1   2   0   0   1   0   0 205   0   0   0   0   0   0   0   0   0   4   1]
 [  1   1   0   1   0   2   0   0   0  77   0   1   0   1   0   0   1   0   1   0]
 [  2   2   0   1   0   2   1   0   0   1  91   0   0   0   0   0   3   2   2   7]
 [  0   4   0   0   1   0   0   0   0   0   0  65   0   3   0   0   4   0   2   2]
 [  0   0   0   0   4   0   0   0   0   0   0   0  77   0   0   0   1   0   1   0]
 [  0   0   0   2   0   0   0   0   0   3   0   0   0 107   0   0   2   0   0   1]
 [  0   1   1   0   5   0   0   0   0   0   0   0   4   0  45   0   0   0   1   2]
 [  0   3   0   2   7   2   0   2   0   0   0   0   0   2   0  77   1   0   2   0]
 [  0   0   0   0   3   1   0   0   0   1   0   1   1   0   0   0  53   1   1   1]
 [  1   0   0   0   0   1   0   0   0   0   2   1   0   0   0   0   4  84   4   0]
 [  1   0   0   0   0   0   0   0   0   1   0   0   0   1   0   0   2   3  93   3]
 [  2   0   0   0   1   4   1   0   0   1   0   0   0   0   0   0   1   0   0 129]]

2025-04-28 01:10:43,672 - ==> Best [Top1: 89.844   Top5: 98.664   Params: 306880 on epoch: 52]
2025-04-28 01:10:43,672 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:10:43,680 - 

2025-04-28 01:10:43,680 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:11:06,512 - Epoch: [57][   90/   90]    Overall Loss 0.181299    Objective Loss 0.181299    Top1 91.366906    Top5 100.000000    LR 0.001000    Time 0.253665    
2025-04-28 01:11:06,539 - --- validate (epoch=57)-----------
2025-04-28 01:11:06,539 - 2245 samples (100 per mini-batch)
2025-04-28 01:11:08,868 - Epoch: [57][   23/   23]    Loss 0.394124    Top1 89.398664    Top5 98.886414    
2025-04-28 01:11:08,893 - ==> Top1: 89.399    Top5: 98.886    Loss: 0.394

2025-04-28 01:11:08,894 - ==> Confusion:
[[ 76   0   5   0   0   2   2   0   0   0   1   0   1   0   5   0   0   1   1   8]
 [  0 111   2   0   0   0   0   1   2   0   0   0   1   1   0   0   2   0   0   0]
 [  0   0 100   0   1   0   0   0   0   0   1   0   0   0   1   0   0   0   0   0]
 [  0   2   4 128   0   1   0   0   1   0   0   3   0   3   0   0   3   0   2   2]
 [  0   0   1   0 182   1   0   0   0   0   0   0   6   0   6   0   0   0   1   1]
 [  0   0   1   0   1  72   0   0   0   0   0   0   0   0   1   1   0   0   1  11]
 [  0   0  11   1   0   2 106   0   0   0   1   0   0   0   4   0   0   0   0   3]
 [  0   2   1   1   0   1   0  93   0   0   1   0   0   0   0   1   0   1   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   4   1   2   0   1   0   0   0  73   0   0   0   0   0   0   4   1   0   0]
 [  0   1   0   0   0   0   0   0   1   0 105   0   0   0   2   1   0   2   1   1]
 [  0   4   0   0   0   1   0   0   0   0   2  63   0   2   0   0   6   2   0   1]
 [  1   0   0   0   0   0   0   0   0   0   0   0  79   0   3   0   0   0   0   0]
 [  0   3   1   3   0   1   0   0   0   1   0   2   0 100   0   0   2   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   0   0   1   1   2   0   1   1   0   0   1   0   0   0  90   1   0   0   0]
 [  0   3   0   0   1   1   0   0   0   0   0   1   0   0   0   1  53   2   1   0]
 [  0   1   2   0   0   0   0   0   0   0   3   0   0   0   1   0   1  86   3   0]
 [  0   0   1   0   0   1   0   0   0   2   0   0   1   1   2   0   0   4  92   0]
 [  0   0   4   0   0   3   1   0   2   0   2   0   0   0   1   0   0   0   0 126]]

2025-04-28 01:11:08,895 - ==> Best [Top1: 89.844   Top5: 98.664   Params: 306880 on epoch: 52]
2025-04-28 01:11:08,896 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:11:08,903 - 

2025-04-28 01:11:08,903 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:11:31,706 - Epoch: [58][   90/   90]    Overall Loss 0.177864    Objective Loss 0.177864    Top1 95.683453    Top5 100.000000    LR 0.001000    Time 0.253339    
2025-04-28 01:11:31,735 - --- validate (epoch=58)-----------
2025-04-28 01:11:31,735 - 2245 samples (100 per mini-batch)
2025-04-28 01:11:34,014 - Epoch: [58][   23/   23]    Loss 0.375084    Top1 90.913140    Top5 98.708241    
2025-04-28 01:11:34,037 - ==> Top1: 90.913    Top5: 98.708    Loss: 0.375

2025-04-28 01:11:34,037 - ==> Confusion:
[[ 97   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   3]
 [  1 106   1   1   0   0   2   3   1   1   0   0   0   0   1   1   1   1   0   0]
 [  0   0  96   0   2   0   3   0   1   0   0   0   1   0   0   0   0   0   0   0]
 [  0   0   1 139   0   0   0   1   0   1   0   0   0   2   0   0   0   0   2   3]
 [  0   1   0   0 179   0   0   0   0   0   0   0  10   0   7   0   0   0   0   1]
 [  1   2   1   0   1  74   0   0   0   0   0   0   0   0   1   1   0   0   0   7]
 [  1   0   0   0   1   0 120   0   1   0   1   0   1   0   2   0   0   0   0   1]
 [  0   0   0   0   0   0   0  98   0   0   1   0   0   0   1   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   2   0   1   1   0   0  78   0   1   0   2   0   0   1   0   0   0]
 [  0   1   1   0   0   0   0   0   1   0 109   0   0   0   1   0   0   1   0   0]
 [  0   1   0   2   0   1   1   0   0   0   1  74   0   1   0   0   0   0   0   0]
 [  1   0   0   0   0   1   0   0   0   0   0   0  80   0   1   0   0   0   0   0]
 [  0   0   0   5   1   1   0   0   1   3   0   0   0 104   0   0   0   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   1   0   4   0  53   0   0   0   0   0]
 [  0   0   0   2   2   1   0   1   1   0   0   1   1   0   3  85   0   0   1   0]
 [  0   1   0   1   2   2   1   2   0   0   1   2   0   1   1   0  47   1   1   0]
 [  2   0   4   1   0   2   0   0   1   0   1   0   0   0   1   0   1  83   1   0]
 [  2   0   0   1   1   2   0   0   1   1   6   1   0   1   2   0   1   2  80   3]
 [  4   0   1   0   1   5   2   0   2   0   1   0   0   0   0   0   0   0   0 123]]

2025-04-28 01:11:34,039 - ==> Best [Top1: 90.913   Top5: 98.708   Params: 306880 on epoch: 58]
2025-04-28 01:11:34,039 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:11:34,050 - 

2025-04-28 01:11:34,050 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:11:56,959 - Epoch: [59][   90/   90]    Overall Loss 0.164467    Objective Loss 0.164467    Top1 90.647482    Top5 100.000000    LR 0.001000    Time 0.254513    
2025-04-28 01:11:56,987 - --- validate (epoch=59)-----------
2025-04-28 01:11:56,987 - 2245 samples (100 per mini-batch)
2025-04-28 01:11:59,272 - Epoch: [59][   23/   23]    Loss 0.398038    Top1 89.398664    Top5 98.975501    
2025-04-28 01:11:59,293 - ==> Top1: 89.399    Top5: 98.976    Loss: 0.398

2025-04-28 01:11:59,294 - ==> Confusion:
[[ 90   0   0   0   0   2   2   0   0   0   0   0   0   0   1   0   1   1   3   2]
 [  0 110   1   0   0   0   1   1   0   0   2   0   0   0   0   0   3   2   0   0]
 [  0   2  77   0   2   1   9   0   4   0   1   0   0   0   3   0   0   0   1   3]
 [  0   3   0 111   0   9   3   2   2   0   0   3   0   4   0   0   1   0   8   3]
 [  0   0   0   0 192   2   0   0   0   0   0   0   1   0   1   0   1   0   0   1]
 [  0   0   0   0   1  76   0   0   0   0   0   0   1   0   0   1   2   0   0   7]
 [  0   0   0   0   0   2 116   0   2   0   1   0   0   0   1   0   0   0   0   6]
 [  0   2   0   0   0   1   0  94   0   1   2   0   0   0   0   0   0   0   2   0]
 [  0   0   0   0   0   0   2   0 214   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   1   0   4   0   0   0  76   1   0   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   1   0 108   0   0   0   0   0   0   3   0   1]
 [  1   2   0   0   0   1   0   1   0   0   0  68   0   0   0   0   6   1   0   1]
 [  0   0   0   0   1   2   0   0   0   0   0   0  76   0   3   0   0   0   1   0]
 [  1   2   0   2   0   3   0   0   0   3   1   2   0  97   0   0   1   0   1   2]
 [  0   0   0   0   1   0   1   0   0   0   0   0   5   0  52   0   0   0   0   0]
 [  0   1   0   1   6   1   0   0   1   0   0   0   0   0   0  87   1   0   0   0]
 [  0   2   0   0   0   1   0   0   0   0   0   1   0   0   0   0  55   1   2   1]
 [  0   0   0   0   1   1   0   0   0   0   2   0   0   0   0   0   1  87   5   0]
 [  0   0   0   0   0   2   0   0   0   1   0   0   1   1   0   0   1   3  95   0]
 [  1   0   0   0   0   6   2   0   0   0   3   0   0   0   0   0   0   0   1 126]]

2025-04-28 01:11:59,296 - ==> Best [Top1: 90.913   Top5: 98.708   Params: 306880 on epoch: 58]
2025-04-28 01:11:59,296 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:11:59,303 - 

2025-04-28 01:11:59,303 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:12:22,280 - Epoch: [60][   90/   90]    Overall Loss 0.163417    Objective Loss 0.163417    Top1 94.244604    Top5 99.280576    LR 0.001000    Time 0.255274    
2025-04-28 01:12:22,308 - --- validate (epoch=60)-----------
2025-04-28 01:12:22,308 - 2245 samples (100 per mini-batch)
2025-04-28 01:12:24,592 - Epoch: [60][   23/   23]    Loss 0.510088    Top1 86.280624    Top5 98.040089    
2025-04-28 01:12:24,616 - ==> Top1: 86.281    Top5: 98.040    Loss: 0.510

2025-04-28 01:12:24,616 - ==> Confusion:
[[ 97   0   0   0   0   0   1   0   0   0   0   0   0   0   1   0   0   0   0   3]
 [  0 105   0   0   0   0   0   3   0   0   4   0   0   2   0   0   4   0   1   1]
 [  0   0  90   0   1   0   4   0   5   0   1   0   0   0   0   0   0   0   1   1]
 [  1   0   2 112   0   0   1   1   2   4   1   4   0  12   0   1   0   0   2   6]
 [  1   1   0   0 178   1   1   0   0   0   0   0   2   0   5   0   1   0   6   2]
 [  2   1   1   0   0  45   2   1   0   2   3   0   1   0   1   1   0   0   3  25]
 [  2   0   0   0   0   0 118   0   2   0   2   0   0   0   0   0   0   0   0   4]
 [  0   0   0   0   0   0   0  98   1   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   1   0   0   1   0   0  77   3   1   0   2   0   0   0   0   0   0]
 [  0   1   0   0   0   0   1   0   0   0 111   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   2   0   0   1  74   0   1   0   0   0   0   0   1]
 [  1   0   0   0   1   0   0   0   0   1   7   0  66   0   4   0   0   0   0   3]
 [  0   0   0   0   0   0   1   1   0   3   1   1   0 103   0   0   0   0   2   3]
 [  1   0   2   0   0   0   1   0   1   1   1   0   2   0  48   0   0   0   1   1]
 [  0   1   0   0   6   1   0  15   3   1   3   1   0   1   0  63   0   0   3   0]
 [  0   3   0   0   0   1   0   0   0   0   4   1   0   2   0   0  44   5   2   1]
 [  1   0   0   0   0   1   0   0   1   0   4   0   0   0   0   0   0  84   4   2]
 [  0   0   0   0   0   0   0   0   1   2   2   0   0   2   0   0   0   7  86   4]
 [  4   0   0   0   0   2   4   0   3   0   3   0   0   0   0   0   0   0   0 123]]

2025-04-28 01:12:24,618 - ==> Best [Top1: 90.913   Top5: 98.708   Params: 306880 on epoch: 58]
2025-04-28 01:12:24,618 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:12:24,626 - 

2025-04-28 01:12:24,626 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:12:47,469 - Epoch: [61][   90/   90]    Overall Loss 0.183372    Objective Loss 0.183372    Top1 93.525180    Top5 100.000000    LR 0.001000    Time 0.253779    
2025-04-28 01:12:47,499 - --- validate (epoch=61)-----------
2025-04-28 01:12:47,499 - 2245 samples (100 per mini-batch)
2025-04-28 01:12:49,825 - Epoch: [61][   23/   23]    Loss 0.518743    Top1 85.968820    Top5 98.351893    
2025-04-28 01:12:49,849 - ==> Top1: 85.969    Top5: 98.352    Loss: 0.519

2025-04-28 01:12:49,850 - ==> Confusion:
[[ 88   0   2   0   0   0   4   0   3   0   1   0   0   0   0   0   0   0   0   4]
 [  0 101   0   1   0   2   1   1   0   3   1   2   0   1   0   1   2   1   1   2]
 [  0   0  73   0   0   0  18   0  10   0   0   0   0   0   0   0   0   0   0   2]
 [  0   0   1 135   0   0   3   0   0   3   0   0   0   4   0   0   0   0   1   2]
 [  2   3   1   0 158   3   7   0   1   1   4   0   5   0   2   2   1   0   0   8]
 [  0   0   0   1   1  53   2   0   0   0   1   0   0   0   0   1   2   0   0  27]
 [  0   0   0   0   0   0 122   0   1   0   3   0   0   0   0   0   0   0   0   2]
 [  0   0   0   3   0   1   0  94   0   1   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   2   0   1   1   0   0  79   2   1   0   0   0   0   0   0   0   0]
 [  0   1   0   0   0   0   1   0   0   2 106   0   0   0   0   0   1   0   0   3]
 [  2   1   0   0   0   0   0   0   0   1   0  73   0   2   0   0   0   0   0   2]
 [  1   0   1   0   0   1   1   0   0   0   6   0  64   0   1   0   1   0   0   7]
 [  0   0   0   5   0   0   0   0   0   5   1   0   0 103   0   0   0   0   0   1]
 [  0   0   1   0   0   0   5   0   1   0   4   0   1   0  43   0   0   0   0   4]
 [  0   1   0   0   2   1   0   1   2   0   4   2   0   2   2  79   0   0   2   0]
 [  1   0   0   0   0   1   0   0   1   1   3   2   0   0   0   0  47   3   1   3]
 [  0   0   2   2   0   3   0   0   0   0   2   1   0   0   0   0   0  80   3   4]
 [  0   0   1   0   0   1   2   0   0   1   4   1   0   2   0   0   0   2  84   6]
 [  0   0   0   0   0   2   2   0   2   0   1   0   0   0   0   0   0   0   0 132]]

2025-04-28 01:12:49,851 - ==> Best [Top1: 90.913   Top5: 98.708   Params: 306880 on epoch: 58]
2025-04-28 01:12:49,852 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:12:49,859 - 

2025-04-28 01:12:49,860 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:13:12,894 - Epoch: [62][   90/   90]    Overall Loss 0.179454    Objective Loss 0.179454    Top1 94.964029    Top5 100.000000    LR 0.001000    Time 0.255911    
2025-04-28 01:13:12,920 - --- validate (epoch=62)-----------
2025-04-28 01:13:12,920 - 2245 samples (100 per mini-batch)
2025-04-28 01:13:15,253 - Epoch: [62][   23/   23]    Loss 0.394884    Top1 88.997773    Top5 98.708241    
2025-04-28 01:13:15,276 - ==> Top1: 88.998    Top5: 98.708    Loss: 0.395

2025-04-28 01:13:15,276 - ==> Confusion:
[[ 81   0   0   1   0   0   2   0   0   0   1   0   0   0   0   0   1   1  10   5]
 [  0  99   1   0   0   0   0   4   0   0   1   3   0   0   0   1   5   1   5   0]
 [  0   0  87   0   1   1  12   0   0   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0 138   0   1   0   1   0   0   0   1   0   1   0   1   0   0   6   0]
 [  0   1   0   0 170   4   1   1   0   0   2   0   1   0   0   5   0   0  11   2]
 [  0   0   2   0   1  65   1   2   0   0   0   0   1   0   0   0   0   1   4  11]
 [  0   0   0   0   0   0 123   0   0   0   1   0   1   0   0   0   0   0   1   2]
 [  0   0   1   1   0   0   0  98   0   0   0   0   0   0   0   1   0   0   1   0]
 [  0   0   1   0   0   0   3   0 212   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   5   0   1   0   0   0  76   0   1   0   0   0   0   1   0   2   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   1   1   0]
 [  1   2   0   0   0   0   0   2   0   0   2  71   0   0   0   0   1   0   1   1]
 [  1   0   0   0   0   0   0   0   0   1   0   0  81   0   0   0   0   0   0   0]
 [  0   0   0  10   2   0   0   0   0   2   1   4   0  88   0   0   2   1   5   0]
 [  0   0   1   0   0   0   0   1   0   0   1   0   3   0  48   1   0   0   3   1]
 [  0   1   0   2   0   0   0   4   0   0   0   0   0   0   0  89   0   0   2   0]
 [  0   0   0   0   0   1   0   0   0   1   2   2   0   0   0   0  54   1   2   0]
 [  0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  87   6   2]
 [  0   0   0   0   0   1   0   0   0   1   0   0   1   1   0   0   0   1  97   2]
 [  0   0   1   0   1   5   3   0   1   0   1   0   0   0   0   1   0   1   2 123]]

2025-04-28 01:13:15,278 - ==> Best [Top1: 90.913   Top5: 98.708   Params: 306880 on epoch: 58]
2025-04-28 01:13:15,278 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:13:15,286 - 

2025-04-28 01:13:15,286 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:13:38,291 - Epoch: [63][   90/   90]    Overall Loss 0.164343    Objective Loss 0.164343    Top1 91.366906    Top5 100.000000    LR 0.001000    Time 0.255586    
2025-04-28 01:13:38,318 - --- validate (epoch=63)-----------
2025-04-28 01:13:38,318 - 2245 samples (100 per mini-batch)
2025-04-28 01:13:40,637 - Epoch: [63][   23/   23]    Loss 0.397502    Top1 89.309577    Top5 98.930958    
2025-04-28 01:13:40,663 - ==> Top1: 89.310    Top5: 98.931    Loss: 0.398

2025-04-28 01:13:40,663 - ==> Confusion:
[[ 68   1   0   3   0   0   1   0   1   1   4   0   0   0   1   0   1   0   8  13]
 [  0 107   1   0   0   0   0   0   0   1   2   4   0   1   0   2   2   0   0   0]
 [  0   0  89   0   1   0   4   0   2   0   5   0   0   0   0   1   0   0   0   1]
 [  0   0   0 141   0   0   0   0   0   0   0   1   0   4   0   2   1   0   0   0]
 [  0   0   1   1 184   0   0   0   0   1   2   0   2   0   0   4   1   0   1   1]
 [  0   1   0   3   1  64   0   0   0   0   0   0   1   0   0   3   2   0   1  12]
 [  0   0   3   1   0   0 110   0   1   0   4   0   0   0   2   1   0   1   0   5]
 [  0   0   0   2   0   0   0  91   0   1   2   0   0   1   0   3   0   0   1   1]
 [  0   0   1   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   3   0   0   1   0   0  79   0   2   0   1   0   0   0   0   0   0]
 [  0   2   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   1   0   0]
 [  0   1   0   1   0   0   0   0   0   0   0  74   0   2   0   0   2   0   0   1]
 [  0   0   0   0   1   0   0   0   0   0   3   0  76   0   0   1   0   0   0   2]
 [  0   0   0   3   0   0   0   0   0   4   0   0   0 107   0   0   0   0   0   1]
 [  0   0   5   0   0   0   0   0   0   1   3   0   0   0  47   1   0   0   1   1]
 [  0   0   0   1   0   0   0   0   0   0   0   1   0   0   0  96   0   0   0   0]
 [  0   1   0   0   1   2   0   0   0   0   2   3   0   0   0   1  50   2   0   1]
 [  0   0   0   0   0   0   0   1   0   0   3   2   0   0   0   1   0  87   2   1]
 [  0   0   0   1   1   0   0   0   0   1   5   0   0   1   0   1   3   6  84   1]
 [  0   0   1   2   2   2   2   0   1   0   3   0   0   0   0   0   0   1   0 125]]

2025-04-28 01:13:40,665 - ==> Best [Top1: 90.913   Top5: 98.708   Params: 306880 on epoch: 58]
2025-04-28 01:13:40,666 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:13:40,673 - 

2025-04-28 01:13:40,673 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:14:03,569 - Epoch: [64][   90/   90]    Overall Loss 0.153116    Objective Loss 0.153116    Top1 90.647482    Top5 100.000000    LR 0.001000    Time 0.254373    
2025-04-28 01:14:03,597 - --- validate (epoch=64)-----------
2025-04-28 01:14:03,597 - 2245 samples (100 per mini-batch)
2025-04-28 01:14:05,934 - Epoch: [64][   23/   23]    Loss 0.400041    Top1 89.220490    Top5 98.530067    
2025-04-28 01:14:05,954 - ==> Top1: 89.220    Top5: 98.530    Loss: 0.400

2025-04-28 01:14:05,954 - ==> Confusion:
[[ 97   1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   2]
 [  0 108   0   1   0   3   1   1   0   0   1   1   0   0   0   1   1   0   1   1]
 [  0   0  94   0   2   0   6   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  1   0   0 140   0   0   2   0   0   0   1   2   0   1   0   0   0   0   1   1]
 [  0   0   0   1 190   2   2   0   0   0   1   0   0   0   0   0   0   0   1   1]
 [  0   0   0   2   1  69   4   1   0   0   1   1   0   0   0   1   0   0   0   8]
 [  0   0   0   0   0   0 126   0   0   0   1   0   0   0   0   0   0   0   0   1]
 [  0   0   0   1   0   1   0  99   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   5   0   0   1   4   0 206   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   8   0   1   1   3   0  67   0   3   0   1   0   0   1   0   0   0]
 [  0   1   0   1   0   0   2   0   0   0 107   0   0   1   0   0   0   1   0   1]
 [  1   1   0   1   0   0   0   0   0   0   1  75   0   1   0   0   0   0   0   1]
 [  1   1   5   0   1   1   0   0   0   0   1   0  71   0   1   0   0   0   1   0]
 [  0   1   0   9   0   0   1   1   0   1   0   8   0  92   0   0   1   0   1   0]
 [  0   0   6   0   1   0   2   0   1   0   1   0   1   0  45   0   0   0   1   1]
 [  0   1   0   2   3   0   1   3   1   0   0   1   0   0   0  85   0   0   1   0]
 [  0   0   0   0   1   1   0   1   0   0   3   3   0   1   0   0  51   1   1   0]
 [  2   0   0   2   2   1   0   1   0   0   2   1   0   0   0   0   2  81   2   1]
 [  0   0   0   2   3   3   2   0   0   1   0   1   0   2   0   1   2   4  81   2]
 [  2   0   1   2   0   3   8   0   2   0   1   0   0   0   0   0   0   0   1 119]]

2025-04-28 01:14:05,956 - ==> Best [Top1: 90.913   Top5: 98.708   Params: 306880 on epoch: 58]
2025-04-28 01:14:05,957 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:14:05,964 - 

2025-04-28 01:14:05,964 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:14:28,887 - Epoch: [65][   90/   90]    Overall Loss 0.167612    Objective Loss 0.167612    Top1 94.964029    Top5 100.000000    LR 0.001000    Time 0.254674    
2025-04-28 01:14:28,917 - --- validate (epoch=65)-----------
2025-04-28 01:14:28,917 - 2245 samples (100 per mini-batch)
2025-04-28 01:14:31,256 - Epoch: [65][   23/   23]    Loss 0.323719    Top1 91.670379    Top5 99.020045    
2025-04-28 01:14:31,281 - ==> Top1: 91.670    Top5: 99.020    Loss: 0.324

2025-04-28 01:14:31,281 - ==> Confusion:
[[ 93   0   0   0   0   1   1   0   2   0   0   0   0   0   0   0   0   1   1   3]
 [  0 111   0   0   0   0   0   1   0   2   2   0   0   0   0   1   2   0   0   1]
 [  0   1  98   0   0   0   1   0   0   0   1   0   0   0   0   1   0   0   0   1]
 [  0   0   0 136   0   0   1   0   0   1   1   3   0   4   0   0   0   0   3   0]
 [  0   1   1   0 178   2   0   0   0   1   1   0   8   0   0   2   0   0   2   2]
 [  0   3   0   0   1  68   1   0   0   0   1   0   0   0   0   3   1   1   0   9]
 [  1   0   2   0   0   1 115   0   1   0   2   0   0   0   1   1   0   0   0   4]
 [  0   1   0   1   0   0   0  90   0   3   2   1   0   1   0   3   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   1   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   1   0   0   0   0   1  80   0   1   0   1   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 111   0   0   0   0   1   0   1   1   0]
 [  1   2   0   2   0   0   0   0   0   1   0  73   0   1   0   0   0   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  82   0   0   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   4   0   0   0 109   0   0   0   0   0   1]
 [  0   0   0   0   1   0   0   0   0   1   0   0  10   0  46   0   0   0   1   0]
 [  0   1   0   1   2   1   0   0   0   0   0   0   0   0   0  92   1   0   0   0]
 [  0   2   0   0   1   0   0   0   0   0   2   3   0   1   0   0  51   1   1   1]
 [  0   2   0   1   0   0   0   0   1   0   1   0   0   0   0   0   1  89   2   0]
 [  0   1   0   0   0   1   0   0   1   2   1   0   1   1   0   0   0   2  94   0]
 [  0   0   0   0   0   4   2   0   2   0   2   0   0   0   0   0   0   2   0 127]]

2025-04-28 01:14:31,283 - ==> Best [Top1: 91.670   Top5: 99.020   Params: 306880 on epoch: 65]
2025-04-28 01:14:31,283 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:14:31,294 - 

2025-04-28 01:14:31,294 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:14:54,167 - Epoch: [66][   90/   90]    Overall Loss 0.140191    Objective Loss 0.140191    Top1 92.805755    Top5 99.280576    LR 0.001000    Time 0.254116    
2025-04-28 01:14:54,194 - --- validate (epoch=66)-----------
2025-04-28 01:14:54,194 - 2245 samples (100 per mini-batch)
2025-04-28 01:14:56,450 - Epoch: [66][   23/   23]    Loss 0.376780    Top1 89.710468    Top5 98.663697    
2025-04-28 01:14:56,472 - ==> Top1: 89.710    Top5: 98.664    Loss: 0.377

2025-04-28 01:14:56,472 - ==> Confusion:
[[ 96   0   0   0   1   0   1   0   0   0   0   0   0   0   1   0   0   1   0   2]
 [  1 108   0   0   0   1   1   1   1   1   0   0   0   0   0   1   3   1   0   1]
 [  0   0  98   0   2   1   2   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  2   1   1 125   0   5   1   0   0   3   1   3   0   4   0   0   0   0   2   1]
 [  0   0   0   0 191   1   0   0   0   0   0   0   2   0   1   0   0   0   2   1]
 [  3   1   0   0   0  71   0   0   0   1   0   0   0   0   0   0   1   0   0  11]
 [  1   0   1   0   0   0 123   0   0   0   0   0   0   0   0   0   0   0   0   3]
 [  0   1   1   0   1   0   0  95   0   0   2   0   0   0   0   0   0   0   2   0]
 [  1   0   1   0   0   0   5   0 208   0   0   0   0   0   0   0   0   0   0   1]
 [  1   0   0   1   0   2   0   0   0  79   0   1   0   0   0   0   2   0   0   0]
 [  2   1   1   0   0   1   0   0   1   0 105   0   0   0   0   0   0   1   0   2]
 [  1   1   0   1   0   1   0   0   0   1   0  69   0   1   0   0   3   0   1   2]
 [  1   0   0   0   1   1   0   0   0   0   0   0  80   0   0   0   0   0   0   0]
 [  1   0   0   1   0   1   0   0   0   4   0   3   0 103   0   0   1   0   0   1]
 [  1   0   5   0   3   0   1   0   0   0   0   0   4   0  42   0   1   0   1   1]
 [  2   1   0   2   8   5   0   3   1   1   0   0   0   0   0  72   0   0   2   1]
 [  1   0   1   0   0   2   0   0   0   0   0   0   1   0   0   0  55   1   0   2]
 [  2   1   0   0   0   1   0   0   1   0   5   0   0   0   0   0   0  86   0   1]
 [  4   0   0   0   1   2   0   0   0   3   3   0   1   1   0   0   0   2  85   2]
 [  3   0   1   0   1   8   2   0   0   0   1   0   0   0   0   0   0   0   0 123]]

2025-04-28 01:14:56,474 - ==> Best [Top1: 91.670   Top5: 99.020   Params: 306880 on epoch: 65]
2025-04-28 01:14:56,474 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:14:56,482 - 

2025-04-28 01:14:56,482 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:15:19,298 - Epoch: [67][   90/   90]    Overall Loss 0.159720    Objective Loss 0.159720    Top1 95.683453    Top5 100.000000    LR 0.001000    Time 0.253485    
2025-04-28 01:15:19,327 - --- validate (epoch=67)-----------
2025-04-28 01:15:19,327 - 2245 samples (100 per mini-batch)
2025-04-28 01:15:21,671 - Epoch: [67][   23/   23]    Loss 0.446337    Top1 88.062361    Top5 98.619154    
2025-04-28 01:15:21,696 - ==> Top1: 88.062    Top5: 98.619    Loss: 0.446

2025-04-28 01:15:21,696 - ==> Confusion:
[[ 96   0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   4]
 [  0 113   0   0   0   0   0   1   0   0   0   0   0   0   0   2   3   0   0   1]
 [  0   0  65   1   1   0  20   0   0   0   9   0   0   0   0   0   0   0   1   6]
 [  1   0   0 142   0   0   1   0   0   0   0   1   0   3   0   0   0   0   0   1]
 [  1   0   0   0 186   3   2   1   0   0   1   0   1   0   1   0   0   0   2   0]
 [  3   1   0   3   1  58   1   0   0   1   2   1   0   0   1   1   1   2   0  12]
 [  3   0   0   1   0   0 118   0   1   0   1   0   0   0   1   0   0   0   0   3]
 [  0   1   1   2   1   0   0  93   0   0   2   0   0   0   0   1   0   0   1   0]
 [  3   0   1   0   0   0   5   0 198   0   3   0   0   0   0   0   1   1   1   3]
 [  1   1   0   7   0   0   0   0   0  75   0   1   0   0   0   1   0   0   0   0]
 [  0   2   0   0   0   0   0   0   0   0 110   0   0   0   0   0   0   1   0   1]
 [  0   1   0   4   0   0   0   0   0   1   2  70   0   2   0   0   1   0   0   0]
 [  3   0   1   0   1   0   1   0   0   0   1   0  68   0   3   0   2   0   1   2]
 [  2   1   0   9   0   0   0   0   0   2   3   0   0  98   0   0   0   0   0   0]
 [  2   0   0   0   1   0   2   0   0   0   0   0   3   0  49   0   0   0   1   1]
 [  0   1   0   1   0   0   0   2   1   0   0   0   0   0   0  92   0   0   1   0]
 [  0   1   0   1   0   1   0   0   0   0   2   0   0   0   0   0  55   2   1   0]
 [  1   2   0   0   0   2   0   0   0   0   2   0   0   0   0   0   1  87   1   1]
 [  3   1   1   0   1   0   0   0   0   2   1   0   0   1   0   1   1   3  88   1]
 [  5   0   0   1   0   3   9   0   0   0   4   0   0   0   0   0   0   1   0 116]]

2025-04-28 01:15:21,698 - ==> Best [Top1: 91.670   Top5: 99.020   Params: 306880 on epoch: 65]
2025-04-28 01:15:21,698 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:15:21,706 - 

2025-04-28 01:15:21,706 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:15:44,620 - Epoch: [68][   90/   90]    Overall Loss 0.146699    Objective Loss 0.146699    Top1 92.805755    Top5 100.000000    LR 0.001000    Time 0.254577    
2025-04-28 01:15:44,652 - --- validate (epoch=68)-----------
2025-04-28 01:15:44,652 - 2245 samples (100 per mini-batch)
2025-04-28 01:15:46,934 - Epoch: [68][   23/   23]    Loss 0.377628    Top1 90.111359    Top5 98.708241    
2025-04-28 01:15:46,959 - ==> Top1: 90.111    Top5: 98.708    Loss: 0.378

2025-04-28 01:15:46,960 - ==> Confusion:
[[ 97   0   0   0   0   0   1   0   0   0   1   0   0   0   0   0   0   1   0   2]
 [  0  99   0   0   0   0   0   2   0   0   6   0   0   0   0   1   5   4   1   2]
 [  0   0  93   0   1   0   5   0   1   0   1   0   0   0   0   1   0   0   0   1]
 [  0   0   0 126   0   0   1   0   0   0   4   2   0   6   0   2   0   0   6   2]
 [  0   0   1   0 188   0   0   3   0   0   1   0   0   0   2   0   0   1   1   1]
 [  0   0   0   0   3  66   0   0   0   0   2   0   0   0   0   1   0   2   1  13]
 [  0   0   3   0   0   0 118   0   0   0   1   0   0   0   1   1   0   0   0   4]
 [  0   0   1   0   0   0   0  98   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0   2   0   3   1   0   0  72   5   1   0   1   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   1   0   0   0   0   1  68   0   4   0   1   1   1   1   1]
 [  1   0   0   0   1   0   0   0   0   0   1   0  72   0   0   0   1   1   1   5]
 [  0   0   0   2   0   0   0   1   0   1   2   0   0 109   0   0   0   0   0   0]
 [  0   0   1   0   0   0   2   0   0   0   2   0   3   0  48   0   0   0   2   1]
 [  0   1   0   1   2   0   0   5   1   0   0   0   0   0   0  86   0   1   1   0]
 [  1   1   0   0   1   0   0   0   0   0   4   1   0   0   0   1  49   2   2   1]
 [  0   1   0   1   0   0   0   0   1   0   4   0   0   0   0   0   0  87   2   1]
 [  0   0   0   0   1   1   0   0   0   1   2   0   0   1   0   0   0   3  94   1]
 [  1   0   3   0   0   2   3   0   0   0   3   0   0   0   0   0   0   0   0 127]]

2025-04-28 01:15:46,962 - ==> Best [Top1: 91.670   Top5: 99.020   Params: 306880 on epoch: 65]
2025-04-28 01:15:46,962 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:15:46,970 - 

2025-04-28 01:15:46,970 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:16:09,616 - Epoch: [69][   90/   90]    Overall Loss 0.124402    Objective Loss 0.124402    Top1 94.964029    Top5 100.000000    LR 0.001000    Time 0.251591    
2025-04-28 01:16:09,643 - --- validate (epoch=69)-----------
2025-04-28 01:16:09,643 - 2245 samples (100 per mini-batch)
2025-04-28 01:16:11,888 - Epoch: [69][   23/   23]    Loss 0.355603    Top1 91.002227    Top5 99.109131    
2025-04-28 01:16:11,911 - ==> Top1: 91.002    Top5: 99.109    Loss: 0.356

2025-04-28 01:16:11,911 - ==> Confusion:
[[ 97   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   1   0   2]
 [  0 109   0   0   0   0   0   1   0   0   1   3   0   0   0   1   3   0   0   2]
 [  0   0  91   0   2   1   2   0   2   0   4   0   0   0   0   0   0   0   1   0]
 [  0   1   0 137   0   0   0   0   0   0   1   3   0   2   0   0   1   0   4   0]
 [  0   1   0   0 186   2   0   1   0   0   2   0   2   0   1   1   1   0   0   1]
 [  0   0   0   0   1  72   0   0   0   0   1   0   0   0   0   1   1   1   0  11]
 [  1   0   0   0   0   3 109   0   1   0   3   0   0   0   1   1   0   0   0   9]
 [  0   1   0   2   0   1   0  96   0   0   0   1   0   1   0   0   0   0   0   0]
 [  3   0   1   0   0   0   1   0 209   0   2   0   0   0   0   0   0   0   0   0]
 [  1   1   0   1   0   0   0   0   0  77   0   2   0   1   0   1   1   0   0   1]
 [  0   1   0   0   0   0   0   0   0   1 109   0   0   0   0   0   1   1   0   1]
 [  0   1   0   2   0   1   0   0   0   0   1  72   0   1   0   0   2   0   0   1]
 [  1   0   0   0   1   1   0   0   0   0   1   0  75   0   1   0   0   0   1   2]
 [  0   1   0   3   0   0   0   1   0   2   1   6   0  99   0   0   1   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  53   0   0   0   0   4]
 [  0   2   0   3   2   0   0   1   0   0   0   0   0   0   0  89   0   0   1   0]
 [  0   3   0   0   1   2   0   0   0   0   2   1   0   0   0   0  54   0   0   0]
 [  0   1   0   1   0   1   0   1   0   0   4   0   0   0   0   1   0  86   2   0]
 [  3   1   0   0   1   2   0   0   0   2   0   0   0   1   0   1   1   1  90   1]
 [  0   0   0   0   1   3   0   0   0   0   2   0   0   0   0   0   0   0   0 133]]

2025-04-28 01:16:11,913 - ==> Best [Top1: 91.670   Top5: 99.020   Params: 306880 on epoch: 65]
2025-04-28 01:16:11,914 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:16:11,921 - 

2025-04-28 01:16:11,921 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:16:34,730 - Epoch: [70][   90/   90]    Overall Loss 0.128184    Objective Loss 0.128184    Top1 92.086331    Top5 100.000000    LR 0.001000    Time 0.253408    
2025-04-28 01:16:34,759 - --- validate (epoch=70)-----------
2025-04-28 01:16:34,759 - 2245 samples (100 per mini-batch)
2025-04-28 01:16:37,093 - Epoch: [70][   23/   23]    Loss 0.356717    Top1 91.046771    Top5 98.574610    
2025-04-28 01:16:37,114 - ==> Top1: 91.047    Top5: 98.575    Loss: 0.357

2025-04-28 01:16:37,114 - ==> Confusion:
[[ 95   0   0   3   0   0   1   0   0   0   1   0   0   0   0   0   0   0   0   2]
 [  0 110   0   0   0   1   1   3   0   1   0   0   0   1   0   1   0   0   0   2]
 [  0   1  94   0   1   0   4   0   1   0   1   0   0   0   0   0   0   0   0   1]
 [  0   0   0 141   0   0   0   0   0   0   0   1   0   4   0   0   0   0   3   0]
 [  0   2   0   0 189   1   0   0   0   1   0   0   0   0   3   0   0   0   1   1]
 [  0   0   0   1   1  70   0   0   0   0   1   0   0   0   0   1   0   0   1  13]
 [  1   0   1   0   0   0 120   0   0   0   2   0   0   0   2   0   0   0   0   2]
 [  0   0   0   1   0   0   0  99   0   1   1   0   0   0   0   0   0   0   0   0]
 [  0   0   4   0   0   0   2   0 209   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   3   0   1   1   0   0  79   0   1   0   0   0   0   0   0   0   0]
 [  1   1   0   1   0   0   1   0   2   0 105   0   0   0   0   0   0   0   1   2]
 [  1   2   0   6   0   1   0   0   0   3   0  65   0   2   0   0   0   0   0   1]
 [  1   0   0   0   1   0   0   0   0   0   0   0  77   0   2   0   0   0   0   2]
 [  0   0   0  11   0   0   0   0   0   2   1   0   0 100   0   0   0   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0   0   0   2   0  54   0   0   0   0   2]
 [  0   1   0   4   1   2   0   4   1   0   0   0   0   0   1  83   0   0   1   0]
 [  0   0   0   1   2   2   0   0   0   1   3   1   0   0   0   0  53   0   0   0]
 [  1   1   0   4   0   1   0   1   0   0   6   0   0   0   0   0   0  77   3   3]
 [  1   0   1   2   1   1   0   0   0   0   1   0   0   2   0   0   0   0  93   2]
 [  1   0   0   0   1   2   1   0   0   0   2   0   0   0   0   0   1   0   0 131]]

2025-04-28 01:16:37,116 - ==> Best [Top1: 91.670   Top5: 99.020   Params: 306880 on epoch: 65]
2025-04-28 01:16:37,116 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:16:37,124 - 

2025-04-28 01:16:37,124 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:16:59,956 - Epoch: [71][   90/   90]    Overall Loss 0.151847    Objective Loss 0.151847    Top1 94.244604    Top5 100.000000    LR 0.001000    Time 0.253666    
2025-04-28 01:16:59,985 - --- validate (epoch=71)-----------
2025-04-28 01:16:59,986 - 2245 samples (100 per mini-batch)
2025-04-28 01:17:02,248 - Epoch: [71][   23/   23]    Loss 0.417773    Top1 88.997773    Top5 98.619154    
2025-04-28 01:17:02,272 - ==> Top1: 88.998    Top5: 98.619    Loss: 0.418

2025-04-28 01:17:02,273 - ==> Confusion:
[[ 93   0   0   1   0   0   1   0   0   0   0   0   0   0   2   0   0   1   1   3]
 [  1  98   3   3   0   5   1   3   0   1   1   1   0   1   0   1   0   0   1   0]
 [  0   0  93   0   1   2   3   0   0   0   1   0   0   0   1   1   0   0   0   1]
 [  1   0   0 141   0   0   0   0   0   0   0   0   0   3   1   0   0   0   1   2]
 [  0   0   0   1 190   2   0   0   0   0   0   0   0   0   3   0   0   0   1   1]
 [  0   0   2   1   2  64   0   1   0   0   1   0   1   0   1   0   0   0   1  14]
 [  0   0   4   0   0   0 116   0   1   0   0   0   1   0   3   0   0   0   0   3]
 [  0   0   1   5   0   1   0  93   0   0   1   0   1   0   0   0   0   0   0   0]
 [  0   0   2   0   0   0   0   0 213   0   0   0   0   0   0   0   0   1   0   0]
 [  1   0   0   8   0   1   0   4   0  70   0   1   0   1   0   0   0   0   0   0]
 [  0   1   1   1   0   1   1   2   2   0 100   0   0   0   0   0   0   1   1   3]
 [  0   1   0  10   0   1   0   0   0   0   0  61   0   5   0   0   0   1   1   1]
 [  1   0   1   0   0   0   0   0   0   0   0   0  80   0   1   0   0   0   0   0]
 [  0   0   0   5   1   0   0   0   0   0   1   0   0 107   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   0   0   7   4   1   0   2   0   0   0   0   0   0   1  83   0   0   0   0]
 [  0   1   0   1   2   1   0   1   0   1   6   1   2   0   0   0  44   1   1   1]
 [  2   0   0   2   1   0   0   0   1   0   1   1   0   0   0   1   0  87   1   0]
 [  2   0   0   1   4   4   0   0   0   1   2   0   2   2   1   0   0   2  78   5]
 [  1   0   0   0   1   5   0   0   0   0   1   0   0   0   0   0   0   0   0 131]]

2025-04-28 01:17:02,275 - ==> Best [Top1: 91.670   Top5: 99.020   Params: 306880 on epoch: 65]
2025-04-28 01:17:02,275 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:17:02,283 - 

2025-04-28 01:17:02,283 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:17:25,035 - Epoch: [72][   90/   90]    Overall Loss 0.134918    Objective Loss 0.134918    Top1 95.683453    Top5 100.000000    LR 0.001000    Time 0.252776    
2025-04-28 01:17:25,065 - --- validate (epoch=72)-----------
2025-04-28 01:17:25,065 - 2245 samples (100 per mini-batch)
2025-04-28 01:17:27,380 - Epoch: [72][   23/   23]    Loss 0.343806    Top1 91.581292    Top5 98.841871    
2025-04-28 01:17:27,405 - ==> Top1: 91.581    Top5: 98.842    Loss: 0.344

2025-04-28 01:17:27,405 - ==> Confusion:
[[ 99   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3]
 [  0 108   1   1   0   0   0   4   0   0   0   0   0   1   0   0   3   1   1   0]
 [  0   0  77   0   3   1   3   0   7   0   0   0   1   0   1   0   0   1   2   7]
 [  0   0   0 131   0   0   0   0   0   0   0   2   0   8   0   0   0   0   4   4]
 [  2   0   0   0 192   1   0   1   0   0   0   0   0   0   1   0   0   0   0   1]
 [  0   0   0   0   4  73   0   1   0   0   0   0   0   0   0   1   1   0   0   8]
 [  1   0   0   0   1   3 113   0   1   0   2   0   0   1   2   1   0   0   0   3]
 [  0   0   0   0   0   1   0  97   0   1   2   0   0   0   0   0   0   0   0   1]
 [  2   0   0   0   0   0   1   0 212   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   2   0   2   0   0   0  74   0   2   0   4   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 107   0   0   0   0   0   1   1   1   3]
 [  1   1   0   1   0   0   0   1   0   0   0  73   0   3   0   0   0   0   0   1]
 [  1   0   0   0   0   0   0   0   0   0   0   0  77   0   4   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   1   0   0   0 112   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   1   0  56   0   0   0   0   1]
 [  0   1   0   1   2   1   0   3   0   0   0   0   0   0   1  88   0   0   1   0]
 [  0   1   0   0   2   2   0   1   0   0   0   1   0   0   0   0  55   1   0   0]
 [  0   1   0   1   0   1   0   0   1   0   2   0   0   0   1   0   0  87   2   1]
 [  2   0   0   0   0   1   0   1   0   0   0   0   1   2   0   0   0   2  95   0]
 [  1   0   0   0   1   6   0   0   0   0   1   0   0   0   0   0   0   0   0 130]]

2025-04-28 01:17:27,407 - ==> Best [Top1: 91.670   Top5: 99.020   Params: 306880 on epoch: 65]
2025-04-28 01:17:27,407 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:17:27,415 - 

2025-04-28 01:17:27,415 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:17:50,116 - Epoch: [73][   90/   90]    Overall Loss 0.158126    Objective Loss 0.158126    Top1 94.964029    Top5 100.000000    LR 0.001000    Time 0.252204    
2025-04-28 01:17:50,145 - --- validate (epoch=73)-----------
2025-04-28 01:17:50,145 - 2245 samples (100 per mini-batch)
2025-04-28 01:17:52,472 - Epoch: [73][   23/   23]    Loss 0.342077    Top1 91.269488    Top5 98.841871    
2025-04-28 01:17:52,498 - ==> Top1: 91.269    Top5: 98.842    Loss: 0.342

2025-04-28 01:17:52,499 - ==> Confusion:
[[ 92   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   4   4]
 [  0 111   0   0   0   0   0   2   0   0   1   1   0   0   0   1   2   1   0   1]
 [  0   0  95   0   1   1   3   0   1   0   1   0   0   0   0   0   0   0   0   1]
 [  0   0   0 136   0   0   0   0   0   0   0   1   0   4   0   0   1   0   6   1]
 [  0   3   1   0 185   2   0   0   0   0   0   0   1   0   1   0   0   0   4   1]
 [  0   3   1   0   1  64   0   0   0   0   0   0   0   0   0   1   1   1   3  13]
 [  0   0   2   0   0   0 119   0   2   0   0   0   0   0   1   1   0   0   0   3]
 [  0   0   0   1   0   1   0  96   0   1   0   0   0   0   0   0   0   1   2   0]
 [  0   0   3   0   0   0   2   0 209   0   0   0   0   0   0   0   1   1   0   0]
 [  1   1   0   1   0   0   0   0   0  79   0   0   0   1   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 108   0   0   0   0   0   0   2   2   1]
 [  0   1   0   1   0   0   0   0   0   1   0  70   0   5   0   0   1   1   0   1]
 [  0   0   1   0   0   1   0   0   0   0   0   0  75   0   1   1   1   0   2   1]
 [  0   1   0   4   0   0   0   0   0   1   0   1   0 105   0   0   2   0   0   1]
 [  0   1   0   0   1   0   0   0   0   1   1   0   2   0  52   0   0   0   0   1]
 [  0   2   0   1   1   1   0   1   0   1   0   0   0   0   0  89   0   0   2   0]
 [  0   3   0   0   0   1   0   0   0   0   2   1   0   0   0   0  52   3   1   0]
 [  0   1   0   0   0   1   0   0   1   0   0   0   0   0   0   1   0  88   5   0]
 [  0   1   0   0   0   1   0   0   0   1   0   0   0   1   0   0   0   3  96   1]
 [  0   0   0   0   0   5   2   0   1   0   3   0   0   0   0   0   0   0   0 128]]

2025-04-28 01:17:52,501 - ==> Best [Top1: 91.670   Top5: 99.020   Params: 306880 on epoch: 65]
2025-04-28 01:17:52,501 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:17:52,508 - 

2025-04-28 01:17:52,508 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:18:15,226 - Epoch: [74][   90/   90]    Overall Loss 0.129971    Objective Loss 0.129971    Top1 97.841727    Top5 100.000000    LR 0.001000    Time 0.252391    
2025-04-28 01:18:15,252 - --- validate (epoch=74)-----------
2025-04-28 01:18:15,252 - 2245 samples (100 per mini-batch)
2025-04-28 01:18:17,582 - Epoch: [74][   23/   23]    Loss 0.442974    Top1 87.795100    Top5 98.663697    
2025-04-28 01:18:17,604 - ==> Top1: 87.795    Top5: 98.664    Loss: 0.443

2025-04-28 01:18:17,604 - ==> Confusion:
[[ 94   0   0   0   0   0   2   0   0   0   0   0   0   0   1   0   1   1   0   3]
 [  0 113   0   0   0   0   1   0   0   0   1   0   0   1   0   1   2   0   0   1]
 [  0   3  92   0   0   0   4   0   0   0   2   0   0   0   2   0   0   0   0   0]
 [  0   3   0 127   0   2   2   0   0   3   0   1   0   7   0   0   1   0   3   0]
 [  0   1   0   0 163  10   0   0   0   0   1   0  16   0   2   0   2   0   2   1]
 [  1   5   0   0   0  63   3   0   0   0   0   0   0   0   1   1   1   1   0  12]
 [  0   0   0   0   0   0 122   0   0   0   1   0   0   0   1   0   0   0   0   4]
 [  0   7   0   0   0   0   0  87   0   0   3   2   0   0   0   0   1   1   0   1]
 [  6   0   2   1   0   0   8   0 195   0   0   0   0   0   1   0   0   0   0   3]
 [  1   1   0   1   0   0   0   0   0  78   1   0   0   1   0   1   2   0   0   0]
 [  0   1   0   0   0   1   0   0   0   0 109   0   0   1   0   0   0   1   0   1]
 [  1   9   0   0   0   2   0   0   0   0   3  60   0   1   0   0   5   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   1   0  81   0   0   0   0   0   1   0]
 [  0   1   0   1   0   0   0   0   0   5   1   0   0 104   0   0   1   0   0   2]
 [  0   0   0   0   0   0   0   0   0   0   0   0   7   0  52   0   0   0   0   0]
 [  0   2   0   2   2   2   0   1   0   0   0   0   1   0   2  83   1   0   1   1]
 [  0   4   0   0   0   1   0   0   0   0   0   0   2   0   0   0  54   1   0   1]
 [  0   3   0   0   0   2   0   0   0   1   4   0   0   0   0   0   2  84   1   0]
 [  1   2   0   0   0   1   1   0   0   2   1   0   3   2   0   0   1   2  87   1]
 [  2   0   1   0   0   6   3   0   0   0   2   0   1   0   0   0   1   0   0 123]]

2025-04-28 01:18:17,607 - ==> Best [Top1: 91.670   Top5: 99.020   Params: 306880 on epoch: 65]
2025-04-28 01:18:17,607 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:18:17,615 - 

2025-04-28 01:18:17,616 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:18:40,211 - Epoch: [75][   90/   90]    Overall Loss 0.114520    Objective Loss 0.114520    Top1 97.841727    Top5 100.000000    LR 0.001000    Time 0.251039    
2025-04-28 01:18:40,238 - --- validate (epoch=75)-----------
2025-04-28 01:18:40,238 - 2245 samples (100 per mini-batch)
2025-04-28 01:18:42,597 - Epoch: [75][   23/   23]    Loss 0.319649    Top1 92.204900    Top5 99.064588    
2025-04-28 01:18:42,624 - ==> Top1: 92.205    Top5: 99.065    Loss: 0.320

2025-04-28 01:18:42,624 - ==> Confusion:
[[ 96   0   1   0   0   0   1   0   0   0   0   0   0   0   1   0   1   1   0   1]
 [  0 112   1   0   0   0   0   2   0   0   0   2   0   0   0   1   2   0   0   0]
 [  0   1  95   0   2   0   3   0   0   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0 134   0   0   0   0   0   1   0   4   0   2   0   2   0   0   3   3]
 [  0   3   1   0 184   2   0   0   0   0   0   0   1   0   0   6   0   0   1   0]
 [  0   1   0   0   1  69   0   1   0   0   0   1   0   0   0   2   1   0   2  10]
 [  0   1   2   0   0   0 110   0   1   0   2   0   1   0   1   1   1   0   0   8]
 [  0   0   0   0   0   1   0  99   0   1   0   1   0   0   0   0   0   0   0   0]
 [  1   0   0   0   0   0   0   0 210   0   0   0   0   0   0   0   0   0   1   4]
 [  1   0   0   1   0   0   1   1   0  79   0   3   0   0   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   2   1   1]
 [  0   1   0   0   0   0   0   0   0   0   1  77   0   1   0   1   0   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   3   0   0   0   0   0   1   1   2   0 108   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   7   0  52   0   0   0   0   0]
 [  0   1   0   2   0   0   0   2   0   0   0   0   0   0   0  93   0   0   0   0]
 [  0   2   0   0   0   3   0   0   0   0   0   1   0   0   0   0  55   1   1   0]
 [  0   1   0   0   1   2   0   1   0   0   1   1   0   0   0   1   1  86   1   1]
 [  0   0   0   0   1   3   0   1   0   1   1   0   1   2   0   0   0   2  91   1]
 [  1   0   1   0   1   3   0   0   0   0   2   1   0   0   0   0   0   0   0 130]]

2025-04-28 01:18:42,626 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:18:42,626 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:18:42,638 - 

2025-04-28 01:18:42,638 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:19:05,326 - Epoch: [76][   90/   90]    Overall Loss 0.114507    Objective Loss 0.114507    Top1 94.964029    Top5 100.000000    LR 0.001000    Time 0.252059    
2025-04-28 01:19:05,356 - --- validate (epoch=76)-----------
2025-04-28 01:19:05,356 - 2245 samples (100 per mini-batch)
2025-04-28 01:19:07,591 - Epoch: [76][   23/   23]    Loss 0.366010    Top1 90.824053    Top5 98.975501    
2025-04-28 01:19:07,616 - ==> Top1: 90.824    Top5: 98.976    Loss: 0.366

2025-04-28 01:19:07,617 - ==> Confusion:
[[ 86   0   0   0   2   0   0   1   0   1   0   0   0   3   0   0   0   2   6   1]
 [  0 109   1   1   1   0   0   2   0   0   0   1   0   0   0   2   2   0   1   0]
 [  0   0  95   0   1   1   2   0   1   0   0   0   1   0   0   0   0   1   1   0]
 [  0   0   0 131   0   0   0   2   0   0   0   5   0   6   0   1   1   0   3   0]
 [  0   0   0   0 193   1   0   0   0   0   0   0   1   0   0   0   0   0   2   1]
 [  0   0   0   0   2  71   0   0   0   0   0   0   0   0   0   3   2   0   4   6]
 [  0   1   1   0   1   1 115   0   1   0   2   0   0   0   1   1   0   0   1   3]
 [  0   0   0   1   0   1   0 100   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   2   0   0   0   0   0 214   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   1   0   0   0   2   0  74   1   2   0   4   0   0   1   0   0   0]
 [  0   1   0   1   0   0   0   0   1   1 105   0   0   1   0   0   0   2   1   1]
 [  0   2   0   0   0   0   0   0   0   0   0  75   0   3   0   0   1   0   0   0]
 [  0   0   0   0   4   1   0   0   0   0   0   0  76   0   0   0   1   0   1   0]
 [  0   0   0   1   0   0   0   0   0   0   0   1   0 111   0   0   0   0   1   1]
 [  0   0   0   0   8   0   0   0   0   0   0   0   3   0  44   1   0   0   3   0]
 [  0   1   0   1   2   1   0   2   0   0   0   0   0   0   0  90   0   0   1   0]
 [  0   3   0   1   1   0   0   0   0   0   0   1   0   0   0   0  55   1   1   0]
 [  0   0   0   0   0   0   0   2   0   0   0   1   0   0   0   0   0  91   3   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   0   2   0   1   1   4  94   0]
 [  0   0   4   0   6   6   1   0   2   1   4   0   0   0   0   0   1   1   3 110]]

2025-04-28 01:19:07,624 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:19:07,625 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:19:07,632 - 

2025-04-28 01:19:07,632 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:19:30,383 - Epoch: [77][   90/   90]    Overall Loss 0.126724    Objective Loss 0.126724    Top1 96.402878    Top5 100.000000    LR 0.001000    Time 0.252762    
2025-04-28 01:19:30,420 - --- validate (epoch=77)-----------
2025-04-28 01:19:30,420 - 2245 samples (100 per mini-batch)
2025-04-28 01:19:32,734 - Epoch: [77][   23/   23]    Loss 0.373213    Top1 90.690423    Top5 98.708241    
2025-04-28 01:19:32,755 - ==> Top1: 90.690    Top5: 98.708    Loss: 0.373

2025-04-28 01:19:32,756 - ==> Confusion:
[[ 92   0   2   1   0   0   1   0   0   0   1   0   0   0   1   0   0   0   1   3]
 [  0 109   0   0   0   2   0   1   1   1   1   0   0   0   0   1   1   2   0   1]
 [  0   0  98   0   2   0   0   0   1   0   0   0   0   0   0   0   0   1   0   1]
 [  1   0   0 139   0   0   0   0   0   0   0   2   1   1   0   0   0   0   4   1]
 [  0   0   0   0 192   0   0   0   0   0   0   0   4   0   1   0   0   0   1   0]
 [  1   0   1   0   6  71   1   0   0   1   0   0   1   0   1   1   0   0   0   4]
 [  0   0  13   1   0   0 100   0   1   0   4   0   0   0   5   1   0   0   0   3]
 [  0   0   0   1   0   1   0  95   0   0   0   0   0   0   1   2   0   0   1   1]
 [  0   0   5   0   0   1   0   0 209   0   0   0   0   0   0   0   0   0   1   0]
 [  0   1   0   2   0   1   0   0   0  77   1   0   1   0   0   0   2   0   1   0]
 [  0   1   0   0   1   0   0   0   0   0 108   0   0   0   1   0   0   2   0   1]
 [  0   1   0   2   0   0   0   0   0   0   1  71   0   2   1   0   0   2   0   1]
 [  0   0   0   0   0   1   0   0   0   0   0   0  80   0   1   0   0   1   0   0]
 [  0   1   0   3   1   0   0   0   0   2   1   2   0 104   0   0   1   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   4   0  54   0   0   0   0   0]
 [  0   0   0   1   2   3   0   0   0   0   0   0   0   0   1  90   0   0   1   0]
 [  0   1   0   0   3   1   0   0   0   0   3   1   1   0   0   0  50   1   2   0]
 [  0   1   0   1   2   1   0   0   0   0   2   0   0   0   0   1   0  88   1   0]
 [  0   0   1   0   3   3   0   0   0   0   0   0   2   1   0   0   0   4  90   0]
 [  0   0   2   1   3   5   1   0   0   0   5   0   0   0   2   0   1   0   0 119]]

2025-04-28 01:19:32,758 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:19:32,758 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:19:32,765 - 

2025-04-28 01:19:32,765 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:19:55,483 - Epoch: [78][   90/   90]    Overall Loss 0.142460    Objective Loss 0.142460    Top1 93.525180    Top5 100.000000    LR 0.001000    Time 0.252386    
2025-04-28 01:19:55,509 - --- validate (epoch=78)-----------
2025-04-28 01:19:55,509 - 2245 samples (100 per mini-batch)
2025-04-28 01:19:57,829 - Epoch: [78][   23/   23]    Loss 0.356789    Top1 91.091314    Top5 98.930958    
2025-04-28 01:19:57,855 - ==> Top1: 91.091    Top5: 98.931    Loss: 0.357

2025-04-28 01:19:57,855 - ==> Confusion:
[[ 88   0   0   0   0   0   4   0   0   0   0   0   0   0   3   0   1   2   0   4]
 [  0 112   0   0   0   0   0   2   0   2   0   0   0   0   0   0   3   0   0   1]
 [  0   0  93   0   1   1   3   0   1   0   1   0   0   0   0   0   0   1   0   2]
 [  2   0   2 125   0   1   1   0   0   4   0   1   0   3   1   0   2   0   4   3]
 [  0   0   2   0 187   2   0   0   0   0   0   0   2   0   3   0   0   0   0   2]
 [  1   0   0   0   3  71   0   0   0   1   0   0   1   0   0   1   0   1   0   9]
 [  0   0   1   0   0   0 119   0   2   0   1   0   0   0   1   1   0   0   0   3]
 [  0   1   0   0   1   2   0  93   0   0   1   0   0   0   0   0   0   1   3   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   1   0   0   0   0   0  77   0   1   0   0   0   0   3   0   2   1]
 [  0   1   0   0   0   0   1   0   1   0 108   0   0   0   0   0   0   1   2   0]
 [  1   2   0   1   0   2   0   0   0   0   1  68   0   1   0   0   3   1   0   1]
 [  0   0   1   0   0   0   0   0   1   0   0   0  76   0   2   0   1   0   1   1]
 [  0   0   0   0   0   0   1   0   0   5   1   0   0 107   0   0   0   0   1   0]
 [  0   0   2   0   0   0   0   0   0   0   0   0   2   0  54   0   0   1   0   0]
 [  0   1   0   1   2   2   0   3   0   0   0   0   0   0   1  88   0   0   0   0]
 [  0   1   0   0   1   1   0   0   0   0   0   1   0   0   0   0  55   1   2   1]
 [  0   1   0   0   0   1   0   0   1   0   1   0   0   0   0   0   0  90   1   2]
 [  1   0   0   0   1   1   1   0   0   1   1   0   1   1   1   0   0   2  92   1]
 [  0   0   1   0   0   3   3   0   1   0   3   0   0   0   0   0   1   1   0 126]]

2025-04-28 01:19:57,857 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:19:57,857 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:19:57,865 - 

2025-04-28 01:19:57,865 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:20:20,604 - Epoch: [79][   90/   90]    Overall Loss 0.135213    Objective Loss 0.135213    Top1 91.366906    Top5 100.000000    LR 0.001000    Time 0.252631    
2025-04-28 01:20:20,636 - --- validate (epoch=79)-----------
2025-04-28 01:20:20,636 - 2245 samples (100 per mini-batch)
2025-04-28 01:20:22,987 - Epoch: [79][   23/   23]    Loss 0.371542    Top1 90.779510    Top5 98.797327    
2025-04-28 01:20:23,008 - ==> Top1: 90.780    Top5: 98.797    Loss: 0.372

2025-04-28 01:20:23,009 - ==> Confusion:
[[ 83   0   0   3   1   2   1   0   0   0   2   0   0   0   0   0   1   1   0   8]
 [  0 103   0   2   1   4   1   1   0   1   1   1   0   1   0   0   2   1   0   1]
 [  0   0  94   1   1   1   3   0   1   0   0   0   0   0   0   0   0   0   1   1]
 [  0   0   0 148   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   1   0 193   0   0   0   0   1   1   0   0   0   1   0   0   0   0   1]
 [  0   1   0   1   3  70   0   0   0   0   0   0   0   0   0   2   1   0   0  10]
 [  0   0   2   0   1   1 113   0   0   0   1   0   0   0   2   1   0   0   0   7]
 [  0   0   0   6   0   1   0  92   0   0   2   0   0   0   0   1   0   0   0   0]
 [  0   0   2   0   0   1   1   0 210   0   0   0   0   0   0   0   0   0   0   2]
 [  0   0   0   3   0   0   0   0   0  79   0   1   0   0   0   0   1   0   1   1]
 [  0   1   0   1   0   1   0   0   0   0 107   0   0   0   0   0   3   0   1   0]
 [  0   1   0   4   0   1   0   0   0   0   2  72   0   1   0   0   0   0   0   0]
 [  1   0   2   0   2   1   0   0   0   0   1   0  75   0   1   0   0   0   0   0]
 [  0   0   0  12   0   0   0   0   0   3   1   1   0  96   0   0   1   0   0   1]
 [  0   0   0   0   1   0   0   0   0   2   0   0   3   0  53   0   0   0   0   0]
 [  0   1   0   1   2   0   0   2   1   0   0   2   0   0   0  89   0   0   0   0]
 [  0   1   0   1   0   2   0   0   0   0   0   2   0   0   0   0  54   1   0   2]
 [  0   1   0   2   1   1   0   0   0   0   3   0   0   0   0   1   1  86   0   1]
 [  0   1   0   0   1   3   0   0   0   1   0   1   0   1   0   0   2   3  89   2]
 [  0   0   0   0   1   3   1   0   0   0   1   0   0   0   0   0   1   0   0 132]]

2025-04-28 01:20:23,011 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:20:23,011 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:20:23,018 - 

2025-04-28 01:20:23,019 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:20:45,776 - Epoch: [80][   90/   90]    Overall Loss 0.124799    Objective Loss 0.124799    Top1 95.683453    Top5 99.280576    LR 0.001000    Time 0.252831    
2025-04-28 01:20:45,802 - --- validate (epoch=80)-----------
2025-04-28 01:20:45,803 - 2245 samples (100 per mini-batch)
2025-04-28 01:20:48,119 - Epoch: [80][   23/   23]    Loss 0.388951    Top1 90.734967    Top5 98.708241    
2025-04-28 01:20:48,145 - ==> Top1: 90.735    Top5: 98.708    Loss: 0.389

2025-04-28 01:20:48,146 - ==> Confusion:
[[ 91   1   0   1   0   0   1   3   0   1   1   0   0   0   0   1   1   1   0   0]
 [  0 111   0   0   0   0   0   3   0   1   0   0   1   0   0   2   2   0   0   0]
 [  0   1  93   0   1   0   4   0   0   0   2   0   0   0   2   0   0   0   0   0]
 [  0   1   0 142   0   0   0   0   0   0   0   2   0   0   0   1   0   0   3   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   2   0   2   0   0   0   2   0]
 [  1   1   0   1   3  68   1   1   0   0   2   0   3   0   1   1   1   0   1   3]
 [  0   1   0   1   0   1 117   0   0   0   3   0   2   0   1   1   0   0   0   1]
 [  0   0   0   1   0   1   0  99   0   0   0   0   0   0   0   1   0   0   0   0]
 [  0   0   1   0   0   0   0   0 213   0   1   0   0   0   0   0   0   0   1   0]
 [  1   1   0   1   0   0   0   2   0  79   0   0   0   0   0   0   2   0   0   0]
 [  0   3   0   0   0   0   0   0   0   0 109   0   1   0   0   0   0   1   0   0]
 [  0   2   0   3   0   1   0   0   0   2   0  65   0   2   1   2   3   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  79   0   2   0   0   0   1   0]
 [  0   1   0   7   0   0   0   1   0   8   0   0   0  96   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   3   0   0   1   0   0   0   0   0   0   0  91   0   0   1   0]
 [  0   2   0   1   1   0   0   1   0   0   2   1   1   0   0   0  52   1   1   0]
 [  1   1   0   1   2   1   0   1   0   0   3   0   0   0   0   1   1  83   0   2]
 [  0   1   0   0   0   0   0   1   0   1   0   0   3   2   0   0   0   2  93   1]
 [  1   0   2   1   2   6   3   0   1   1   5   0   1   0   3   0   3   0   2 108]]

2025-04-28 01:20:48,148 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:20:48,148 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:20:48,155 - 

2025-04-28 01:20:48,156 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:21:10,892 - Epoch: [81][   90/   90]    Overall Loss 0.123169    Objective Loss 0.123169    Top1 96.402878    Top5 100.000000    LR 0.001000    Time 0.252602    
2025-04-28 01:21:10,918 - --- validate (epoch=81)-----------
2025-04-28 01:21:10,918 - 2245 samples (100 per mini-batch)
2025-04-28 01:21:13,186 - Epoch: [81][   23/   23]    Loss 0.544483    Top1 86.191537    Top5 98.619154    
2025-04-28 01:21:13,212 - ==> Top1: 86.192    Top5: 98.619    Loss: 0.544

2025-04-28 01:21:13,212 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   2]
 [  1  97   0   0   0   5   1   2   0   1   0   1   0   0   0   0   6   1   1   4]
 [  0   0  93   0   1   1   2   0   1   0   2   0   0   0   0   0   0   0   1   2]
 [  3   0   1 122   0   0   0   0   0   0   0   1   0   1   0   1   2   0   8  10]
 [  8   0   0   0 176   2   0   1   0   0   0   0   1   0   0   0   0   2   3   5]
 [  2   0   0   0   1  54   0   0   0   0   0   0   0   0   0   0   1   1   1  28]
 [  6   0   2   0   0   0 108   0   2   0   0   0   0   0   0   0   0   0   0  10]
 [  0   1   0   0   0   1   0  94   0   1   1   0   0   0   0   0   0   0   2   2]
 [  3   0   1   0   0   0   0   0 205   0   0   0   0   0   0   0   1   1   1   4]
 [  2   0   0   1   0   1   0   0   0  76   1   0   0   0   0   0   4   0   0   1]
 [  2   1   0   0   0   0   0   0   0   0  96   0   0   0   0   0   0   4   1  10]
 [  1   1   0   0   0   0   0   0   0   1   0  62   0   1   0   0   8   2   1   4]
 [  1   0   0   0   0   1   0   0   0   0   0   0  74   0   0   0   0   2   1   4]
 [  2   0   0   1   0   0   0   0   0   5   0   0   0 104   0   0   1   0   0   2]
 [  0   0   2   0   0   0   2   0   0   0   1   0   8   0  32   0   0   0   0  14]
 [  1   0   0   1   3   3   0   6   0   1   0   1   0   0   0  76   0   2   3   1]
 [  1   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0  50   5   2   4]
 [  0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  90   2   3]
 [  4   0   0   0   0   1   0   0   0   0   0   0   0   1   0   0   0   2  93   3]
 [  2   0   0   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0   0 135]]

2025-04-28 01:21:13,214 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:21:13,214 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:21:13,222 - 

2025-04-28 01:21:13,222 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:21:35,839 - Epoch: [82][   90/   90]    Overall Loss 0.115649    Objective Loss 0.115649    Top1 95.683453    Top5 99.280576    LR 0.001000    Time 0.251275    
2025-04-28 01:21:35,868 - --- validate (epoch=82)-----------
2025-04-28 01:21:35,868 - 2245 samples (100 per mini-batch)
2025-04-28 01:21:38,209 - Epoch: [82][   23/   23]    Loss 0.364386    Top1 91.447661    Top5 98.574610    
2025-04-28 01:21:38,232 - ==> Top1: 91.448    Top5: 98.575    Loss: 0.364

2025-04-28 01:21:38,233 - ==> Confusion:
[[ 86   0   1   2   0   1   1   0   3   1   0   0   0   1   0   0   0   1   1   4]
 [  0 111   0   1   0   0   2   1   0   0   0   2   0   1   0   2   0   0   0   0]
 [  0   0  91   0   1   0   4   0   3   0   0   0   0   0   0   1   0   0   0   3]
 [  0   0   0 144   0   0   0   0   0   0   0   1   0   3   0   0   0   0   1   0]
 [  1   1   0   1 180   1   0   1   0   0   1   0   2   0   1   4   0   0   3   2]
 [  0   0   0   0   1  67   0   0   0   1   0   1   0   0   0   2   0   1   3  12]
 [  0   0   1   1   0   0 114   0   2   0   1   0   0   0   0   1   0   0   0   8]
 [  0   0   1   1   0   0   0  99   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   5   0   0   0   1   0  78   0   1   0   1   0   0   0   0   0   0]
 [  0   1   0   1   0   0   0   0   0   2 105   1   0   0   0   0   1   1   0   2]
 [  0   1   0   1   0   0   0   0   0   0   0  78   0   1   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   1   2   0  75   0   1   0   0   0   3   1]
 [  0   0   0   7   0   0   0   0   0   1   0   1   0 105   0   0   0   0   1   0]
 [  0   0   1   0   0   0   0   0   0   1   0   0   3   0  51   0   0   0   2   1]
 [  0   1   0   3   0   0   0   1   0   0   0   0   0   0   0  91   0   0   2   0]
 [  0   2   0   0   0   0   0   1   0   0   1   5   0   0   0   0  52   0   2   0]
 [  0   0   0   3   0   0   0   0   2   0   2   0   0   0   0   1   0  87   2   0]
 [  0   2   0   0   0   0   0   0   0   1   0   0   1   1   0   1   0   3  93   2]
 [  0   0   0   2   1   2   1   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 01:21:38,235 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:21:38,235 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:21:38,242 - 

2025-04-28 01:21:38,243 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:22:00,609 - Epoch: [83][   90/   90]    Overall Loss 0.114173    Objective Loss 0.114173    Top1 94.244604    Top5 100.000000    LR 0.001000    Time 0.248493    
2025-04-28 01:22:00,636 - --- validate (epoch=83)-----------
2025-04-28 01:22:00,636 - 2245 samples (100 per mini-batch)
2025-04-28 01:22:02,900 - Epoch: [83][   23/   23]    Loss 0.371297    Top1 91.180401    Top5 98.663697    
2025-04-28 01:22:02,921 - ==> Top1: 91.180    Top5: 98.664    Loss: 0.371

2025-04-28 01:22:02,922 - ==> Confusion:
[[ 96   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   2   2]
 [  0 111   1   0   0   0   1   1   0   0   0   0   0   0   0   1   3   1   0   1]
 [  0   0 101   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   2 125   0   1   0   0   0   0   0   1   0   4   0   1   0   2   9   2]
 [  1   1   0   0 190   1   0   0   0   0   0   0   1   0   1   0   0   0   2   1]
 [  1   0   3   0   2  63   0   0   0   0   1   0   2   0   1   1   0   1   2  11]
 [  0   0   7   0   1   0 111   0   1   0   4   0   0   0   1   0   0   0   0   3]
 [  0   0   0   1   0   0   0  98   0   0   1   0   0   0   0   0   0   0   2   0]
 [  0   0   1   0   0   0   0   0 211   0   2   0   0   0   0   0   0   1   1   0]
 [  1   0   0   1   0   1   0   1   0  75   0   0   0   3   0   0   3   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   2   0   0   0   0   0   0   0   0   3  67   0   1   0   1   2   3   0   1]
 [  1   1   1   0   0   0   0   0   0   0   0   0  76   0   3   0   0   1   0   0]
 [  0   0   0   1   0   1   0   0   0   0   2   0   0 109   0   0   1   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  56   0   0   0   1   0]
 [  0   1   0   2   4   0   0   1   0   0   0   0   0   0   0  88   0   0   2   0]
 [  1   1   0   0   2   2   0   0   0   1   1   0   0   0   0   0  47   5   1   2]
 [  0   0   0   0   0   1   0   0   1   0   1   0   0   0   0   0   0  93   1   0]
 [  2   0   1   0   0   1   0   0   0   0   0   0   0   1   0   0   0   8  91   0]
 [  1   0   4   0   1   2   0   0   0   0   3   0   0   0   0   0   0   0   1 127]]

2025-04-28 01:22:02,924 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:22:02,924 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:22:02,931 - 

2025-04-28 01:22:02,931 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:22:25,390 - Epoch: [84][   90/   90]    Overall Loss 0.124997    Objective Loss 0.124997    Top1 94.964029    Top5 100.000000    LR 0.001000    Time 0.249514    
2025-04-28 01:22:25,419 - --- validate (epoch=84)-----------
2025-04-28 01:22:25,419 - 2245 samples (100 per mini-batch)
2025-04-28 01:22:27,740 - Epoch: [84][   23/   23]    Loss 0.381288    Top1 90.734967    Top5 98.797327    
2025-04-28 01:22:27,768 - ==> Top1: 90.735    Top5: 98.797    Loss: 0.381

2025-04-28 01:22:27,768 - ==> Confusion:
[[ 97   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   1   0   1   2]
 [  0 105   1   0   0   0   0   3   1   0   2   0   0   3   0   1   1   0   2   1]
 [  0   0  83   0   1   0   9   0   4   0   2   0   0   0   0   0   0   0   3   1]
 [  0   0   0 132   0   0   2   0   0   0   3   0   0   8   0   0   0   0   4   0]
 [  0   1   0   1 191   0   0   0   0   0   1   0   0   1   0   0   0   0   2   1]
 [  0   0   0   1   2  56   5   0   1   0   0   1   0   0   0   2   0   1   2  17]
 [  0   0   0   0   0   0 123   0   0   0   2   0   0   0   0   0   0   0   0   3]
 [  0   0   1   5   0   0   0  93   0   0   1   0   0   2   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   0   0   0   0   0   1]
 [  0   1   0   0   0   0   1   0   0  77   1   1   0   3   0   0   1   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   1]
 [  0   1   0   1   0   0   1   0   0   0   1  71   0   4   0   1   0   0   0   1]
 [  1   0   0   0   0   1   0   0   0   0   1   0  76   0   2   0   0   0   2   0]
 [  0   0   0   1   0   0   0   0   0   1   0   0   0 111   0   0   0   0   1   1]
 [  0   0   2   0   0   0   0   0   0   0   0   0   2   0  53   0   0   0   2   0]
 [  0   2   0   2   2   0   1   1   0   0   0   0   0   0   0  88   0   0   2   0]
 [  0   1   0   1   0   0   0   0   0   0   5   2   0   2   0   0  49   1   2   0]
 [  0   0   0   0   0   0   1   0   0   1   2   0   0   1   0   1   0  86   5   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   0   1   0   0   0   2  97   2]
 [  1   0   0   0   0   1   8   0   1   0   3   0   0   0   0   0   0   0   1 124]]

2025-04-28 01:22:27,771 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:22:27,771 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:22:27,780 - 

2025-04-28 01:22:27,780 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:22:50,485 - Epoch: [85][   90/   90]    Overall Loss 0.135800    Objective Loss 0.135800    Top1 95.683453    Top5 100.000000    LR 0.001000    Time 0.252244    
2025-04-28 01:22:50,514 - --- validate (epoch=85)-----------
2025-04-28 01:22:50,514 - 2245 samples (100 per mini-batch)
2025-04-28 01:22:52,798 - Epoch: [85][   23/   23]    Loss 0.427953    Top1 89.532294    Top5 98.530067    
2025-04-28 01:22:52,822 - ==> Top1: 89.532    Top5: 98.530    Loss: 0.428

2025-04-28 01:22:52,823 - ==> Confusion:
[[ 79   0   0   1   1   3   1   2   2   0   0   0   0   3   2   0   1   1   4   2]
 [  0 102   1   0   0   1   1   1   0   2   0   3   1   3   0   1   3   0   1   0]
 [  0   0  97   0   1   0   1   0   1   0   0   0   0   0   1   1   0   0   1   0]
 [  0   0   0 131   0   0   1   0   1   1   0   1   0  11   0   2   1   0   0   0]
 [  0   2   0   0 176   0   0   0   0   1   0   0  10   0   3   4   0   0   2   0]
 [  0   2   1   0   0  75   0   0   0   0   1   0   0   1   0   1   1   0   3   3]
 [  1   1   8   1   0   0 102   0   2   0   5   0   0   0   2   0   0   0   2   4]
 [  0   0   0   0   0   1   0  95   0   4   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   1   0   0 212   0   0   0   0   0   0   0   0   1   2   0]
 [  0   0   0   1   0   0   1   0   0  81   0   2   0   1   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   1 109   0   0   1   0   0   2   1   0   0]
 [  0   1   0   1   0   0   0   0   0   0   0  78   0   1   0   0   0   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   2   0   1   0 110   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   2   0  54   0   0   0   2   0]
 [  0   1   0   2   0   0   1   0   0   1   0   0   0   0   0  92   0   0   1   0]
 [  0   0   0   1   0   1   0   0   0   1   1   5   1   0   0   0  50   1   2   0]
 [  0   0   0   0   0   2   0   0   1   1   2   0   0   0   0   1   2  83   5   0]
 [  0   0   0   2   1   0   0   0   0   1   2   1   1   4   0   0   2   2  88   0]
 [  2   0   4   4   1   3   0   0   0   0   4   1   0   0   0   2   2   0   1 115]]

2025-04-28 01:22:52,825 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:22:52,825 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:22:52,833 - 

2025-04-28 01:22:52,833 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:23:15,620 - Epoch: [86][   90/   90]    Overall Loss 0.120271    Objective Loss 0.120271    Top1 92.805755    Top5 99.280576    LR 0.001000    Time 0.253166    
2025-04-28 01:23:15,652 - --- validate (epoch=86)-----------
2025-04-28 01:23:15,652 - 2245 samples (100 per mini-batch)
2025-04-28 01:23:17,995 - Epoch: [86][   23/   23]    Loss 0.412825    Top1 90.200445    Top5 98.485523    
2025-04-28 01:23:18,016 - ==> Top1: 90.200    Top5: 98.486    Loss: 0.413

2025-04-28 01:23:18,017 - ==> Confusion:
[[ 94   0   0   1   0   0   0   0   2   0   0   0   0   0   0   0   0   2   0   3]
 [  0 101   2   1   1   1   0   3   1   2   2   0   1   2   0   0   2   0   0   1]
 [  0   0  90   0   5   0   2   0   4   0   0   0   0   0   0   0   0   0   0   2]
 [  0   0   0 140   0   0   0   3   0   1   0   0   0   2   0   0   0   0   2   1]
 [  0   0   0   0 194   0   0   0   0   0   0   0   2   0   0   0   0   0   1   1]
 [  1   0   0   1   6  64   0   0   1   0   2   0   0   0   0   1   0   2   1   9]
 [  0   0   0   2   3   0 110   0   1   0   3   0   0   0   2   1   0   0   1   5]
 [  0   0   0   0   0   0   0 100   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   2   0   0   0   2   0  75   1   2   0   1   0   0   0   0   1   1]
 [  0   0   0   0   0   0   0   0   1   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   2   0   1   0   1   0   0   0  72   0   1   0   0   0   0   1   2]
 [  1   0   0   0   3   0   0   0   0   0   2   0  76   0   0   0   0   1   0   0]
 [  0   0   0  12   0   0   0   1   0   6   3   1   0  92   0   0   0   0   0   0]
 [  0   0   0   1   3   0   0   0   0   0   0   0   3   0  51   0   0   0   0   1]
 [  0   1   0   2   7   1   0   4   0   0   0   0   0   0   0  83   0   0   0   0]
 [  0   1   0   1   3   0   0   0   0   1   4   1   0   0   0   0  47   2   2   1]
 [  0   0   0   2   0   0   0   1   1   0   2   0   0   0   0   1   0  87   2   1]
 [  3   0   0   0   4   0   0   1   0   0   2   0   0   0   0   0   0   1  92   1]
 [  0   0   2   0   2   2   1   0   2   0   1   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:23:18,019 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:23:18,019 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:23:18,028 - 

2025-04-28 01:23:18,028 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:23:40,963 - Epoch: [87][   90/   90]    Overall Loss 0.123209    Objective Loss 0.123209    Top1 95.683453    Top5 100.000000    LR 0.001000    Time 0.254811    
2025-04-28 01:23:40,994 - --- validate (epoch=87)-----------
2025-04-28 01:23:40,994 - 2245 samples (100 per mini-batch)
2025-04-28 01:23:43,263 - Epoch: [87][   23/   23]    Loss 0.363671    Top1 91.002227    Top5 98.752784    
2025-04-28 01:23:43,289 - ==> Top1: 91.002    Top5: 98.753    Loss: 0.364

2025-04-28 01:23:43,289 - ==> Confusion:
[[ 82   0   2   4   0   2   3   0   1   0   0   0   0   0   0   1   1   2   0   4]
 [  0 107   1   2   0   0   0   2   0   1   1   3   0   0   0   2   0   0   1   0]
 [  0   0  96   0   0   2   2   0   1   0   0   0   0   0   0   2   0   0   0   0]
 [  0   0   0 144   0   0   0   0   0   0   0   1   0   3   0   0   0   0   1   0]
 [  0   0   1   2 180   5   0   1   0   0   0   0   1   0   2   3   0   0   2   1]
 [  0   0   1   2   1  75   1   0   0   0   0   0   0   0   0   2   0   0   1   5]
 [  0   0   0   2   0   0 122   0   0   0   1   0   0   0   1   1   0   0   0   1]
 [  0   1   1   4   0   0   0  89   0   0   2   1   0   1   0   3   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0   8   0   0   0   0   0  71   1   2   0   2   0   0   1   0   1   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   3   0   0   0   0   0   0   1  74   0   1   0   0   0   0   0   1]
 [  1   0   0   0   0   0   0   0   0   0   1   0  80   0   1   0   0   0   0   0]
 [  0   0   0   6   0   0   0   0   0   0   1   1   0 106   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   0   0]
 [  0   1   0   2   0   0   0   2   0   0   1   0   0   0   0  91   0   0   1   0]
 [  0   2   0   1   0   1   0   0   0   0   3   4   0   0   0   0  51   0   1   0]
 [  0   2   0   1   0   2   0   0   0   0   4   0   0   0   0   0   1  85   2   0]
 [  0   0   0   2   2   3   1   2   0   1   1   0   1   1   0   1   0   0  88   1]
 [  0   0   5   2   0   7   2   0   0   0   3   0   0   0   0   0   0   0   0 120]]

2025-04-28 01:23:43,291 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:23:43,291 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:23:43,299 - 

2025-04-28 01:23:43,299 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:24:06,013 - Epoch: [88][   90/   90]    Overall Loss 0.114528    Objective Loss 0.114528    Top1 94.244604    Top5 100.000000    LR 0.001000    Time 0.252358    
2025-04-28 01:24:06,045 - --- validate (epoch=88)-----------
2025-04-28 01:24:06,045 - 2245 samples (100 per mini-batch)
2025-04-28 01:24:08,337 - Epoch: [88][   23/   23]    Loss 0.368527    Top1 91.135857    Top5 98.619154    
2025-04-28 01:24:08,362 - ==> Top1: 91.136    Top5: 98.619    Loss: 0.369

2025-04-28 01:24:08,363 - ==> Confusion:
[[ 92   0   0   0   3   0   1   1   0   0   0   0   0   1   0   0   0   3   0   1]
 [  0 112   0   0   1   0   1   2   0   1   0   0   1   0   0   1   0   0   1   0]
 [  0   0  97   0   4   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0 133   0   3   2   1   0   0   0   1   0   3   0   1   1   0   2   1]
 [  0   0   0   0 197   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0]
 [  0   1   1   0   4  71   0   0   0   0   1   0   0   0   0   1   1   2   0   6]
 [  0   0   2   0   2   0 118   0   1   0   3   0   0   0   1   0   0   0   0   1]
 [  0   0   1   0   1   1   0  98   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   3   0   0   0   1   0 212   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   1   0   1   0   1   0  76   1   0   0   1   0   0   2   0   1   0]
 [  0   1   0   0   0   0   0   0   0   0 109   0   0   0   0   0   1   3   0   0]
 [  1   5   0   1   0   1   0   2   0   0   0  66   0   2   0   1   1   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  80   0   2   0   0   0   0   0]
 [  0   1   0   2   3   2   0   0   0   0   1   0   0 105   0   0   0   0   0   1]
 [  0   0   0   0   5   0   1   0   0   0   0   0   2   0  51   0   0   0   0   0]
 [  0   1   0   1   4   1   0   2   0   0   0   0   0   0   0  88   0   0   1   0]
 [  0   2   0   1   2   1   0   0   0   2   1   0   0   0   0   0  51   1   2   0]
 [  0   0   0   0   0   1   0   1   0   1   2   0   0   0   0   0   1  90   1   0]
 [  1   0   0   0   6   1   0   0   0   1   0   0   1   2   0   0   2   2  88   0]
 [  1   0   8   0   5   4   2   0   0   0   4   0   0   0   2   0   0   0   1 112]]

2025-04-28 01:24:08,365 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:24:08,365 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:24:08,372 - 

2025-04-28 01:24:08,372 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:24:31,023 - Epoch: [89][   90/   90]    Overall Loss 0.100953    Objective Loss 0.100953    Top1 97.841727    Top5 100.000000    LR 0.001000    Time 0.251650    
2025-04-28 01:24:31,047 - --- validate (epoch=89)-----------
2025-04-28 01:24:31,047 - 2245 samples (100 per mini-batch)
2025-04-28 01:24:33,313 - Epoch: [89][   23/   23]    Loss 0.343610    Top1 91.670379    Top5 98.663697    
2025-04-28 01:24:33,335 - ==> Top1: 91.670    Top5: 98.664    Loss: 0.344

2025-04-28 01:24:33,336 - ==> Confusion:
[[ 97   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   3]
 [  0 109   0   0   0   1   1   2   0   0   1   0   0   1   0   2   1   0   1   1]
 [  0   0  90   0   2   1   9   0   0   0   0   0   0   0   0   0   0   1   0   0]
 [  1   0   0 136   0   0   0   3   0   0   0   2   0   2   0   1   0   0   3   1]
 [  1   0   1   0 192   0   2   0   0   0   1   0   1   0   0   0   0   0   0   0]
 [  0   0   0   1   1  72   4   1   0   0   0   0   0   0   0   1   0   0   1   7]
 [  0   0   0   0   0   0 124   0   1   0   1   0   0   0   0   0   0   0   0   2]
 [  0   0   1   0   0   0   0  99   0   0   1   0   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   2   0 213   0   0   0   0   0   0   0   0   0   0   1]
 [  1   2   0   3   0   1   0   6   0  67   2   2   0   1   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   0   1   1   1]
 [  0   3   0   2   0   1   0   0   0   0   1  71   0   1   0   0   0   2   0   0]
 [  0   0   1   0   0   1   0   0   0   0   0   0  78   0   1   0   0   0   2   0]
 [  0   0   0   6   1   0   0   4   0   0   2   0   0  99   0   0   1   0   0   2]
 [  0   0   2   0   0   0   1   0   1   0   0   0   1   0  54   0   0   0   0   0]
 [  0   1   0   2   2   0   0   1   0   0   0   0   0   0   0  90   0   0   2   0]
 [  0   2   0   1   2   2   0   0   0   0   1   2   0   0   0   0  48   4   1   0]
 [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   2   0  90   4   0]
 [  1   1   0   0   2   1   1   1   1   0   0   0   1   0   0   0   0   3  91   1]
 [  0   0   1   0   1   1   5   0   0   0   3   0   0   0   0   0   0   0   0 128]]

2025-04-28 01:24:33,338 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:24:33,338 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:24:33,345 - 

2025-04-28 01:24:33,345 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:24:55,892 - Epoch: [90][   90/   90]    Overall Loss 0.094413    Objective Loss 0.094413    Top1 94.964029    Top5 100.000000    LR 0.001000    Time 0.250489    
2025-04-28 01:24:55,924 - --- validate (epoch=90)-----------
2025-04-28 01:24:55,924 - 2245 samples (100 per mini-batch)
2025-04-28 01:24:58,239 - Epoch: [90][   23/   23]    Loss 0.333498    Top1 92.204900    Top5 98.886414    
2025-04-28 01:24:58,264 - ==> Top1: 92.205    Top5: 98.886    Loss: 0.333

2025-04-28 01:24:58,264 - ==> Confusion:
[[ 91   0   2   0   0   1   2   0   0   0   0   0   0   0   1   0   0   0   1   4]
 [  0 111   1   0   0   0   0   1   0   1   1   0   0   0   0   1   3   0   1   0]
 [  0   0  95   0   1   0   3   0   2   0   0   0   0   0   0   0   0   1   1   0]
 [  0   0   0 141   0   1   0   0   0   0   0   0   0   1   0   1   0   0   5   0]
 [  0   2   1   0 186   0   1   0   0   0   0   0   1   0   1   1   0   0   5   0]
 [  0   0   0   0   2  81   0   0   0   0   0   0   0   0   0   1   0   0   2   2]
 [  0   0   0   1   0   0 122   0   1   0   1   0   0   0   0   1   0   0   0   2]
 [  0   2   0   0   0   0   0  98   0   0   1   0   0   0   0   0   0   1   0   0]
 [  0   0   1   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   2   0   2   0   1   0   1   0  72   1   2   0   0   0   1   1   0   2   0]
 [  0   1   0   0   0   0   0   0   1   0 110   0   0   0   0   0   0   0   2   0]
 [  0   2   0   0   0   1   0   0   0   0   1  76   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   1   0  78   0   2   0   0   0   2   0]
 [  0   1   0   6   0   0   0   1   0   3   1   1   0 101   0   0   1   0   0   0]
 [  0   0   1   0   0   0   1   0   0   0   1   0   1   0  51   0   0   0   4   0]
 [  0   2   0   1   2   1   0   2   0   0   0   0   0   0   0  88   0   0   2   0]
 [  0   1   0   1   1   2   0   0   0   1   2   1   0   0   0   0  50   1   3   0]
 [  0   1   1   1   0   2   0   0   1   0   2   0   0   0   0   1   0  85   3   0]
 [  0   1   0   0   1   1   1   0   1   1   1   0   0   0   0   0   0   1  95   1]
 [  1   0   3   0   1   6   1   0   0   0   2   0   0   0   0   0   0   0   1 124]]

2025-04-28 01:24:58,266 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:24:58,266 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:24:58,274 - 

2025-04-28 01:24:58,274 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:25:20,960 - Epoch: [91][   90/   90]    Overall Loss 0.102780    Objective Loss 0.102780    Top1 97.122302    Top5 100.000000    LR 0.001000    Time 0.252044    
2025-04-28 01:25:20,989 - --- validate (epoch=91)-----------
2025-04-28 01:25:20,989 - 2245 samples (100 per mini-batch)
2025-04-28 01:25:23,240 - Epoch: [91][   23/   23]    Loss 0.377433    Top1 91.180401    Top5 98.752784    
2025-04-28 01:25:23,265 - ==> Top1: 91.180    Top5: 98.753    Loss: 0.377

2025-04-28 01:25:23,265 - ==> Confusion:
[[ 98   0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 106   0   0   0   1   1   0   1   0   1   1   0   1   0   1   5   1   0   1]
 [  0   1  89   0   1   1   4   0   1   0   0   0   0   0   3   1   0   0   0   2]
 [  0   0   0 137   0   0   0   0   0   0   0   0   0   4   1   1   1   0   3   2]
 [  0   0   0   0 192   0   0   0   0   0   0   0   0   0   2   1   0   0   2   1]
 [  0   0   0   1   2  69   1   0   0   0   0   0   2   0   1   1   0   1   2   8]
 [  0   0   0   0   0   1 117   0   0   0   0   0   0   0   5   0   0   0   0   5]
 [  0   0   0   2   2   2   0  91   0   0   1   0   0   1   0   2   0   0   1   0]
 [  0   0   0   0   0   0   2   0 214   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   2   0   1   0   0   0  77   0   1   0   1   0   0   1   0   1   0]
 [  1   0   0   0   0   0   3   0   4   0  98   0   1   0   0   0   0   2   1   4]
 [  1   1   0   1   0   1   0   0   0   0   1  73   0   1   0   0   1   0   0   1]
 [  1   0   0   0   0   0   0   0   0   0   0   0  80   0   2   0   0   0   0   0]
 [  0   0   0   6   0   1   0   0   0   0   1   0   0 104   0   0   2   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   4   0  55   0   0   0   0   0]
 [  0   0   0   1   3   2   0   1   1   0   1   0   0   0   0  88   0   0   0   1]
 [  0   1   0   0   1   0   0   0   0   0   1   2   1   0   0   0  53   3   1   0]
 [  0   1   0   0   0   1   0   0   0   0   1   0   0   0   1   1   0  91   1   0]
 [  1   0   0   0   3   1   0   0   1   0   0   0   2   3   1   0   1   1  89   1]
 [  5   0   0   0   0   5   1   0   0   0   1   0   0   0   0   0   0   0   1 126]]

2025-04-28 01:25:23,267 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:25:23,267 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:25:23,276 - 

2025-04-28 01:25:23,276 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:25:45,781 - Epoch: [92][   90/   90]    Overall Loss 0.102312    Objective Loss 0.102312    Top1 96.402878    Top5 100.000000    LR 0.001000    Time 0.250026    
2025-04-28 01:25:45,808 - --- validate (epoch=92)-----------
2025-04-28 01:25:45,809 - 2245 samples (100 per mini-batch)
2025-04-28 01:25:48,135 - Epoch: [92][   23/   23]    Loss 0.387378    Top1 90.868597    Top5 98.485523    
2025-04-28 01:25:48,158 - ==> Top1: 90.869    Top5: 98.486    Loss: 0.387

2025-04-28 01:25:48,159 - ==> Confusion:
[[ 89   0   0   0   0   0   3   0   4   0   0   0   0   0   1   1   0   2   1   1]
 [  0 112   1   0   0   0   0   2   0   2   0   0   0   0   0   0   2   1   0   0]
 [  0   0  93   0   0   0   6   0   2   0   0   0   0   0   1   1   0   0   0   0]
 [  1   2   0 129   0   0   0   0   0   0   1   2   0   4   0   3   4   0   3   0]
 [  0   2   0   0 187   0   0   0   0   1   0   1   1   0   3   1   0   0   1   1]
 [  0   8   2   0   1  64   2   0   0   1   0   0   0   0   0   2   2   1   0   5]
 [  0   0   0   0   0   1 121   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   2   0   0   0   0   0  89   0   3   1   0   0   0   0   3   0   0   4   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   2   0   1   0   0   0   0   0  79   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   1   0 110   0   0   0   0   0   1   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   2  76   0   0   0   1   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   2   0  78   0   1   0   0   0   1   0]
 [  0   1   0   6   0   0   0   0   0   6   1   2   0  99   0   0   0   0   0   0]
 [  0   0   1   0   0   0   1   0   0   0   0   0   3   0  53   1   0   0   0   0]
 [  0   2   0   0   0   0   0   2   1   0   0   0   0   0   0  93   0   0   0   0]
 [  0   1   0   1   0   0   0   0   0   0   1   2   0   0   0   0  54   2   2   0]
 [  0   2   0   0   0   2   0   0   1   0   1   0   0   0   1   1   0  87   2   0]
 [  1   1   1   0   0   0   1   0   0   1   1   0   3   2   0   0   1   0  92   0]
 [  0   0   2   0   1   5   1   0   3   0   3   0   0   0   1   1   2   1   0 119]]

2025-04-28 01:25:48,161 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:25:48,161 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:25:48,168 - 

2025-04-28 01:25:48,168 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:26:10,793 - Epoch: [93][   90/   90]    Overall Loss 0.112444    Objective Loss 0.112444    Top1 95.683453    Top5 100.000000    LR 0.001000    Time 0.251356    
2025-04-28 01:26:10,814 - --- validate (epoch=93)-----------
2025-04-28 01:26:10,814 - 2245 samples (100 per mini-batch)
2025-04-28 01:26:13,115 - Epoch: [93][   23/   23]    Loss 0.407463    Top1 91.002227    Top5 98.307350    
2025-04-28 01:26:13,136 - ==> Top1: 91.002    Top5: 98.307    Loss: 0.407

2025-04-28 01:26:13,136 - ==> Confusion:
[[ 96   0   0   0   1   1   1   0   0   0   0   0   0   0   0   1   0   0   0   2]
 [  0 109   0   0   1   2   1   1   0   0   1   1   0   0   0   1   2   1   0   0]
 [  0   0  94   0   3   1   2   0   1   0   0   0   0   0   0   2   0   0   0   0]
 [  0   1   0 133   0   1   0   0   0   0   0   1   0   3   0   2   1   0   5   2]
 [  0   1   0   0 194   0   0   0   0   0   0   0   1   0   0   0   0   0   1   1]
 [  0   0   0   0   4  75   0   0   0   0   0   0   0   0   0   2   0   0   0   7]
 [  0   0   0   1   1   0 117   0   1   0   2   1   0   0   0   1   0   1   0   3]
 [  0   0   0   1   0   1   0  94   0   0   2   0   0   0   0   3   0   0   1   0]
 [  0   0   0   0   0   0   2   0 213   0   0   0   0   0   0   0   0   0   0   1]
 [  1   3   0   2   0   3   0   2   0  69   0   3   0   1   0   1   1   0   0   0]
 [  1   1   1   0   0   0   0   0   1   0 100   0   1   0   0   3   1   3   1   1]
 [  0   1   0   0   0   1   0   0   0   0   0  78   0   0   0   0   0   0   0   1]
 [  0   0   0   0   3   1   0   0   0   0   0   0  77   0   0   0   0   0   1   1]
 [  0   0   0   6   0   1   0   2   0   1   0   7   0  97   0   0   1   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   5   0  52   1   0   0   0   0]
 [  0   1   0   0   3   0   0   1   1   0   0   0   0   0   0  92   0   0   0   0]
 [  0   2   0   0   3   2   0   0   0   0   0   2   1   0   0   1  50   1   1   0]
 [  1   2   0   1   0   2   0   0   2   0   1   0   0   1   0   1   1  82   2   1]
 [  1   2   0   0   2   2   0   0   0   0   0   0   1   1   0   1   0   0  92   2]
 [  0   0   1   0   2   5   1   0   0   0   1   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:26:13,138 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:26:13,139 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:26:13,146 - 

2025-04-28 01:26:13,146 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:26:35,960 - Epoch: [94][   90/   90]    Overall Loss 0.103693    Objective Loss 0.103693    Top1 95.683453    Top5 100.000000    LR 0.001000    Time 0.253460    
2025-04-28 01:26:35,989 - --- validate (epoch=94)-----------
2025-04-28 01:26:35,989 - 2245 samples (100 per mini-batch)
2025-04-28 01:26:38,257 - Epoch: [94][   23/   23]    Loss 0.365347    Top1 91.937639    Top5 98.396437    
2025-04-28 01:26:38,282 - ==> Top1: 91.938    Top5: 98.396    Loss: 0.365

2025-04-28 01:26:38,283 - ==> Confusion:
[[ 99   0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   1]
 [  0 108   1   1   0   0   0   3   0   1   0   1   0   0   0   0   3   0   2   0]
 [  0   0  97   0   2   0   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0 129   0   0   0   0   0   1   1   3   0   5   0   0   1   0   6   2]
 [  1   0   0   0 192   0   0   0   0   0   0   0   1   0   0   0   0   0   3   1]
 [  3   0   0   0   1  71   2   0   0   0   1   0   0   0   0   1   1   1   1   6]
 [  0   0   0   0   1   0 123   0   1   0   1   0   0   0   0   0   0   0   0   2]
 [  0   0   0   0   0   0   0  97   0   0   2   0   0   1   0   0   0   1   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  1   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   0   0]
 [  2   1   0   1   0   0   0   0   0   0   1  72   0   0   0   0   2   1   0   1]
 [  1   0   2   0   4   0   0   0   0   0   2   0  73   0   1   0   0   0   0   0]
 [  1   0   1   3   0   0   0   1   0   2   1   0   0 105   0   0   1   0   0   0]
 [  2   0   1   0   1   0   2   0   0   0   1   0   2   0  49   0   0   0   0   1]
 [  1   1   0   3   3   0   0   1   0   0   0   0   0   0   0  88   0   0   1   0]
 [  0   1   0   0   3   1   0   0   0   0   0   1   0   0   0   0  53   1   2   1]
 [  3   0   0   0   0   1   0   0   1   0   1   0   0   0   0   0   0  89   2   0]
 [  3   0   0   0   2   1   0   0   0   0   0   0   0   0   0   0   0   2  96   0]
 [  4   0   5   0   3   1   4   0   0   0   2   0   0   0   0   0   0   0   0 120]]

2025-04-28 01:26:38,285 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:26:38,285 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:26:38,294 - 

2025-04-28 01:26:38,294 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:27:00,973 - Epoch: [95][   90/   90]    Overall Loss 0.095344    Objective Loss 0.095344    Top1 94.244604    Top5 100.000000    LR 0.001000    Time 0.251966    
2025-04-28 01:27:01,000 - --- validate (epoch=95)-----------
2025-04-28 01:27:01,001 - 2245 samples (100 per mini-batch)
2025-04-28 01:27:03,263 - Epoch: [95][   23/   23]    Loss 0.364064    Top1 91.848552    Top5 98.396437    
2025-04-28 01:27:03,285 - ==> Top1: 91.849    Top5: 98.396    Loss: 0.364

2025-04-28 01:27:03,286 - ==> Confusion:
[[101   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0]
 [  0 104   1   0   0   2   0   2   0   1   1   0   0   0   0   0   5   0   4   0]
 [  0   0  90   0   2   1   3   0   5   0   0   0   0   0   0   0   0   0   1   1]
 [  0   0   0 139   0   0   0   0   0   0   0   2   0   3   0   0   0   0   5   0]
 [  0   0   1   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   2   0]
 [  2   0   0   0   0  71   0   2   0   0   1   0   1   0   0   2   1   0   1   7]
 [  1   0   2   0   1   0 116   0   2   0   2   1   0   0   0   1   0   0   0   2]
 [  0   0   1   0   0   0   0  99   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   1   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   0   0   0  78   0   1   0   0   0   0   1   0   1   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   0   1   0]
 [  1   1   0   1   0   0   0   0   0   0   0  76   0   0   0   0   2   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   1   0  80   0   0   0   0   0   1   0]
 [  0   0   0   3   0   0   0   0   0   3   1   1   0 106   0   0   1   0   0   0]
 [  2   0   1   0   0   0   0   0   0   0   1   0   3   0  51   0   0   0   0   1]
 [  0   1   0   1   4   0   0   3   0   0   0   0   0   0   0  88   0   0   1   0]
 [  0   1   0   0   0   0   0   0   0   1   0   3   1   0   0   0  54   1   2   0]
 [  2   0   0   1   1   2   0   0   1   1   2   0   0   1   0   0   7  72   7   0]
 [  2   0   1   0   1   1   0   0   0   0   0   0   1   3   0   0   0   1  94   0]
 [  4   0   2   1   2   2   1   0   0   0   3   0   0   0   0   0   0   0   1 123]]

2025-04-28 01:27:03,288 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:27:03,288 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:27:03,295 - 

2025-04-28 01:27:03,295 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:27:25,897 - Epoch: [96][   90/   90]    Overall Loss 0.125572    Objective Loss 0.125572    Top1 91.366906    Top5 100.000000    LR 0.001000    Time 0.251100    
2025-04-28 01:27:25,928 - --- validate (epoch=96)-----------
2025-04-28 01:27:25,928 - 2245 samples (100 per mini-batch)
2025-04-28 01:27:28,185 - Epoch: [96][   23/   23]    Loss 0.352657    Top1 91.625835    Top5 98.797327    
2025-04-28 01:27:28,206 - ==> Top1: 91.626    Top5: 98.797    Loss: 0.353

2025-04-28 01:27:28,207 - ==> Confusion:
[[ 94   0   0   0   0   0   1   0   0   1   0   0   0   0   0   0   0   2   0   4]
 [  0 116   1   0   0   0   0   2   0   0   0   1   0   0   0   0   0   0   0   0]
 [  1   0  95   0   1   0   3   0   0   0   0   0   0   0   0   0   0   0   1   2]
 [  1   4   0 139   0   1   0   0   0   0   0   0   0   0   0   0   0   0   3   1]
 [  0   1   0   0 186   4   1   0   0   0   0   0   2   0   0   0   0   0   1   3]
 [  2   0   0   0   0  76   1   0   0   0   0   0   0   0   0   1   1   0   0   7]
 [  0   0   0   0   0   0 124   0   0   0   2   0   0   0   0   0   0   0   0   2]
 [  0   2   1   0   0   0   0  97   0   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   8   0 207   0   0   0   0   0   0   0   0   0   0   1]
 [  1   1   0   1   0   0   0   0   0  80   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   1   0 105   0   2   0   0   0   1   3   1   0]
 [  2   1   0   1   0   0   0   0   0   0   0  74   0   0   0   0   2   0   0   1]
 [  3   0   0   0   0   0   0   0   0   0   1   0  77   0   1   0   0   0   0   1]
 [  0   6   0   1   0   1   0   0   0   2   0   1   0 101   0   0   0   0   0   3]
 [  0   0   0   0   0   0   2   0   0   0   0   0   3   0  51   0   0   0   3   0]
 [  0   3   0   3   1   2   1   9   0   0   0   0   1   0   0  77   0   0   1   0]
 [  0   4   0   1   0   1   0   0   0   1   0   2   0   0   0   0  52   1   1   0]
 [  0   1   1   1   0   1   0   0   0   0   0   0   0   0   0   0   1  90   2   0]
 [  2   3   0   0   0   0   2   0   1   1   0   0   1   1   0   0   3   3  87   0]
 [  2   0   1   0   0   2   3   0   0   0   2   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:27:28,214 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:27:28,214 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:27:28,222 - 

2025-04-28 01:27:28,222 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:27:50,874 - Epoch: [97][   90/   90]    Overall Loss 0.108401    Objective Loss 0.108401    Top1 92.086331    Top5 100.000000    LR 0.001000    Time 0.251659    
2025-04-28 01:27:50,904 - --- validate (epoch=97)-----------
2025-04-28 01:27:50,905 - 2245 samples (100 per mini-batch)
2025-04-28 01:27:53,224 - Epoch: [97][   23/   23]    Loss 0.593048    Top1 86.369710    Top5 97.772829    
2025-04-28 01:27:53,246 - ==> Top1: 86.370    Top5: 97.773    Loss: 0.593

2025-04-28 01:27:53,247 - ==> Confusion:
[[ 76   0   3   0   2   2   9   0   0   0   0   0   0   0   0   0   0   4   0   6]
 [  0  98   2   0   3   1   3   0   0   0   6   0   1   1   0   1   0   1   3   0]
 [  0   0  98   0   2   0   2   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   4   3 101   1  11   4   1   0   0   2   0   0   1   0   5   0   2   8   6]
 [  0   0   1   0 192   0   0   0   0   0   0   0   3   0   0   0   0   0   2   0]
 [  0   0   1   0   0  69   2   0   0   0   0   0   1   0   0   1   1   3   0  10]
 [  0   0   2   0   1   0 120   0   0   0   1   0   0   0   0   0   0   0   0   4]
 [  0   0   1   0   3   1   0  91   0   0   2   0   0   0   0   1   0   1   2   0]
 [  0   0   2   0   0   0   3   0 211   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   2   1   1   1   1   1  69   1   0   0   2   0   0   1   3   3   0]
 [  0   0   1   0   0   0   0   0   1   0 108   0   1   0   0   0   0   2   1   0]
 [  0   4   0   1   1   4   1   0   0   0   2  60   0   1   0   0   2   1   1   3]
 [  0   0   0   0   0   0   2   0   0   0   1   0  79   0   1   0   0   0   0   0]
 [  1   1   1   1   7   2   0   0   1   0   1   0   0  97   0   0   0   0   2   1]
 [  0   0   0   0   2   0   1   0   0   0   0   0  10   0  46   0   0   0   0   0]
 [  0   2   0   0   8   0   0   1   0   0   0   0   1   0   0  84   0   1   1   0]
 [  0   0   0   0   3   3   0   0   0   0   2   1   3   0   0   0  42   3   6   0]
 [  0   0   1   0   2   2   0   0   1   0   1   0   0   0   0   0   0  89   1   0]
 [  1   0   3   0   2   2   2   0   0   1   0   0   3   1   1   0   0   1  87   0]
 [  0   0   2   0   4   4   2   0   1   0   2   0   1   0   0   0   0   1   0 122]]

2025-04-28 01:27:53,249 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:27:53,249 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:27:53,257 - 

2025-04-28 01:27:53,257 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:28:15,877 - Epoch: [98][   90/   90]    Overall Loss 0.108257    Objective Loss 0.108257    Top1 95.683453    Top5 100.000000    LR 0.001000    Time 0.251303    
2025-04-28 01:28:15,906 - --- validate (epoch=98)-----------
2025-04-28 01:28:15,906 - 2245 samples (100 per mini-batch)
2025-04-28 01:28:18,221 - Epoch: [98][   23/   23]    Loss 0.365011    Top1 91.403118    Top5 98.574610    
2025-04-28 01:28:18,240 - ==> Top1: 91.403    Top5: 98.575    Loss: 0.365

2025-04-28 01:28:18,241 - ==> Confusion:
[[ 99   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   2]
 [  0 108   0   0   1   2   0   2   0   1   1   1   0   0   0   1   2   0   1   0]
 [  0   0  99   0   1   0   1   0   0   0   1   0   0   0   0   0   0   0   0   1]
 [  1   1   0 130   0   2   0   5   0   3   0   1   0   1   0   0   1   0   3   1]
 [  1   1   0   0 189   0   0   0   0   0   0   0   2   0   2   0   0   0   2   1]
 [  0   1   0   0   1  71   0   2   0   0   1   0   2   0   0   1   0   0   1   8]
 [  1   1   2   0   0   0 113   1   0   0   5   0   0   0   1   1   0   0   0   3]
 [  0   0   1   0   0   0   0 101   0   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   1   0   0   0   1   0 211   0   0   0   0   0   0   0   0   0   1   1]
 [  1   1   0   1   0   0   0   2   0  79   0   2   0   0   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   0   0   2   1]
 [  2   1   0   0   0   0   0   2   0   0   0  74   0   1   0   0   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   1   0  77   0   1   0   0   0   2   1]
 [  0   3   0   4   0   0   0   5   0   7   0   1   0  94   0   0   0   0   1   0]
 [  0   0   0   0   1   0   0   0   0   0   1   0   3   0  54   0   0   0   0   0]
 [  0   1   0   1   1   0   0   9   0   0   0   0   1   0   0  84   0   0   1   0]
 [  0   1   0   1   1   1   0   0   0   0   2   1   0   0   0   0  53   1   2   0]
 [  1   0   1   0   0   2   0   2   0   0   3   0   0   0   0   0   1  81   6   0]
 [  1   1   0   0   0   1   0   0   1   1   0   0   0   0   0   0   0   2  96   1]
 [  1   0   0   0   1   4   1   1   0   0   2   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:28:18,243 - ==> Best [Top1: 92.205   Top5: 99.065   Params: 306880 on epoch: 75]
2025-04-28 01:28:18,243 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:28:18,250 - 

2025-04-28 01:28:18,251 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:28:40,615 - Epoch: [99][   90/   90]    Overall Loss 0.085004    Objective Loss 0.085004    Top1 98.561151    Top5 100.000000    LR 0.001000    Time 0.248470    
2025-04-28 01:28:40,645 - --- validate (epoch=99)-----------
2025-04-28 01:28:40,646 - 2245 samples (100 per mini-batch)
2025-04-28 01:28:42,909 - Epoch: [99][   23/   23]    Loss 0.323219    Top1 92.917595    Top5 98.663697    
2025-04-28 01:28:42,933 - ==> Top1: 92.918    Top5: 98.664    Loss: 0.323

2025-04-28 01:28:42,933 - ==> Confusion:
[[ 98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   3]
 [  0 109   1   0   0   0   1   5   0   0   0   1   0   0   0   1   1   0   1   0]
 [  0   0  98   0   2   0   1   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 137   0   1   0   0   0   0   0   1   0   3   0   1   0   0   6   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   2   1]
 [  0   0   1   0   1  72   0   2   0   0   0   1   1   0   0   0   1   0   0   9]
 [  0   0   0   0   1   0 117   0   1   0   0   0   0   0   2   1   0   0   0   6]
 [  0   1   1   0   0   0   0 100   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   2   0   2   0   2   0  77   0   0   0   0   0   0   0   0   2   0]
 [  0   1   1   0   0   0   0   0   1   0 108   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   1   0   0   0   0   1  75   0   1   0   0   1   0   0   0]
 [  0   0   2   0   0   0   0   0   0   0   0   0  76   0   3   0   0   1   0   1]
 [  0   0   0   1   1   1   0   3   0   0   0   0   0 107   0   0   1   0   0   1]
 [  0   0   1   0   0   0   0   0   0   0   0   0   2   0  55   0   0   0   0   1]
 [  0   1   0   2   4   0   0   4   1   0   0   0   0   0   1  85   0   0   0   0]
 [  0   0   0   1   0   2   0   0   0   1   1   0   0   0   0   0  55   1   2   0]
 [  1   0   0   0   1   2   0   0   1   0   1   0   0   0   0   0   0  87   4   0]
 [  2   0   1   0   1   1   0   0   0   1   0   0   1   1   1   0   0   1  94   0]
 [  0   0   1   0   1   4   1   0   0   0   3   0   0   0   0   0   1   0   0 128]]

2025-04-28 01:28:42,935 - ==> Best [Top1: 92.918   Top5: 98.664   Params: 306880 on epoch: 99]
2025-04-28 01:28:42,935 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:28:42,946 - 

2025-04-28 01:28:42,946 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:29:05,550 - Epoch: [100][   90/   90]    Overall Loss 0.059955    Objective Loss 0.059955    Top1 98.561151    Top5 99.280576    LR 0.000500    Time 0.251128    
2025-04-28 01:29:05,585 - --- validate (epoch=100)-----------
2025-04-28 01:29:05,586 - 2245 samples (100 per mini-batch)
2025-04-28 01:29:07,930 - Epoch: [100][   23/   23]    Loss 0.259613    Top1 94.342984    Top5 98.797327    
2025-04-28 01:29:07,949 - ==> Top1: 94.343    Top5: 98.797    Loss: 0.260

2025-04-28 01:29:07,950 - ==> Confusion:
[[ 97   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   2   1   1]
 [  0 113   1   0   0   0   1   1   0   0   0   1   0   0   0   1   2   0   0   0]
 [  0   0  97   0   3   0   2   0   0   0   0   0   0   0   0   0   0   1   0   0]
 [  0   1   0 139   0   0   0   0   0   0   0   1   0   3   1   1   1   0   2   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   2  73   0   0   0   1   0   0   0   0   0   1   1   1   0   9]
 [  0   0   0   0   0   0 123   0   0   0   1   0   0   0   1   0   1   0   0   2]
 [  0   1   1   0   0   0   0  99   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   2   0   1   0   1   0  77   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  0   1   0   0   0   1   0   0   0   0   0  74   0   1   0   0   3   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   2   0   0   0   1   0   0   0   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  54   0   0   0   3   0]
 [  0   1   0   2   1   0   0   2   0   0   0   0   0   0   0  91   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0   2   0   0   0   0  57   1   1   0]
 [  0   2   0   0   0   1   0   0   0   0   2   0   0   0   0   0   1  89   2   0]
 [  0   2   0   0   1   0   0   0   0   2   0   0   0   1   0   1   1   3  93   0]
 [  0   0   0   0   1   4   1   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 01:29:07,952 - ==> Best [Top1: 94.343   Top5: 98.797   Params: 306880 on epoch: 100]
2025-04-28 01:29:07,952 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:29:07,962 - 

2025-04-28 01:29:07,963 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:29:30,522 - Epoch: [101][   90/   90]    Overall Loss 0.041534    Objective Loss 0.041534    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.250628    
2025-04-28 01:29:30,552 - --- validate (epoch=101)-----------
2025-04-28 01:29:30,552 - 2245 samples (100 per mini-batch)
2025-04-28 01:29:32,801 - Epoch: [101][   23/   23]    Loss 0.262785    Top1 94.432071    Top5 98.930958    
2025-04-28 01:29:32,828 - ==> Top1: 94.432    Top5: 98.931    Loss: 0.263

2025-04-28 01:29:32,828 - ==> Confusion:
[[ 96   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   1   3]
 [  0 113   1   0   0   0   0   1   0   0   1   0   0   0   0   1   2   0   1   0]
 [  0   0  98   0   1   0   2   0   0   0   1   0   0   0   0   0   0   0   0   1]
 [  0   0   0 141   0   0   0   0   0   0   0   1   0   3   0   0   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   1   0   0   1   1]
 [  0   0   0   0   0  75   0   0   0   0   0   0   1   0   0   1   1   0   0  10]
 [  0   0   0   0   0   0 121   0   1   0   1   0   0   0   1   1   0   0   0   3]
 [  0   0   0   0   0   0   0  98   0   2   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   1   0   0   0   0   0  80   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   1   0   0   0   0   2  74   0   1   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   2   0   0   0   0   0   3   1   0   0 108   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   3   0   0   1   0   0   0   0   0   0   0  89   0   0   2   0]
 [  0   1   0   1   1   1   0   0   0   0   0   1   0   0   0   0  56   1   1   0]
 [  0   0   0   0   0   1   0   0   0   0   2   0   0   0   0   0   1  89   4   0]
 [  2   0   0   0   1   0   0   0   0   2   0   0   1   1   0   0   1   2  94   0]
 [  0   0   0   0   1   4   1   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 01:29:32,831 - ==> Best [Top1: 94.432   Top5: 98.931   Params: 306880 on epoch: 101]
2025-04-28 01:29:32,831 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:29:32,842 - 

2025-04-28 01:29:32,842 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:29:55,501 - Epoch: [102][   90/   90]    Overall Loss 0.034427    Objective Loss 0.034427    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.251735    
2025-04-28 01:29:55,539 - --- validate (epoch=102)-----------
2025-04-28 01:29:55,539 - 2245 samples (100 per mini-batch)
2025-04-28 01:29:57,818 - Epoch: [102][   23/   23]    Loss 0.258616    Top1 94.565702    Top5 99.109131    
2025-04-28 01:29:57,843 - ==> Top1: 94.566    Top5: 99.109    Loss: 0.259

2025-04-28 01:29:57,844 - ==> Confusion:
[[ 98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   2]
 [  0 114   1   0   0   0   0   1   0   0   0   1   0   0   0   1   2   0   0   0]
 [  0   0  97   0   2   0   2   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 141   0   0   0   0   0   0   0   1   0   4   0   0   0   0   3   0]
 [  0   0   0   0 195   0   0   0   0   0   0   0   1   0   1   0   0   0   0   1]
 [  0   0   0   0   2  75   0   0   0   0   0   0   1   0   0   1   1   1   0   7]
 [  0   0   0   1   1   0 120   0   1   0   1   0   0   0   1   1   0   0   0   2]
 [  0   1   0   0   0   0   0  98   0   1   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   2   0   0   0   0   0  80   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  0   1   0   1   0   0   0   0   0   0   0  75   0   3   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   1   0   0   0 112   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  1   1   0   2   4   0   0   1   0   0   0   0   0   0   0  89   0   0   0   0]
 [  0   1   0   1   2   0   0   0   0   0   0   2   0   0   0   0  55   1   1   0]
 [  0   1   0   1   0   1   0   0   0   0   2   0   0   0   0   0   1  90   1   0]
 [  2   0   0   0   2   0   0   0   0   1   0   0   0   2   0   0   1   3  93   0]
 [  1   0   0   0   1   4   1   0   0   0   3   0   0   0   0   0   1   0   0 128]]

2025-04-28 01:29:57,846 - ==> Best [Top1: 94.566   Top5: 99.109   Params: 306880 on epoch: 102]
2025-04-28 01:29:57,846 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:29:57,856 - 

2025-04-28 01:29:57,856 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:30:20,432 - Epoch: [103][   90/   90]    Overall Loss 0.027475    Objective Loss 0.027475    Top1 98.561151    Top5 100.000000    LR 0.000500    Time 0.250811    
2025-04-28 01:30:20,461 - --- validate (epoch=103)-----------
2025-04-28 01:30:20,461 - 2245 samples (100 per mini-batch)
2025-04-28 01:30:22,795 - Epoch: [103][   23/   23]    Loss 0.263579    Top1 94.432071    Top5 98.797327    
2025-04-28 01:30:22,818 - ==> Top1: 94.432    Top5: 98.797    Loss: 0.264

2025-04-28 01:30:22,818 - ==> Confusion:
[[ 96   0   0   0   0   1   0   0   2   0   0   0   0   0   0   0   0   1   0   2]
 [  0 113   1   0   0   0   1   1   0   0   0   0   0   0   0   1   2   0   1   0]
 [  0   1  95   0   2   0   3   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 139   0   0   0   0   0   0   0   2   0   3   0   0   0   0   5   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   1   1   1   0]
 [  0   0   0   0   1  77   0   0   0   0   0   0   1   0   0   1   1   1   0   6]
 [  0   0   0   0   0   0 122   0   1   0   1   0   0   0   1   1   0   0   0   2]
 [  0   0   1   0   0   0   0  98   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   1   0   0   0   0   0  80   0   2   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   1   0   0   0   0   0  74   0   1   0   0   2   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   2   0   0   0 111   0   0   1   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   3   0   0   1   0   0   0   0   0   0   1  90   0   0   0   0]
 [  0   2   0   1   0   0   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   0   0   1   0   1   0   0   0   0   2   0   0   0   0   0   1  91   1   0]
 [  0   1   0   0   1   0   0   0   0   1   1   0   1   1   0   0   1   2  94   1]
 [  1   0   1   0   1   4   2   0   0   0   3   0   0   0   0   0   0   0   0 127]]

2025-04-28 01:30:22,820 - ==> Best [Top1: 94.566   Top5: 99.109   Params: 306880 on epoch: 102]
2025-04-28 01:30:22,820 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:30:22,828 - 

2025-04-28 01:30:22,828 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:30:45,507 - Epoch: [104][   90/   90]    Overall Loss 0.029550    Objective Loss 0.029550    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.251965    
2025-04-28 01:30:45,534 - --- validate (epoch=104)-----------
2025-04-28 01:30:45,534 - 2245 samples (100 per mini-batch)
2025-04-28 01:30:47,799 - Epoch: [104][   23/   23]    Loss 0.257637    Top1 94.298441    Top5 98.975501    
2025-04-28 01:30:47,824 - ==> Top1: 94.298    Top5: 98.976    Loss: 0.258

2025-04-28 01:30:47,825 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   2   0   1]
 [  0 113   1   0   0   0   0   1   0   0   0   0   0   0   0   1   3   0   1   0]
 [  0   0  97   0   2   1   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   3   0 137   0   0   0   0   0   0   0   1   0   3   0   0   0   0   5   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   1   0   1   1]
 [  0   0   0   0   0  75   0   0   0   0   0   0   1   0   0   1   1   2   0   8]
 [  0   0   0   0   0   0 122   0   1   0   1   0   0   0   1   0   0   0   0   3]
 [  0   1   1   0   0   0   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   1   0   1   1   0   0  79   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   1   0   0   0   0   1  75   0   1   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   1   0 110   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  56   0   0   0   1   0]
 [  0   1   0   2   2   0   0   2   0   0   0   0   0   0   0  89   0   0   2   0]
 [  0   1   0   1   0   1   0   0   0   0   0   2   0   0   0   0  56   1   1   0]
 [  0   2   0   0   0   1   0   0   0   0   2   0   0   0   0   0   1  89   2   0]
 [  2   0   0   0   0   0   0   0   0   1   0   0   1   1   0   0   1   2  96   0]
 [  2   0   0   0   1   5   2   0   0   0   2   0   0   0   0   0   0   0   0 127]]

2025-04-28 01:30:47,827 - ==> Best [Top1: 94.566   Top5: 99.109   Params: 306880 on epoch: 102]
2025-04-28 01:30:47,827 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:30:47,834 - 

2025-04-28 01:30:47,834 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:31:10,378 - Epoch: [105][   90/   90]    Overall Loss 0.027701    Objective Loss 0.027701    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.250461    
2025-04-28 01:31:10,405 - --- validate (epoch=105)-----------
2025-04-28 01:31:10,405 - 2245 samples (100 per mini-batch)
2025-04-28 01:31:12,736 - Epoch: [105][   23/   23]    Loss 0.263131    Top1 94.120267    Top5 98.930958    
2025-04-28 01:31:12,757 - ==> Top1: 94.120    Top5: 98.931    Loss: 0.263

2025-04-28 01:31:12,758 - ==> Confusion:
[[ 96   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   1   0   3]
 [  0 110   1   0   0   0   0   1   0   0   2   1   0   0   0   1   3   0   1   0]
 [  0   0  98   0   2   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0 136   0   0   0   0   0   0   0   3   0   4   0   0   0   0   3   1]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   2  74   0   0   0   0   0   0   1   0   0   1   1   0   0   9]
 [  0   0   0   0   0   0 120   0   0   0   2   0   0   0   1   1   0   0   0   4]
 [  0   1   1   0   0   0   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   0   0   0   0   0   1]
 [  1   1   0   1   0   1   0   0   0  79   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   0   0   1   0   0   0   0   1  75   0   2   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   1   1   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   2   0   0   2   0   0   0   0   0   0   0  90   0   0   1   0]
 [  0   1   0   1   3   0   0   0   0   0   0   1   1   0   0   0  54   1   1   0]
 [  0   2   0   1   0   1   0   0   0   0   2   0   0   0   0   1   0  89   1   0]
 [  1   1   0   0   1   0   0   0   0   1   0   0   0   1   0   0   0   3  96   0]
 [  0   0   0   0   2   3   1   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 01:31:12,760 - ==> Best [Top1: 94.566   Top5: 99.109   Params: 306880 on epoch: 102]
2025-04-28 01:31:12,760 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:31:12,769 - 

2025-04-28 01:31:12,769 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:31:35,443 - Epoch: [106][   90/   90]    Overall Loss 0.026457    Objective Loss 0.026457    Top1 98.561151    Top5 100.000000    LR 0.000500    Time 0.251906    
2025-04-28 01:31:35,476 - --- validate (epoch=106)-----------
2025-04-28 01:31:35,476 - 2245 samples (100 per mini-batch)
2025-04-28 01:31:37,858 - Epoch: [106][   23/   23]    Loss 0.279865    Top1 94.164811    Top5 98.975501    
2025-04-28 01:31:37,880 - ==> Top1: 94.165    Top5: 98.976    Loss: 0.280

2025-04-28 01:31:37,881 - ==> Confusion:
[[ 97   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   1   2]
 [  0 111   1   0   0   0   1   1   0   0   1   1   0   0   0   1   2   0   1   0]
 [  0   0  97   0   2   0   2   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   1   0 137   0   0   0   0   0   0   0   1   0   3   0   1   1   0   4   1]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   1   2]
 [  0   0   0   0   2  73   0   0   0   0   0   0   1   0   0   1   0   1   0  10]
 [  0   0   0   0   0   0 122   0   1   0   1   0   0   0   1   0   0   0   0   3]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   1   0   1   1   0   0  79   0   1   0   0   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   2   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   1   0   1   0   0   0   0   1   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   4   0   0   1   0   0   0   0   0   0   0  89   0   0   1   0]
 [  0   1   0   1   1   0   0   0   0   0   0   2   0   0   0   0  56   1   1   0]
 [  0   0   0   2   0   1   0   0   0   0   2   0   0   0   0   0   1  88   3   0]
 [  2   0   0   0   1   0   0   0   0   1   0   0   1   1   0   0   0   2  96   0]
 [  1   0   1   0   1   4   1   0   0   0   3   0   0   0   0   0   0   0   0 128]]

2025-04-28 01:31:37,883 - ==> Best [Top1: 94.566   Top5: 99.109   Params: 306880 on epoch: 102]
2025-04-28 01:31:37,883 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:31:37,890 - 

2025-04-28 01:31:37,890 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:32:00,611 - Epoch: [107][   90/   90]    Overall Loss 0.027855    Objective Loss 0.027855    Top1 97.841727    Top5 100.000000    LR 0.000500    Time 0.252428    
2025-04-28 01:32:00,642 - --- validate (epoch=107)-----------
2025-04-28 01:32:00,642 - 2245 samples (100 per mini-batch)
2025-04-28 01:32:02,954 - Epoch: [107][   23/   23]    Loss 0.264418    Top1 94.610245    Top5 98.975501    
2025-04-28 01:32:02,974 - ==> Top1: 94.610    Top5: 98.976    Loss: 0.264

2025-04-28 01:32:02,974 - ==> Confusion:
[[ 97   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   1   1   1   1]
 [  0 113   1   0   0   0   0   1   0   0   1   0   0   0   0   1   2   0   1   0]
 [  0   0  95   0   2   0   3   0   3   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 138   0   0   0   0   0   0   0   2   0   3   0   1   1   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   1   0   1   1]
 [  0   0   0   0   3  78   0   0   0   0   0   0   1   0   0   1   1   1   0   3]
 [  0   0   0   0   0   0 123   0   0   0   1   0   0   0   1   0   0   0   0   3]
 [  0   0   0   0   0   1   0  97   0   1   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   1   0   0   1   0   0  79   1   1   0   0   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 112   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   1  74   0   1   0   1   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   1   1   0   0 111   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   2   2   0   0   1   0   0   0   0   0   0   0  91   0   0   1   0]
 [  0   1   0   0   1   0   0   0   0   0   0   3   0   0   0   0  56   1   1   0]
 [  0   0   0   1   0   1   0   0   0   0   2   0   0   0   0   0   1  89   3   0]
 [  2   1   0   0   2   0   0   0   0   1   0   0   0   1   0   0   0   2  95   0]
 [  1   0   0   0   1   4   1   0   0   0   2   0   0   0   0   0   0   0   0 130]]

2025-04-28 01:32:02,976 - ==> Best [Top1: 94.610   Top5: 98.976   Params: 306880 on epoch: 107]
2025-04-28 01:32:02,977 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:32:02,987 - 

2025-04-28 01:32:02,987 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:32:25,490 - Epoch: [108][   90/   90]    Overall Loss 0.026820    Objective Loss 0.026820    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.250002    
2025-04-28 01:32:25,523 - --- validate (epoch=108)-----------
2025-04-28 01:32:25,523 - 2245 samples (100 per mini-batch)
2025-04-28 01:32:27,861 - Epoch: [108][   23/   23]    Loss 0.269570    Top1 94.521158    Top5 98.975501    
2025-04-28 01:32:27,883 - ==> Top1: 94.521    Top5: 98.976    Loss: 0.270

2025-04-28 01:32:27,884 - ==> Confusion:
[[ 95   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   1   1   1   2]
 [  0 113   1   0   0   0   0   1   0   0   0   1   0   0   0   1   2   0   1   0]
 [  0   0  97   0   2   0   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 143   0   0   0   0   0   0   0   0   0   3   0   0   0   0   2   1]
 [  0   0   0   0 195   0   0   0   0   0   0   0   1   0   0   0   1   0   1   0]
 [  0   0   0   0   1  78   0   0   0   0   0   0   0   0   0   1   1   1   0   6]
 [  0   0   0   0   0   1 121   0   1   0   1   0   0   0   0   1   0   0   0   3]
 [  0   0   0   0   0   1   0  98   0   1   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   2   0   2   0   0   0  77   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   1   1   0]
 [  0   1   0   1   0   0   0   0   0   0   0  75   0   2   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   1   0   0   0   1   1   0   0 111   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   2   3   0   0   2   0   0   0   0   0   0   0  89   0   0   1   0]
 [  0   1   0   1   2   1   0   0   0   0   0   1   0   0   0   0  54   2   1   0]
 [  0   0   0   1   0   2   0   0   0   0   2   0   0   0   0   0   1  88   3   0]
 [  1   1   0   0   2   1   0   0   0   1   0   0   0   1   0   0   1   3  93   0]
 [  0   0   0   0   1   4   1   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 01:32:27,886 - ==> Best [Top1: 94.610   Top5: 98.976   Params: 306880 on epoch: 107]
2025-04-28 01:32:27,886 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:32:27,894 - 

2025-04-28 01:32:27,894 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:32:50,401 - Epoch: [109][   90/   90]    Overall Loss 0.025502    Objective Loss 0.025502    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.250055    
2025-04-28 01:32:50,428 - --- validate (epoch=109)-----------
2025-04-28 01:32:50,428 - 2245 samples (100 per mini-batch)
2025-04-28 01:32:52,744 - Epoch: [109][   23/   23]    Loss 0.270335    Top1 94.877506    Top5 98.975501    
2025-04-28 01:32:52,769 - ==> Top1: 94.878    Top5: 98.976    Loss: 0.270

2025-04-28 01:32:52,770 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   1   1   0   1]
 [  0 112   1   0   0   0   0   1   0   0   0   1   0   0   0   1   3   0   1   0]
 [  0   0  98   0   1   1   2   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 138   0   0   0   0   0   0   0   3   0   4   0   1   0   0   3   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   1   0   1   1   1   0   1   1]
 [  0   0   0   0   2  79   0   1   0   0   0   0   0   0   0   1   1   0   0   4]
 [  0   0   0   0   0   0 122   0   1   0   1   0   0   0   0   1   0   0   0   3]
 [  0   0   1   0   0   0   0  99   0   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   1   0   1   0   0   0  78   0   3   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   1   1   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   2   1   0   0   2   0   0   0   0   0   0   0  91   0   0   1   0]
 [  0   1   0   0   2   1   0   0   0   0   0   2   0   0   0   0  55   1   1   0]
 [  0   0   0   1   0   1   0   0   0   0   1   0   0   0   0   0   1  92   1   0]
 [  1   0   0   0   1   1   0   0   0   1   0   0   0   1   0   0   1   2  96   0]
 [  0   0   0   0   1   4   1   0   0   0   3   0   0   0   0   0   1   0   0 129]]

2025-04-28 01:32:52,772 - ==> Best [Top1: 94.878   Top5: 98.976   Params: 306880 on epoch: 109]
2025-04-28 01:32:52,772 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:32:52,782 - 

2025-04-28 01:32:52,782 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:33:15,359 - Epoch: [110][   90/   90]    Overall Loss 0.023330    Objective Loss 0.023330    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.250830    
2025-04-28 01:33:15,386 - --- validate (epoch=110)-----------
2025-04-28 01:33:15,387 - 2245 samples (100 per mini-batch)
2025-04-28 01:33:17,707 - Epoch: [110][   23/   23]    Loss 0.261572    Top1 94.788419    Top5 99.109131    
2025-04-28 01:33:17,732 - ==> Top1: 94.788    Top5: 99.109    Loss: 0.262

2025-04-28 01:33:17,732 - ==> Confusion:
[[ 97   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   1   2]
 [  0 113   1   0   0   1   0   1   0   0   0   1   0   0   0   1   1   0   1   0]
 [  0   0  97   0   1   1   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 142   0   0   0   0   0   0   0   2   0   2   0   0   0   0   3   0]
 [  0   0   0   1 192   0   0   0   0   0   0   0   1   0   1   1   0   0   2   0]
 [  0   0   0   0   0  80   0   0   0   0   0   0   0   0   0   2   0   0   0   6]
 [  0   0   0   0   1   0 123   0   1   0   1   0   0   0   0   1   0   0   0   1]
 [  0   0   0   1   0   1   0  98   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   2   0   0   1   0   0  77   1   2   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   1  75   0   1   0   0   1   1   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   2   0   1   0   0   0   1   1   1   0 108   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   2   2   0   0   2   0   0   0   0   0   0   0  90   0   0   1   0]
 [  0   1   0   1   1   1   0   0   0   0   0   1   0   0   0   0  55   1   2   0]
 [  0   0   0   0   0   2   0   0   0   0   2   0   0   0   0   0   1  90   2   0]
 [  1   0   0   0   1   1   0   0   0   1   0   0   0   1   0   0   0   2  97   0]
 [  0   0   0   0   1   4   2   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:33:17,735 - ==> Best [Top1: 94.878   Top5: 98.976   Params: 306880 on epoch: 109]
2025-04-28 01:33:17,735 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:33:17,742 - 

2025-04-28 01:33:17,742 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:33:40,333 - Epoch: [111][   90/   90]    Overall Loss 0.021405    Objective Loss 0.021405    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.250984    
2025-04-28 01:33:40,363 - --- validate (epoch=111)-----------
2025-04-28 01:33:40,363 - 2245 samples (100 per mini-batch)
2025-04-28 01:33:42,620 - Epoch: [111][   23/   23]    Loss 0.285180    Top1 93.986637    Top5 99.064588    
2025-04-28 01:33:42,641 - ==> Top1: 93.987    Top5: 99.065    Loss: 0.285

2025-04-28 01:33:42,642 - ==> Confusion:
[[ 93   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   7]
 [  0 111   1   0   0   0   0   1   0   1   1   0   0   1   0   1   1   0   2   0]
 [  0   0  98   0   1   0   2   0   1   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 141   0   0   0   0   0   0   0   2   0   3   0   0   0   0   3   0]
 [  0   0   0   1 191   0   0   0   0   0   0   0   1   0   1   0   0   0   2   2]
 [  0   0   0   0   0  73   0   0   0   0   0   0   0   0   0   1   0   0   1  13]
 [  0   0   0   0   0   1 116   0   1   0   1   0   0   0   1   1   0   0   0   7]
 [  0   1   0   0   0   0   0  97   0   1   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   1   0   0   0   0   0  80   0   0   0   0   0   0   2   0   1   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  0   1   0   1   0   0   0   0   0   0   1  75   0   2   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   1   0   0   0 112   0   0   1   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  54   0   0   0   0   2]
 [  1   1   0   1   2   0   0   2   1   0   0   0   0   0   0  89   0   0   1   0]
 [  0   0   0   1   0   2   0   0   0   1   1   1   0   0   0   0  55   0   1   1]
 [  0   1   0   2   0   0   0   0   0   0   2   0   0   0   0   0   1  90   1   0]
 [  0   2   0   0   0   0   0   0   0   1   0   0   0   1   0   0   2   2  94   2]
 [  0   0   0   0   1   3   1   0   0   0   1   0   0   0   0   0   0   0   0 133]]

2025-04-28 01:33:42,644 - ==> Best [Top1: 94.878   Top5: 98.976   Params: 306880 on epoch: 109]
2025-04-28 01:33:42,644 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:33:42,652 - 

2025-04-28 01:33:42,652 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:34:05,304 - Epoch: [112][   90/   90]    Overall Loss 0.025443    Objective Loss 0.025443    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.251665    
2025-04-28 01:34:05,334 - --- validate (epoch=112)-----------
2025-04-28 01:34:05,334 - 2245 samples (100 per mini-batch)
2025-04-28 01:34:07,576 - Epoch: [112][   23/   23]    Loss 0.263051    Top1 94.877506    Top5 99.020045    
2025-04-28 01:34:07,601 - ==> Top1: 94.878    Top5: 99.020    Loss: 0.263

2025-04-28 01:34:07,601 - ==> Confusion:
[[ 99   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   2]
 [  0 113   1   0   0   0   0   1   0   1   0   0   0   0   0   1   2   0   1   0]
 [  0   0  98   0   0   1   2   0   0   0   0   0   0   0   0   1   0   1   0   0]
 [  0   0   0 138   0   0   0   0   0   0   0   2   0   4   0   1   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   2   1]
 [  0   0   0   0   1  78   0   0   0   0   0   0   0   0   0   1   1   0   0   7]
 [  0   0   0   0   0   0 122   0   0   0   2   0   0   0   1   1   0   0   0   2]
 [  0   0   0   1   0   0   0  98   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   1   0   0   0   0   0  80   0   3   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   1   0   0   0   0   0   0   1  75   0   1   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   2   0   0   0   1   0   1   0   0   0 111   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  56   0   0   0   1   0]
 [  0   1   0   2   0   0   0   2   0   0   0   0   0   0   0  93   0   0   0   0]
 [  0   0   0   1   2   0   0   0   0   1   1   1   0   0   0   0  56   0   1   0]
 [  1   1   0   1   0   1   0   0   0   0   2   0   0   0   0   0   1  89   1   0]
 [  1   0   0   0   0   1   0   0   0   1   0   0   1   2   0   0   1   2  95   0]
 [  0   0   0   1   1   4   2   0   0   0   2   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:34:07,604 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:34:07,604 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:34:07,614 - 

2025-04-28 01:34:07,614 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:34:30,259 - Epoch: [113][   90/   90]    Overall Loss 0.026357    Objective Loss 0.026357    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.251584    
2025-04-28 01:34:30,290 - --- validate (epoch=113)-----------
2025-04-28 01:34:30,291 - 2245 samples (100 per mini-batch)
2025-04-28 01:34:32,506 - Epoch: [113][   23/   23]    Loss 0.267724    Top1 94.743875    Top5 99.064588    
2025-04-28 01:34:32,528 - ==> Top1: 94.744    Top5: 99.065    Loss: 0.268

2025-04-28 01:34:32,528 - ==> Confusion:
[[ 97   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   1   0   2]
 [  0 111   0   1   1   1   0   1   0   0   0   0   0   0   0   1   3   0   1   0]
 [  0   0  97   0   2   0   3   0   0   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 144   0   0   0   0   0   0   0   0   0   2   0   1   0   0   2   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   1   0   1   0]
 [  0   0   0   0   1  80   0   0   0   0   0   0   0   0   0   2   0   0   0   5]
 [  0   0   0   0   1   0 122   0   0   0   1   0   0   0   1   1   0   0   0   2]
 [  0   0   0   0   0   1   0  98   0   0   2   0   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   0   0   0  77   1   1   0   1   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   0   0   1]
 [  1   0   0   0   1   0   0   0   0   0   0   0  79   0   2   0   0   0   0   0]
 [  0   0   0   2   0   0   0   0   0   0   0   1   0 110   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   1   0  58   0   0   0   0   0]
 [  0   1   0   2   4   0   0   1   0   0   0   0   0   0   0  89   0   0   1   0]
 [  0   2   0   1   1   0   0   0   0   0   0   1   0   0   0   0  56   1   1   0]
 [  0   0   0   2   0   1   0   0   0   0   2   0   0   0   0   0   1  89   2   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   2   0   0   1   2  94   1]
 [  0   0   0   0   1   4   1   0   0   0   1   0   0   0   0   0   0   0   0 132]]

2025-04-28 01:34:32,530 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:34:32,531 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:34:32,538 - 

2025-04-28 01:34:32,538 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:34:55,225 - Epoch: [114][   90/   90]    Overall Loss 0.028989    Objective Loss 0.028989    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.252050    
2025-04-28 01:34:55,253 - --- validate (epoch=114)-----------
2025-04-28 01:34:55,253 - 2245 samples (100 per mini-batch)
2025-04-28 01:34:57,606 - Epoch: [114][   23/   23]    Loss 0.297229    Top1 94.120267    Top5 98.841871    
2025-04-28 01:34:57,627 - ==> Top1: 94.120    Top5: 98.842    Loss: 0.297

2025-04-28 01:34:57,627 - ==> Confusion:
[[ 98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   2]
 [  0 114   1   0   0   0   0   1   0   2   0   0   0   0   0   1   1   0   0   0]
 [  0   1  94   0   0   0   2   0   4   0   0   0   0   0   0   1   0   0   0   1]
 [  0   0   0 140   0   0   0   0   0   0   0   1   0   3   0   1   0   0   3   1]
 [  1   2   0   0 190   2   0   0   0   0   0   0   0   0   0   0   0   0   2   1]
 [  0   1   0   0   1  74   0   0   0   0   0   0   0   0   0   2   0   1   0   9]
 [  0   0   0   0   0   1 121   0   1   0   1   0   0   0   1   0   0   0   0   3]
 [  0   0   0   0   0   0   0  99   0   1   1   0   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   2   0   0   0   0   0  81   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   1   0   0   0   2 108   0   0   0   0   0   1   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  76   0   3   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   4   0   0   0 110   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  1   2   0   2   0   0   0   3   0   0   0   0   0   0   0  89   0   0   1   0]
 [  0   2   0   1   0   0   0   0   0   2   0   2   0   0   0   0  53   1   1   1]
 [  1   3   0   0   0   1   0   0   0   0   2   0   0   0   0   0   1  88   1   0]
 [  1   2   0   0   0   0   0   0   0   1   0   0   0   1   0   0   0   2  96   1]
 [  1   0   0   0   0   5   2   0   0   0   2   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:34:57,629 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:34:57,630 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:34:57,638 - 

2025-04-28 01:34:57,638 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:35:20,272 - Epoch: [115][   90/   90]    Overall Loss 0.029574    Objective Loss 0.029574    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.251459    
2025-04-28 01:35:20,297 - --- validate (epoch=115)-----------
2025-04-28 01:35:20,297 - 2245 samples (100 per mini-batch)
2025-04-28 01:35:22,651 - Epoch: [115][   23/   23]    Loss 0.268118    Top1 94.253898    Top5 99.242762    
2025-04-28 01:35:22,671 - ==> Top1: 94.254    Top5: 99.243    Loss: 0.268

2025-04-28 01:35:22,672 - ==> Confusion:
[[ 91   0   1   0   0   1   1   0   0   0   2   0   0   0   0   0   0   1   0   5]
 [  0 113   1   0   0   0   1   1   0   0   1   0   0   0   0   1   1   0   1   0]
 [  0   0  98   0   1   0   2   0   1   0   0   0   0   0   0   1   0   0   0   0]
 [  0   1   0 143   0   0   0   0   0   0   0   1   0   2   0   0   0   0   2   0]
 [  0   1   0   0 190   0   0   0   0   0   1   0   1   0   1   0   1   0   2   1]
 [  0   0   0   0   0  79   0   0   0   0   1   0   0   0   0   1   0   0   0   7]
 [  0   0   0   0   0   0 124   0   1   0   1   0   0   0   1   0   0   0   0   1]
 [  0   0   0   0   0   0   0  99   0   0   2   0   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   1   0 214   0   1   0   0   0   0   0   0   0   0   0]
 [  1   0   0   2   0   1   1   0   0  78   1   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   1   0   0   0   0   0   0   1  75   0   1   0   0   1   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   1   0   3   0   1   0 107   0   0   0   0   0   2]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   2   0   1   1   0   0   1   1   0   0   0   0   0   0  90   0   0   2   0]
 [  0   2   0   1   0   1   0   0   0   0   0   1   1   0   0   0  54   1   2   0]
 [  0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   1   0  87   3   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   1   1   0   0   0   2  97   1]
 [  0   0   0   0   0   4   2   0   0   0   5   0   0   0   0   0   0   0   0 128]]

2025-04-28 01:35:22,674 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:35:22,674 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:35:22,682 - 

2025-04-28 01:35:22,682 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:35:45,371 - Epoch: [116][   90/   90]    Overall Loss 0.030782    Objective Loss 0.030782    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.252075    
2025-04-28 01:35:45,395 - --- validate (epoch=116)-----------
2025-04-28 01:35:45,395 - 2245 samples (100 per mini-batch)
2025-04-28 01:35:47,700 - Epoch: [116][   23/   23]    Loss 0.258825    Top1 94.788419    Top5 99.109131    
2025-04-28 01:35:47,722 - ==> Top1: 94.788    Top5: 99.109    Loss: 0.259

2025-04-28 01:35:47,723 - ==> Confusion:
[[ 99   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3]
 [  0 114   0   0   0   0   0   1   0   0   0   1   0   0   0   1   1   0   1   1]
 [  0   0  97   0   2   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0 138   0   0   0   0   0   0   0   4   0   3   0   0   0   0   3   0]
 [  0   0   0   0 196   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0]
 [  0   0   0   0   1  77   0   0   0   0   0   0   0   0   0   1   0   0   0   9]
 [  0   0   0   0   0   0 125   0   0   0   1   0   0   0   0   0   0   0   0   2]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   2   0   0   1   0   0  79   0   2   0   0   0   0   1   0   0   0]
 [  0   1   0   1   0   0   0   0   0   0 111   0   0   0   0   0   0   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  76   0   1   0   0   2   0   0   1]
 [  1   0   0   0   1   0   0   0   0   0   0   0  79   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   1   0   1   0   0   0 111   0   0   0   0   0   1]
 [  0   0   0   0   0   0   1   0   0   0   0   0   1   0  56   0   0   0   1   0]
 [  0   1   0   2   2   0   0   1   0   0   0   0   0   0   0  90   0   0   2   0]
 [  0   2   0   0   2   0   0   0   0   0   0   2   0   0   0   0  54   1   1   1]
 [  0   2   0   1   0   1   0   0   0   0   2   0   0   0   0   0   0  88   3   0]
 [  1   0   0   0   0   1   0   0   0   1   0   0   1   2   0   0   0   2  96   0]
 [  0   0   0   0   0   4   1   0   0   0   4   0   0   0   0   0   0   0   0 130]]

2025-04-28 01:35:47,725 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:35:47,725 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:35:47,733 - 

2025-04-28 01:35:47,733 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:36:10,298 - Epoch: [117][   90/   90]    Overall Loss 0.029235    Objective Loss 0.029235    Top1 98.561151    Top5 100.000000    LR 0.000500    Time 0.250692    
2025-04-28 01:36:10,321 - --- validate (epoch=117)-----------
2025-04-28 01:36:10,321 - 2245 samples (100 per mini-batch)
2025-04-28 01:36:12,615 - Epoch: [117][   23/   23]    Loss 0.283570    Top1 94.565702    Top5 98.841871    
2025-04-28 01:36:12,641 - ==> Top1: 94.566    Top5: 98.842    Loss: 0.284

2025-04-28 01:36:12,642 - ==> Confusion:
[[ 98   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 112   0   0   1   0   1   3   0   0   0   0   0   0   0   1   1   0   1   0]
 [  0   0  93   0   2   0   6   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 144   0   0   0   0   0   0   0   0   0   2   0   1   0   0   2   0]
 [  0   0   0   0 195   0   0   0   0   0   0   0   1   0   0   0   0   0   1   1]
 [  0   0   0   0   3  77   1   0   0   0   0   0   0   0   0   2   0   0   0   5]
 [  0   0   0   0   0   0 126   0   0   0   1   0   0   0   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0  99   0   0   2   0   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   4   0   1   0   0   0  78   0   2   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   1   0   0   0 110   0   0   0   0   0   1   1   0   0]
 [  0   1   0   1   0   1   0   0   0   0   0  76   0   1   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   3   1   1   0   1   0   1   0   0   0 108   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   4   0   0   1   1   0   0   0   0   0   0  89   0   0   1   0]
 [  0   1   0   0   2   1   0   0   0   0   0   3   1   0   0   0  53   1   1   0]
 [  1   1   0   0   0   2   0   0   0   0   2   0   0   0   0   0   1  88   2   0]
 [  1   0   1   0   2   1   0   0   0   1   0   0   1   1   0   0   1   1  94   0]
 [  0   0   0   0   1   4   2   0   0   0   1   0   0   0   0   0   0   0   0 131]]

2025-04-28 01:36:12,644 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:36:12,644 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:36:12,651 - 

2025-04-28 01:36:12,651 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:36:35,195 - Epoch: [118][   90/   90]    Overall Loss 0.031691    Objective Loss 0.031691    Top1 98.561151    Top5 100.000000    LR 0.000500    Time 0.250459    
2025-04-28 01:36:35,220 - --- validate (epoch=118)-----------
2025-04-28 01:36:35,221 - 2245 samples (100 per mini-batch)
2025-04-28 01:36:37,529 - Epoch: [118][   23/   23]    Loss 0.287118    Top1 94.031180    Top5 99.109131    
2025-04-28 01:36:37,556 - ==> Top1: 94.031    Top5: 99.109    Loss: 0.287

2025-04-28 01:36:37,557 - ==> Confusion:
[[ 96   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   5]
 [  0 113   0   0   1   0   0   1   0   0   2   0   0   0   0   1   2   0   0   0]
 [  0   0  98   0   2   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0 139   0   1   0   0   0   0   0   1   0   3   0   0   0   0   3   1]
 [  0   1   0   0 189   1   0   0   0   0   0   0   2   0   0   0   2   0   2   1]
 [  0   0   0   0   2  74   0   0   0   0   0   0   0   0   0   1   1   0   0  10]
 [  0   1   1   0   1   0 116   0   1   0   2   1   0   0   1   0   0   0   0   4]
 [  0   2   0   0   0   0   0  96   0   0   2   0   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   2   0   1   0   0   0  77   1   3   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   1  76   0   1   0   0   1   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0  79   0   1   0   1   1   1   0]
 [  0   0   0   0   0   0   0   0   0   1   0   0   0 112   0   0   0   0   1   1]
 [  0   1   0   0   0   0   0   0   0   0   0   0   2   0  56   0   0   0   0   0]
 [  0   2   0   1   1   0   0   1   1   0   0   0   0   0   0  90   0   0   2   0]
 [  0   1   0   0   0   0   0   0   0   0   0   3   0   0   0   0  57   1   1   0]
 [  0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   0   1  88   2   0]
 [  1   0   0   0   1   1   0   0   0   1   0   0   0   1   0   0   0   2  97   0]
 [  0   0   0   0   0   4   0   0   0   0   4   0   0   0   0   0   0   0   0 131]]

2025-04-28 01:36:37,559 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:36:37,559 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:36:37,568 - 

2025-04-28 01:36:37,569 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:37:00,203 - Epoch: [119][   90/   90]    Overall Loss 0.027202    Objective Loss 0.027202    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.251462    
2025-04-28 01:37:00,229 - --- validate (epoch=119)-----------
2025-04-28 01:37:00,229 - 2245 samples (100 per mini-batch)
2025-04-28 01:37:02,552 - Epoch: [119][   23/   23]    Loss 0.277977    Top1 94.342984    Top5 99.020045    
2025-04-28 01:37:02,571 - ==> Top1: 94.343    Top5: 99.020    Loss: 0.278

2025-04-28 01:37:02,571 - ==> Confusion:
[[ 95   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   5]
 [  0 114   0   0   0   0   1   2   0   0   0   0   0   0   0   0   1   0   1   1]
 [  0   0  98   0   1   0   2   0   1   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 142   0   1   0   0   0   0   0   1   0   2   0   0   0   0   3   0]
 [  0   0   0   0 192   2   0   0   0   0   0   0   1   0   0   0   1   0   1   1]
 [  0   0   0   0   1  73   0   0   0   0   0   0   0   0   0   0   0   0   0  14]
 [  0   0   0   0   0   0 123   0   0   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   1   0   0  77   1   1   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 113   0   0   0   0   0   0   1   0   0]
 [  0   1   0   1   0   1   0   0   0   0   1  74   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  80   0   1   0   0   0   2   0]
 [  0   0   0   0   0   0   0   1   0   4   0   0   0 108   0   0   0   0   0   2]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   1   3   0   0   1   1   0   0   0   0   0   0  89   0   0   2   0]
 [  0   2   0   1   0   1   0   0   0   0   1   0   0   0   0   0  56   0   1   1]
 [  1   1   0   2   0   2   0   0   0   0   2   0   0   0   0   0   0  87   2   0]
 [  1   0   0   0   0   1   0   0   0   1   0   0   2   1   0   0   0   1  97   0]
 [  0   0   0   0   0   4   2   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 01:37:02,573 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:37:02,573 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:37:02,581 - 

2025-04-28 01:37:02,581 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:37:25,247 - Epoch: [120][   90/   90]    Overall Loss 0.031404    Objective Loss 0.031404    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.251825    
2025-04-28 01:37:25,272 - --- validate (epoch=120)-----------
2025-04-28 01:37:25,273 - 2245 samples (100 per mini-batch)
2025-04-28 01:37:27,595 - Epoch: [120][   23/   23]    Loss 0.277311    Top1 94.565702    Top5 99.109131    
2025-04-28 01:37:27,620 - ==> Top1: 94.566    Top5: 99.109    Loss: 0.277

2025-04-28 01:37:27,621 - ==> Confusion:
[[ 92   0   0   1   1   0   1   0   0   0   0   0   0   0   2   0   1   1   0   3]
 [  0 116   1   0   0   0   0   1   0   0   0   0   0   0   0   1   1   0   0   0]
 [  0   0  98   0   2   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 138   0   0   0   0   0   0   0   3   0   3   0   1   1   0   3   0]
 [  0   0   1   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   2   0]
 [  0   1   0   0   0  78   0   0   0   0   0   1   1   0   0   2   0   0   0   5]
 [  0   1   1   1   1   1 118   0   0   0   2   0   0   0   1   1   1   0   0   0]
 [  0   1   0   0   0   0   0  97   0   0   2   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   2   0   2   0   0   0  78   0   0   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   1  76   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   2   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   1   1   0   0 111   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   3   1   0   1   0   0   0   0   0   0   0  91   0   0   0   0]
 [  0   2   0   1   0   1   0   0   0   0   0   0   0   0   0   0  57   0   2   0]
 [  0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1  92   1   0]
 [  1   1   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   3  94   0]
 [  0   0   0   0   2   2   1   0   0   0   2   0   0   0   0   1   0   0   0 131]]

2025-04-28 01:37:27,623 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:37:27,623 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:37:27,630 - 

2025-04-28 01:37:27,630 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:37:50,255 - Epoch: [121][   90/   90]    Overall Loss 0.031187    Objective Loss 0.031187    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.251353    
2025-04-28 01:37:50,281 - --- validate (epoch=121)-----------
2025-04-28 01:37:50,281 - 2245 samples (100 per mini-batch)
2025-04-28 01:37:52,579 - Epoch: [121][   23/   23]    Loss 0.291459    Top1 94.031180    Top5 99.064588    
2025-04-28 01:37:52,611 - ==> Top1: 94.031    Top5: 99.065    Loss: 0.291

2025-04-28 01:37:52,611 - ==> Confusion:
[[ 96   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   1   1   2]
 [  0 114   1   0   0   0   0   1   0   0   0   0   0   0   0   2   2   0   0   0]
 [  0   0  96   0   1   0   1   0   2   0   1   0   0   0   0   0   0   0   0   2]
 [  0   0   0 142   0   0   0   0   0   0   0   2   0   2   0   1   0   0   2   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   0   0   0   0   2   1]
 [  0   0   0   0   1  73   0   0   0   0   1   1   1   0   0   2   0   0   1   8]
 [  1   0   1   0   1   1 115   0   1   0   3   0   0   0   1   0   0   0   0   4]
 [  0   0   0   1   0   0   0  94   0   1   2   0   0   1   0   3   0   0   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   2   0   0   0  77   1   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  0   1   0   1   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   1   0   3   0   1   0   0   0   0   1   0   0 109   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   3   0  55   0   0   0   0   0]
 [  0   1   0   2   1   0   0   1   0   0   0   0   0   0   0  92   1   0   0   0]
 [  0   1   0   0   0   2   0   0   0   0   0   0   0   0   0   0  58   1   1   0]
 [  0   0   0   0   0   3   0   0   0   0   3   0   0   0   0   0   1  89   1   0]
 [  1   2   0   0   1   3   0   0   0   1   0   0   0   1   0   0   0   1  94   0]
 [  0   0   0   0   0   3   0   0   0   0   5   0   0   0   0   0   0   1   0 130]]

2025-04-28 01:37:52,614 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:37:52,614 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:37:52,621 - 

2025-04-28 01:37:52,621 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:38:15,431 - Epoch: [122][   90/   90]    Overall Loss 0.043443    Objective Loss 0.043443    Top1 97.841727    Top5 100.000000    LR 0.000500    Time 0.253416    
2025-04-28 01:38:15,457 - --- validate (epoch=122)-----------
2025-04-28 01:38:15,457 - 2245 samples (100 per mini-batch)
2025-04-28 01:38:17,758 - Epoch: [122][   23/   23]    Loss 0.295206    Top1 94.209354    Top5 98.797327    
2025-04-28 01:38:17,780 - ==> Top1: 94.209    Top5: 98.797    Loss: 0.295

2025-04-28 01:38:17,780 - ==> Confusion:
[[ 98   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 112   0   0   0   0   2   1   0   1   1   0   0   0   0   1   1   0   0   1]
 [  0   0  98   0   2   0   1   0   0   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0 137   0   0   1   0   0   0   0   3   0   4   0   1   0   0   3   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   1   0   1   0   0   0   2   2]
 [  2   0   0   0   1  76   0   0   0   0   0   1   0   0   0   1   0   1   0   6]
 [  0   0   0   0   0   0 124   0   0   0   1   0   0   0   0   0   0   0   0   3]
 [  0   0   0   1   0   0   0  98   0   1   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   4   0   1   0   0   0  76   1   1   0   1   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   1  74   0   1   0   0   1   2   0   0]
 [  1   0   0   0   1   0   0   0   0   0   0   0  80   0   1   0   0   0   0   0]
 [  0   0   0   2   0   1   0   0   0   0   1   0   0 109   0   0   1   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   1   0   0   0   0   0   0  91   0   0   1   0]
 [  0   1   0   1   1   1   0   0   0   0   0   2   0   0   0   0  54   2   1   0]
 [  1   0   0   1   0   1   0   0   0   0   1   1   0   0   0   0   0  91   1   0]
 [  1   1   0   0   1   1   0   0   0   1   1   0   0   1   0   0   0   1  95   1]
 [  5   0   1   0   1   2   1   0   0   0   2   0   0   0   1   0   0   0   0 126]]

2025-04-28 01:38:17,782 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:38:17,783 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:38:17,790 - 

2025-04-28 01:38:17,790 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:38:40,368 - Epoch: [123][   90/   90]    Overall Loss 0.033012    Objective Loss 0.033012    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.250842    
2025-04-28 01:38:40,398 - --- validate (epoch=123)-----------
2025-04-28 01:38:40,398 - 2245 samples (100 per mini-batch)
2025-04-28 01:38:42,746 - Epoch: [123][   23/   23]    Loss 0.319516    Top1 94.120267    Top5 98.752784    
2025-04-28 01:38:42,770 - ==> Top1: 94.120    Top5: 98.753    Loss: 0.320

2025-04-28 01:38:42,771 - ==> Confusion:
[[ 96   0   0   2   0   1   0   0   0   0   0   0   0   0   1   0   1   0   0   1]
 [  0 113   0   0   0   0   1   1   0   0   0   0   0   0   0   1   2   0   1   1]
 [  0   0  97   0   3   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   1   0   0   0   0   1   0   3   0   0   0   0   4   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   0   2   0]
 [  0   0   0   0   1  76   0   0   0   0   0   1   1   0   0   1   1   0   0   7]
 [  0   0   0   0   0   1 123   0   0   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   0   0   0   0   0  99   0   1   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   3   0   1   0   0   0  76   1   0   0   1   0   0   2   0   1   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   1   0   0   0   0   0   0   1  73   0   1   0   1   1   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   2   0   0   0   0   0   1   1   0   0 110   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   4   0   0   2   0   0   1   0   0   0   0  87   0   0   1   0]
 [  0   1   0   1   0   0   0   0   0   0   0   2   1   0   0   0  54   2   2   0]
 [  1   2   0   1   0   1   0   0   0   0   3   0   0   0   0   0   0  86   3   0]
 [  1   0   0   0   0   1   0   0   0   1   0   0   2   1   0   0   0   1  97   0]
 [  0   0   1   0   1   5   1   0   0   0   3   0   0   0   0   0   0   0   0 128]]

2025-04-28 01:38:42,773 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:38:42,773 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:38:42,781 - 

2025-04-28 01:38:42,781 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:39:05,389 - Epoch: [124][   90/   90]    Overall Loss 0.040856    Objective Loss 0.040856    Top1 97.122302    Top5 100.000000    LR 0.000500    Time 0.251180    
2025-04-28 01:39:05,417 - --- validate (epoch=124)-----------
2025-04-28 01:39:05,418 - 2245 samples (100 per mini-batch)
2025-04-28 01:39:07,710 - Epoch: [124][   23/   23]    Loss 0.305450    Top1 93.719376    Top5 98.797327    
2025-04-28 01:39:07,734 - ==> Top1: 93.719    Top5: 98.797    Loss: 0.305

2025-04-28 01:39:07,734 - ==> Confusion:
[[ 95   0   0   0   0   0   1   0   0   0   0   0   0   0   1   0   1   1   1   2]
 [  0 114   0   0   0   0   1   1   0   0   0   0   0   0   0   1   1   0   1   1]
 [  0   1  94   0   2   0   4   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 136   0   0   1   0   0   0   0   3   0   4   0   1   0   0   4   0]
 [  0   1   0   0 192   1   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   0  75   0   0   0   0   0   0   1   0   1   1   1   1   0   8]
 [  0   0   0   1   0   1 120   0   1   0   2   1   0   0   1   0   0   0   0   1]
 [  0   1   0   0   0   0   0  98   0   0   1   0   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   1   0   0   0  76   1   2   0   0   0   0   2   0   0   0]
 [  0   2   0   0   0   1   0   0   0   0 110   0   0   0   0   0   0   0   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  77   0   1   0   0   0   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   1   0   1   0   1   0   0   0 109   0   0   0   0   0   2]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   0   2   0   0   1   1   0   0   0   0   0   0  91   0   0   2   0]
 [  0   1   0   0   0   3   0   0   0   0   0   2   0   0   0   0  55   1   1   0]
 [  0   0   0   2   0   2   0   1   0   0   2   0   0   0   1   0   1  86   2   0]
 [  1   0   0   0   2   1   0   1   0   0   1   0   1   2   0   0   0   0  95   0]
 [  1   0   1   0   0   5   1   0   0   0   2   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:39:07,736 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:39:07,736 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:39:07,744 - 

2025-04-28 01:39:07,744 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:39:30,429 - Epoch: [125][   90/   90]    Overall Loss 0.038862    Objective Loss 0.038862    Top1 98.561151    Top5 100.000000    LR 0.000500    Time 0.252025    
2025-04-28 01:39:30,455 - --- validate (epoch=125)-----------
2025-04-28 01:39:30,456 - 2245 samples (100 per mini-batch)
2025-04-28 01:39:32,888 - Epoch: [125][   23/   23]    Loss 0.322772    Top1 93.630290    Top5 98.752784    
2025-04-28 01:39:32,916 - ==> Top1: 93.630    Top5: 98.753    Loss: 0.323

2025-04-28 01:39:32,916 - ==> Confusion:
[[ 96   0   0   0   1   3   0   0   0   0   0   0   0   0   0   0   1   0   0   1]
 [  0 114   0   0   0   0   0   1   0   0   0   1   0   1   0   1   2   0   0   0]
 [  0   2  94   1   1   2   2   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 142   0   0   0   0   0   0   0   1   0   3   0   0   0   0   3   0]
 [  0   1   0   0 192   2   0   0   0   0   0   0   1   0   0   0   0   0   1   1]
 [  0   0   0   0   1  78   0   0   0   0   0   0   0   0   0   1   0   1   0   7]
 [  0   0   2   1   1   1 115   0   0   0   2   1   0   0   1   0   0   0   0   4]
 [  0   0   0   0   0   1   0  98   1   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0   3   0   2   0   1   0  76   0   1   0   1   0   0   2   0   0   0]
 [  0   1   0   0   0   1   0   0   0   0 110   0   0   0   0   0   1   1   0   0]
 [  1   1   0   2   0   0   0   1   0   0   0  72   0   1   0   0   2   1   0   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0  80   0   0   0   0   1   0   0]
 [  0   0   0   1   0   1   0   0   0   0   0   0   0 110   0   0   2   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   1   0   0   0   0   0   0  91   0   0   1   0]
 [  0   1   0   1   1   2   0   0   0   0   1   0   0   0   0   0  56   1   0   0]
 [  0   1   0   2   0   2   0   0   0   0   2   0   0   0   0   0   1  88   1   0]
 [  0   0   0   0   1   4   0   0   0   0   0   0   0   2   0   0   1   3  92   1]
 [  0   0   0   1   0   9   0   0   0   0   2   0   0   0   0   0   0   0   0 127]]

2025-04-28 01:39:32,918 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:39:32,918 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:39:32,925 - 

2025-04-28 01:39:32,926 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:39:55,545 - Epoch: [126][   90/   90]    Overall Loss 0.037024    Objective Loss 0.037024    Top1 98.561151    Top5 100.000000    LR 0.000500    Time 0.251305    
2025-04-28 01:39:55,572 - --- validate (epoch=126)-----------
2025-04-28 01:39:55,572 - 2245 samples (100 per mini-batch)
2025-04-28 01:39:57,896 - Epoch: [126][   23/   23]    Loss 0.294360    Top1 93.942094    Top5 98.975501    
2025-04-28 01:39:57,919 - ==> Top1: 93.942    Top5: 98.976    Loss: 0.294

2025-04-28 01:39:57,919 - ==> Confusion:
[[ 96   0   0   0   0   0   1   0   0   0   0   0   0   0   1   0   0   1   0   3]
 [  0 114   0   0   0   0   0   1   0   1   0   0   0   1   0   0   2   0   1   0]
 [  0   1  95   0   2   0   3   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 138   0   0   0   1   0   0   0   2   0   4   0   0   0   0   4   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  1   0   0   0   3  75   0   0   0   0   0   0   0   0   1   1   0   0   0   7]
 [  0   0   0   0   2   0 121   0   1   0   1   0   0   0   1   0   0   0   0   2]
 [  0   1   0   1   0   0   0  98   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 214   0   0   0   0   0   0   0   1   0   1   0]
 [  1   0   0   3   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  2   1   0   0   0   0   0   0   0   0   0  74   0   1   0   0   2   0   1   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   1   0   0   0 111   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   3   0   0   1   0   0   0   0   0   0   0  90   0   0   1   0]
 [  0   0   0   0   1   2   0   0   0   1   0   2   0   0   0   0  56   0   1   0]
 [  1   1   0   2   0   1   0   0   0   0   2   0   0   0   0   0   2  87   1   0]
 [  1   0   0   0   2   1   0   0   0   0   0   0   0   2   0   0   2   2  94   0]
 [  2   0   0   0   1   5   1   0   0   0   3   0   0   0   0   0   0   0   0 127]]

2025-04-28 01:39:57,921 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:39:57,922 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:39:57,929 - 

2025-04-28 01:39:57,929 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:40:20,725 - Epoch: [127][   90/   90]    Overall Loss 0.045174    Objective Loss 0.045174    Top1 97.841727    Top5 100.000000    LR 0.000500    Time 0.253260    
2025-04-28 01:40:20,750 - --- validate (epoch=127)-----------
2025-04-28 01:40:20,750 - 2245 samples (100 per mini-batch)
2025-04-28 01:40:23,070 - Epoch: [127][   23/   23]    Loss 0.320337    Top1 93.318486    Top5 98.619154    
2025-04-28 01:40:23,092 - ==> Top1: 93.318    Top5: 98.619    Loss: 0.320

2025-04-28 01:40:23,093 - ==> Confusion:
[[ 91   0   1   0   1   3   1   0   0   0   0   0   0   0   0   0   0   0   1   4]
 [  0 111   0   1   1   0   1   3   0   1   1   0   0   0   0   0   0   0   1   0]
 [  0   0  98   0   2   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0 144   0   0   0   0   0   0   0   1   0   1   0   0   0   0   2   0]
 [  0   0   0   0 191   1   0   0   0   0   0   0   1   0   1   0   1   0   1   2]
 [  0   0   0   0   0  77   0   0   0   0   0   0   0   0   0   2   1   0   0   8]
 [  0   0   2   0   0   0 118   0   0   0   3   0   0   0   0   0   0   0   0   5]
 [  0   0   2   0   0   0   0  98   0   1   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   3   0   1   0   0   0  77   1   1   0   0   0   0   1   0   0   0]
 [  0   0   0   1   0   0   0   0   0   1 110   0   0   0   0   0   0   1   1   0]
 [  1   1   0   3   0   0   0   0   0   0   0  73   0   1   0   0   1   0   1   0]
 [  0   0   1   0   0   1   0   0   0   0   0   0  80   0   0   0   0   0   1   0]
 [  0   0   0   4   0   0   0   0   0   4   1   1   0 104   0   0   0   0   0   1]
 [  0   0   1   0   1   0   1   1   0   0   1   0   2   0  52   0   0   0   0   0]
 [  0   1   0   1   1   1   0   1   0   0   0   0   0   0   0  92   0   0   1   0]
 [  0   2   0   1   0   0   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   1   0   1   0   2   0   0   0   0   3   0   0   0   0   0   0  88   2   0]
 [  0   0   0   1   1   2   0   0   0   1   0   0   1   2   0   0   1   1  92   2]
 [  0   0   4   0   1   4   1   0   0   0   2   0   0   0   0   0   0   0   1 126]]

2025-04-28 01:40:23,095 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:40:23,095 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:40:23,102 - 

2025-04-28 01:40:23,103 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:40:45,617 - Epoch: [128][   90/   90]    Overall Loss 0.040359    Objective Loss 0.040359    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.250134    
2025-04-28 01:40:45,647 - --- validate (epoch=128)-----------
2025-04-28 01:40:45,647 - 2245 samples (100 per mini-batch)
2025-04-28 01:40:47,979 - Epoch: [128][   23/   23]    Loss 0.312725    Top1 93.897550    Top5 98.841871    
2025-04-28 01:40:48,005 - ==> Top1: 93.898    Top5: 98.842    Loss: 0.313

2025-04-28 01:40:48,005 - ==> Confusion:
[[ 93   1   0   1   1   0   1   0   0   0   1   0   0   0   0   0   0   1   1   2]
 [  0 114   0   0   0   1   1   1   0   0   0   0   0   0   0   1   2   0   0   0]
 [  0   0  98   0   1   0   2   0   0   0   1   0   0   0   0   0   0   0   0   1]
 [  0   0   0 142   0   0   0   0   0   0   0   0   0   2   0   1   0   0   4   0]
 [  0   1   0   0 186   1   0   0   0   0   3   0   2   0   1   0   1   0   2   1]
 [  0   1   0   0   1  76   0   0   0   0   1   0   0   0   0   1   0   2   0   6]
 [  0   0   0   0   0   0 120   0   1   0   2   0   0   0   0   0   0   0   0   5]
 [  0   0   1   0   0   0   0  98   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   1   0   2   0   1   0  79   0   0   0   0   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 113   0   0   0   0   0   0   1   0   0]
 [  1   2   0   1   0   0   0   0   0   0   1  72   0   1   0   1   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   3   0   0   0   0   0   4   1   0   0 107   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   3   0   0   1   0   0   0   0   0   0   0  90   1   0   1   0]
 [  0   2   0   0   0   2   0   0   0   0   0   0   0   0   0   0  58   1   0   0]
 [  1   2   0   0   0   1   0   0   0   1   2   0   0   0   0   0   0  88   2   0]
 [  0   1   0   0   0   2   0   0   0   1   1   0   1   1   0   0   0   2  93   2]
 [  0   0   0   0   0   5   1   0   0   0   4   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:40:48,007 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:40:48,007 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:40:48,015 - 

2025-04-28 01:40:48,015 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:41:10,722 - Epoch: [129][   90/   90]    Overall Loss 0.029142    Objective Loss 0.029142    Top1 98.561151    Top5 100.000000    LR 0.000500    Time 0.252273    
2025-04-28 01:41:10,750 - --- validate (epoch=129)-----------
2025-04-28 01:41:10,751 - 2245 samples (100 per mini-batch)
2025-04-28 01:41:13,035 - Epoch: [129][   23/   23]    Loss 0.346544    Top1 93.452116    Top5 98.797327    
2025-04-28 01:41:13,057 - ==> Top1: 93.452    Top5: 98.797    Loss: 0.347

2025-04-28 01:41:13,057 - ==> Confusion:
[[ 96   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   1   3]
 [  0 114   0   0   1   1   0   1   0   0   0   0   0   0   0   1   1   0   1   0]
 [  0   0  97   0   2   0   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   2 128   1   0   3   2   0   0   0   2   0   3   0   2   1   0   5   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   1   0   1   0   0   0   3   1]
 [  1   0   0   0   2  72   1   0   0   0   0   1   0   0   0   1   0   0   1   9]
 [  0   0   0   0   1   0 124   0   1   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   1   0   0   0   0  98   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   1   1   0   0  75   1   1   0   1   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   2   0   0   0   0   0   0   0   0   1  73   0   1   0   0   1   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  79   0   2   0   0   0   2   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0 112   0   0   0   0   1   1]
 [  0   0   1   0   0   0   0   0   0   0   0   0   2   0  55   0   0   0   1   0]
 [  0   1   0   0   4   0   0   1   1   0   0   0   0   0   0  90   0   0   1   0]
 [  0   2   0   0   0   0   0   0   0   0   0   1   0   0   0   0  57   1   2   0]
 [  1   2   0   0   0   0   0   0   0   0   2   1   0   0   0   0   1  88   2   0]
 [  1   0   0   0   0   1   1   0   0   1   0   0   0   1   0   0   1   2  95   1]
 [  0   0   3   0   2   3   2   0   0   0   2   0   0   0   0   0   0   0   0 127]]

2025-04-28 01:41:13,059 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:41:13,059 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:41:13,067 - 

2025-04-28 01:41:13,067 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:41:35,708 - Epoch: [130][   90/   90]    Overall Loss 0.033051    Objective Loss 0.033051    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.251547    
2025-04-28 01:41:35,739 - --- validate (epoch=130)-----------
2025-04-28 01:41:35,739 - 2245 samples (100 per mini-batch)
2025-04-28 01:41:38,055 - Epoch: [130][   23/   23]    Loss 0.317160    Top1 93.630290    Top5 98.752784    
2025-04-28 01:41:38,081 - ==> Top1: 93.630    Top5: 98.753    Loss: 0.317

2025-04-28 01:41:38,082 - ==> Confusion:
[[ 96   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   1   0   3]
 [  0 115   1   0   0   0   0   1   0   1   0   0   0   0   0   1   1   0   0   0]
 [  0   1  96   0   1   0   2   0   1   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 140   0   0   0   1   0   0   0   3   0   3   0   0   0   0   2   0]
 [  0   1   0   0 188   1   0   0   0   0   1   0   2   0   1   0   0   1   1   2]
 [  0   0   0   0   3  70   0   1   0   0   0   1   0   0   0   0   0   0   1  12]
 [  0   0   0   0   0   0 118   0   1   0   1   1   0   0   0   0   0   0   0   7]
 [  0   1   1   0   0   0   0  99   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   0   0   0  78   0   2   0   0   0   0   1   0   0   0]
 [  0   2   0   0   0   0   0   0   0   1 108   0   0   0   0   0   0   2   0   1]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   0   1   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   1   0  78   0   1   0   0   1   1   1]
 [  0   0   0   1   0   0   0   1   0   0   0   0   0 112   0   0   0   0   0   1]
 [  0   0   1   0   0   0   0   0   0   0   0   0   2   0  54   0   0   0   0   2]
 [  0   1   0   1   3   0   0   3   1   0   0   0   0   0   0  87   0   0   2   0]
 [  0   2   0   0   0   1   0   0   0   0   1   1   0   0   0   0  56   1   1   0]
 [  0   2   0   0   0   1   0   0   0   0   1   0   0   0   0   0   0  92   1   0]
 [  0   0   0   1   2   1   0   0   0   0   0   0   0   3   0   0   1   3  91   2]
 [  0   0   0   0   0   2   1   0   0   0   3   0   0   0   0   0   0   0   0 133]]

2025-04-28 01:41:38,084 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:41:38,084 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:41:38,092 - 

2025-04-28 01:41:38,092 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:42:00,703 - Epoch: [131][   90/   90]    Overall Loss 0.028747    Objective Loss 0.028747    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.251212    
2025-04-28 01:42:00,730 - --- validate (epoch=131)-----------
2025-04-28 01:42:00,730 - 2245 samples (100 per mini-batch)
2025-04-28 01:42:03,065 - Epoch: [131][   23/   23]    Loss 0.291705    Top1 94.298441    Top5 99.020045    
2025-04-28 01:42:03,087 - ==> Top1: 94.298    Top5: 99.020    Loss: 0.292

2025-04-28 01:42:03,087 - ==> Confusion:
[[ 97   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   1   1   1]
 [  0 113   1   0   0   0   0   2   0   0   0   1   0   0   0   1   1   0   1   0]
 [  0   1  97   0   1   0   2   0   1   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 140   0   0   0   0   0   0   0   2   0   3   0   0   0   0   4   0]
 [  0   1   0   0 189   1   0   0   0   0   0   0   2   0   1   0   1   0   1   2]
 [  0   0   0   0   0  78   0   0   0   0   0   1   0   0   0   1   1   0   0   7]
 [  0   0   0   1   0   0 120   0   0   0   2   0   0   0   1   1   0   0   0   3]
 [  0   1   1   0   0   0   0  99   0   0   1   0   0   0   0   0   0   0   0   0]
 [  1   0   0   0   0   0   1   0 214   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   1   0   0   0  78   0   2   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   2   0   0   0   1   0   0   0   0   1  74   0   1   0   0   1   0   0   0]
 [  1   0   0   0   1   0   0   0   0   0   0   0  81   0   0   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   1   0   0   0 112   0   0   0   0   1   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   1   0   0   0   0   0   0  91   0   0   1   0]
 [  0   2   0   1   0   1   0   0   0   0   1   1   0   0   0   0  55   1   1   0]
 [  0   1   0   1   0   2   0   0   0   0   2   0   0   0   0   0   0  90   1   0]
 [  1   0   0   0   0   1   0   0   0   1   0   1   2   2   0   0   0   1  95   0]
 [  1   0   0   0   1   5   1   0   0   0   3   0   0   0   0   0   0   0   0 128]]

2025-04-28 01:42:03,089 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:42:03,089 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:42:03,097 - 

2025-04-28 01:42:03,097 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:42:25,678 - Epoch: [132][   90/   90]    Overall Loss 0.032069    Objective Loss 0.032069    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.250869    
2025-04-28 01:42:25,706 - --- validate (epoch=132)-----------
2025-04-28 01:42:25,707 - 2245 samples (100 per mini-batch)
2025-04-28 01:42:28,046 - Epoch: [132][   23/   23]    Loss 0.323495    Top1 93.363029    Top5 98.797327    
2025-04-28 01:42:28,071 - ==> Top1: 93.363    Top5: 98.797    Loss: 0.323

2025-04-28 01:42:28,071 - ==> Confusion:
[[ 95   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   1   2   2]
 [  0 114   0   0   1   0   0   1   0   1   0   0   0   0   0   1   1   0   1   0]
 [  0   1  98   0   1   0   1   0   0   0   0   0   0   0   0   1   0   1   0   0]
 [  0   0   0 135   0   0   0   1   0   0   0   2   0   4   0   1   0   0   6   0]
 [  0   1   0   1 188   0   0   0   0   0   0   0   2   0   1   0   1   0   3   1]
 [  0   1   0   0   2  70   0   1   0   0   0   1   1   0   0   2   1   1   1   7]
 [  0   0   2   1   0   0 117   0   0   0   2   0   0   0   1   1   0   0   1   3]
 [  0   1   0   0   0   0   0  98   0   2   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   3   0   1   0   0   0  76   0   0   0   0   0   1   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 108   1   0   0   0   0   1   1   2   0]
 [  0   1   0   0   0   0   0   0   0   1   0  77   0   0   0   0   2   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0  81   0   0   0   0   0   1   0]
 [  0   0   0   3   0   0   0   0   0   0   0   0   0 111   0   0   0   0   1   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   4   0  52   0   0   0   2   0]
 [  0   1   0   0   0   1   0   1   0   0   0   0   0   0   0  93   0   0   2   0]
 [  0   2   0   0   0   0   0   0   0   0   0   1   0   0   0   0  58   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1  90   3   0]
 [  0   1   0   0   1   0   0   0   0   1   0   0   1   0   0   0   1   2  96   1]
 [  0   1   4   0   2   2   1   0   0   0   3   0   0   0   0   0   0   1   1 124]]

2025-04-28 01:42:28,073 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:42:28,073 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:42:28,081 - 

2025-04-28 01:42:28,081 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:42:50,816 - Epoch: [133][   90/   90]    Overall Loss 0.028940    Objective Loss 0.028940    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.252581    
2025-04-28 01:42:50,844 - --- validate (epoch=133)-----------
2025-04-28 01:42:50,844 - 2245 samples (100 per mini-batch)
2025-04-28 01:42:53,190 - Epoch: [133][   23/   23]    Loss 0.308670    Top1 93.630290    Top5 98.975501    
2025-04-28 01:42:53,215 - ==> Top1: 93.630    Top5: 98.976    Loss: 0.309

2025-04-28 01:42:53,216 - ==> Confusion:
[[ 96   0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   4]
 [  0 116   1   0   0   0   0   1   0   0   0   0   0   0   0   1   0   0   1   0]
 [  0   1  94   0   1   0   2   0   2   0   0   0   0   0   0   0   0   1   1   1]
 [  0   0   0 139   0   0   1   0   0   0   0   2   0   2   0   1   0   0   4   0]
 [  0   0   0   1 191   0   0   0   0   0   0   0   1   0   2   0   0   0   1   2]
 [  0   0   0   0   2  74   1   0   0   0   0   0   0   0   0   1   0   2   1   7]
 [  0   0   0   1   0   0 123   0   0   0   2   0   0   0   0   1   0   0   0   1]
 [  0   1   1   0   0   0   0  97   0   1   1   0   0   0   0   0   0   0   1   0]
 [  1   0   0   0   0   0   1   0 214   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   3   0   1   0   0   0  76   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   1   0   0   0 110   0   0   0   0   0   1   1   0   0]
 [  0   1   0   0   0   0   1   0   0   0   0  74   0   1   0   0   1   3   0   0]
 [  0   0   1   0   0   0   0   0   0   0   1   0  77   0   3   0   0   0   1   0]
 [  0   0   0   3   0   0   0   0   0   2   0   1   0 107   0   0   0   0   2   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   3   0  55   0   0   0   0   0]
 [  0   2   0   1   3   0   0   1   0   0   0   0   0   0   0  90   0   0   1   0]
 [  0   1   0   1   0   0   0   0   0   0   0   2   0   0   0   0  56   2   1   0]
 [  0   1   0   0   0   1   0   0   0   0   3   0   0   0   1   0   0  90   1   0]
 [  0   0   0   1   2   1   0   0   0   1   1   0   1   1   0   0   0   2  92   2]
 [  0   0   0   0   2   1   3   0   0   0   1   0   0   0   0   1   0   0   0 131]]

2025-04-28 01:42:53,218 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:42:53,218 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:42:53,225 - 

2025-04-28 01:42:53,226 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:43:15,851 - Epoch: [134][   90/   90]    Overall Loss 0.031904    Objective Loss 0.031904    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.251369    
2025-04-28 01:43:15,881 - --- validate (epoch=134)-----------
2025-04-28 01:43:15,881 - 2245 samples (100 per mini-batch)
2025-04-28 01:43:18,188 - Epoch: [134][   23/   23]    Loss 0.310837    Top1 94.164811    Top5 98.930958    
2025-04-28 01:43:18,211 - ==> Top1: 94.165    Top5: 98.931    Loss: 0.311

2025-04-28 01:43:18,212 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   2]
 [  0 107   1   0   0   0   0   2   0   0   0   1   0   1   0   2   3   0   3   0]
 [  0   0  98   0   1   0   1   0   1   0   1   0   0   0   0   0   0   0   0   1]
 [  0   0   0 140   0   0   0   0   0   0   0   2   0   1   0   1   0   0   5   0]
 [  0   0   0   0 193   0   0   1   0   0   0   0   0   0   1   0   0   0   1   2]
 [  0   0   0   0   1  77   0   0   0   0   0   0   0   0   1   1   0   1   0   7]
 [  0   0   1   1   0   0 118   0   1   0   1   0   0   0   1   1   0   0   1   3]
 [  0   0   1   0   0   0   0  99   0   0   1   0   0   0   0   1   0   0   0   0]
 [  1   0   0   0   0   0   0   0 214   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   2   0   1   0   1   0  76   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   0  76   0   1   0   1   2   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   1   0  80   0   0   0   0   0   1   0]
 [  0   0   0   2   0   1   0   0   0   1   0   2   0 107   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   0   0   0   0   0   0   0  91   0   0   2   0]
 [  0   0   0   1   1   1   0   0   0   1   0   0   0   0   0   0  56   2   1   0]
 [  0   0   0   1   0   2   0   0   0   0   2   0   0   0   0   1   0  89   2   0]
 [  1   0   0   0   0   1   0   0   0   1   0   1   1   1   0   0   0   3  95   0]
 [  1   0   0   1   1   1   0   0   0   0   2   0   0   0   0   0   0   0   0 133]]

2025-04-28 01:43:18,214 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:43:18,214 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:43:18,223 - 

2025-04-28 01:43:18,223 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:43:40,846 - Epoch: [135][   90/   90]    Overall Loss 0.033286    Objective Loss 0.033286    Top1 97.841727    Top5 100.000000    LR 0.000500    Time 0.251335    
2025-04-28 01:43:40,871 - --- validate (epoch=135)-----------
2025-04-28 01:43:40,871 - 2245 samples (100 per mini-batch)
2025-04-28 01:43:43,203 - Epoch: [135][   23/   23]    Loss 0.330537    Top1 93.808463    Top5 98.841871    
2025-04-28 01:43:43,226 - ==> Top1: 93.808    Top5: 98.842    Loss: 0.331

2025-04-28 01:43:43,226 - ==> Confusion:
[[ 93   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   1   1   5]
 [  0 116   1   0   0   0   0   1   0   0   0   0   0   0   0   1   1   0   0   0]
 [  0   1  96   0   1   0   2   0   1   0   1   0   0   0   0   0   0   0   0   1]
 [  0   0   0 140   0   0   0   0   0   0   0   2   0   2   0   0   1   0   4   0]
 [  0   0   0   0 191   0   0   0   0   0   0   0   1   0   1   0   2   0   1   2]
 [  0   0   0   0   3  77   0   0   0   0   0   0   0   0   0   1   1   2   0   4]
 [  0   1   0   1   0   0 118   0   1   0   2   0   0   0   1   0   0   0   0   4]
 [  0   1   1   2   0   1   0  94   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   2   0   2   0   1   0   0   0  77   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 109   1   0   0   0   0   1   2   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  77   0   0   0   0   2   1   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0  81   0   0   0   0   1   0   0]
 [  0   0   0   3   0   0   0   0   0   0   0   2   0 109   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   0   1]
 [  0   1   0   2   5   1   0   1   0   0   0   0   0   0   0  87   0   0   1   0]
 [  0   1   0   0   1   1   0   0   0   0   0   0   0   0   0   0  57   2   1   0]
 [  0   2   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1  91   1   0]
 [  0   0   0   0   1   1   0   0   0   1   0   1   1   1   0   0   0   3  94   1]
 [  0   0   1   0   3   2   1   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:43:43,228 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:43:43,228 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:43:43,236 - 

2025-04-28 01:43:43,236 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:44:05,924 - Epoch: [136][   90/   90]    Overall Loss 0.032569    Objective Loss 0.032569    Top1 97.122302    Top5 100.000000    LR 0.000500    Time 0.252062    
2025-04-28 01:44:05,953 - --- validate (epoch=136)-----------
2025-04-28 01:44:05,953 - 2245 samples (100 per mini-batch)
2025-04-28 01:44:08,278 - Epoch: [136][   23/   23]    Loss 0.308229    Top1 94.164811    Top5 98.752784    
2025-04-28 01:44:08,304 - ==> Top1: 94.165    Top5: 98.753    Loss: 0.308

2025-04-28 01:44:08,305 - ==> Confusion:
[[ 96   0   0   0   1   1   1   0   0   0   0   0   0   0   0   0   0   0   0   3]
 [  0 113   0   0   0   0   0   2   0   0   0   1   0   0   0   0   2   0   1   1]
 [  0   0  95   0   3   0   2   0   2   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 137   1   0   2   0   0   0   0   2   0   3   0   0   0   0   4   0]
 [  0   0   0   0 191   0   0   0   0   0   0   0   1   0   2   0   1   0   1   2]
 [  0   0   0   0   3  73   0   0   0   0   0   0   0   0   0   1   1   0   0  10]
 [  0   0   0   0   1   0 123   0   0   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   1   0   1   0   0  98   0   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   2   0 214   0   0   0   0   0   0   0   0   0   0   0]
 [  1   2   0   2   0   1   0   0   0  77   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  74   0   1   0   0   1   0   0   3]
 [  1   0   1   0   0   0   0   0   0   0   1   0  79   0   1   0   0   0   0   0]
 [  0   0   0   2   0   0   0   0   0   0   0   0   0 111   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   1   0  58   0   0   0   0   0]
 [  0   1   0   1   0   0   0   1   1   0   0   0   0   0   0  94   0   0   0   0]
 [  0   0   0   0   1   1   0   1   0   0   0   2   0   0   0   0  55   1   2   0]
 [  0   0   0   1   0   2   0   0   0   0   3   0   0   0   0   0   0  88   3   0]
 [  1   0   0   0   0   1   1   0   0   1   1   0   2   2   0   0   0   0  95   0]
 [  0   0   0   0   2   2   1   0   0   0   2   0   0   0   0   0   0   0   0 132]]

2025-04-28 01:44:08,307 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:44:08,307 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:44:08,315 - 

2025-04-28 01:44:08,315 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:44:31,024 - Epoch: [137][   90/   90]    Overall Loss 0.043010    Objective Loss 0.043010    Top1 100.000000    Top5 100.000000    LR 0.000500    Time 0.252294    
2025-04-28 01:44:31,062 - --- validate (epoch=137)-----------
2025-04-28 01:44:31,062 - 2245 samples (100 per mini-batch)
2025-04-28 01:44:33,371 - Epoch: [137][   23/   23]    Loss 0.322009    Top1 93.674833    Top5 98.886414    
2025-04-28 01:44:33,396 - ==> Top1: 93.675    Top5: 98.886    Loss: 0.322

2025-04-28 01:44:33,396 - ==> Confusion:
[[ 96   0   0   0   0   0   1   0   1   0   0   1   0   0   0   0   0   1   1   1]
 [  0 111   0   0   1   0   0   1   0   0   0   4   0   0   0   1   2   0   0   0]
 [  0   1  95   0   2   0   2   0   3   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 139   0   0   0   0   0   0   0   3   0   3   0   1   0   0   3   0]
 [  0   0   0   0 189   1   0   0   0   0   0   0   2   0   1   0   1   0   2   2]
 [  0   0   0   0   2  78   1   0   0   0   0   0   0   0   0   1   1   2   0   3]
 [  0   0   0   1   0   0 119   0   1   0   2   1   0   0   0   0   0   0   0   4]
 [  0   1   1   0   0   0   0  97   0   0   2   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   3   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  77   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   3   0   0   0   0   0   2   0   1   0 108   0   0   0   0   1   0]
 [  0   0   1   0   2   0   0   0   0   0   0   0   4   0  51   0   0   0   0   1]
 [  0   1   0   0   3   1   0   1   0   0   0   0   0   0   0  91   0   0   1   0]
 [  0   1   0   0   0   0   0   0   0   0   0   3   0   0   0   0  55   2   2   0]
 [  0   1   0   1   0   1   0   0   0   0   2   1   0   0   0   0   0  89   2   0]
 [  1   0   0   0   0   1   0   0   0   1   0   1   0   1   0   0   0   2  97   0]
 [  0   0   2   0   3   2   1   0   0   0   2   0   0   0   0   0   0   1   1 127]]

2025-04-28 01:44:33,398 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:44:33,398 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:44:33,406 - 

2025-04-28 01:44:33,406 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:44:56,000 - Epoch: [138][   90/   90]    Overall Loss 0.036179    Objective Loss 0.036179    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.251022    
2025-04-28 01:44:56,026 - --- validate (epoch=138)-----------
2025-04-28 01:44:56,026 - 2245 samples (100 per mini-batch)
2025-04-28 01:44:58,331 - Epoch: [138][   23/   23]    Loss 0.297009    Top1 94.342984    Top5 98.886414    
2025-04-28 01:44:58,357 - ==> Top1: 94.343    Top5: 98.886    Loss: 0.297

2025-04-28 01:44:58,358 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   2]
 [  0 113   0   0   0   0   0   1   0   1   1   0   0   0   0   1   1   0   1   1]
 [  0   0  95   0   2   0   5   0   0   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 138   0   0   1   1   0   0   0   2   0   3   0   0   0   0   4   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   1   1   0]
 [  0   0   0   0   2  78   1   0   0   0   0   0   0   0   0   1   1   1   0   4]
 [  0   0   0   0   1   0 122   0   0   0   1   0   0   0   1   0   0   0   0   3]
 [  0   0   1   0   0   0   0  98   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   2   0 214   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   0   0   0   0  77   1   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   1   0   0   0   0   0   0   0  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   1   1   0   0   0   0   0   0  79   0   1   0   0   1   0   0]
 [  0   0   0   2   1   0   0   0   0   1   0   0   0 110   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   1   0  58   0   0   0   0   0]
 [  0   1   0   1   4   1   0   1   0   0   0   0   0   0   0  89   0   0   1   0]
 [  0   2   0   1   1   1   0   0   0   0   0   1   0   0   0   0  55   1   1   0]
 [  1   1   0   0   0   1   0   0   0   0   2   0   0   0   0   1   0  90   1   0]
 [  2   0   0   0   1   0   0   0   0   1   0   0   0   2   0   0   0   2  95   1]
 [  3   0   0   1   0   2   1   0   0   0   2   0   0   0   0   0   0   0   0 130]]

2025-04-28 01:44:58,360 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:44:58,360 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:44:58,367 - 

2025-04-28 01:44:58,367 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:45:20,889 - Epoch: [139][   90/   90]    Overall Loss 0.033216    Objective Loss 0.033216    Top1 98.561151    Top5 100.000000    LR 0.000500    Time 0.250213    
2025-04-28 01:45:20,920 - --- validate (epoch=139)-----------
2025-04-28 01:45:20,920 - 2245 samples (100 per mini-batch)
2025-04-28 01:45:23,227 - Epoch: [139][   23/   23]    Loss 0.323703    Top1 94.610245    Top5 99.109131    
2025-04-28 01:45:23,250 - ==> Top1: 94.610    Top5: 99.109    Loss: 0.324

2025-04-28 01:45:23,251 - ==> Confusion:
[[ 96   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   1   0   3]
 [  0 115   0   0   0   0   0   1   0   0   0   0   0   0   0   1   2   0   0   1]
 [  0   0  98   0   1   0   2   0   0   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 141   0   0   0   0   0   0   0   0   0   4   0   0   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   1   2]
 [  0   0   0   0   3  74   0   0   0   0   0   0   0   0   0   1   1   0   0   9]
 [  0   0   1   0   1   0 122   0   0   0   1   0   0   0   0   1   0   0   0   2]
 [  0   0   0   1   0   0   0  98   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   2   0 214   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   1   0   1   0   0   0  79   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   1   1   0]
 [  1   1   0   1   0   0   0   0   0   0   0  72   0   3   0   0   1   2   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  80   0   2   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   1   0   0   0 112   0   0   0   0   1   0]
 [  0   0   1   0   0   0   0   0   0   0   1   0   3   0  53   0   0   0   0   1]
 [  0   1   0   1   3   0   0   1   0   0   0   0   0   0   0  92   0   0   0   0]
 [  0   1   0   0   1   1   0   0   0   0   0   1   0   0   0   0  56   2   1   0]
 [  0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   1   0  92   2   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   3  95   1]
 [  0   0   1   0   2   1   1   0   0   0   3   0   0   0   0   0   0   0   0 131]]

2025-04-28 01:45:23,253 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:45:23,253 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:45:23,261 - 

2025-04-28 01:45:23,261 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:45:46,034 - Epoch: [140][   90/   90]    Overall Loss 0.034448    Objective Loss 0.034448    Top1 97.841727    Top5 100.000000    LR 0.000500    Time 0.253014    
2025-04-28 01:45:46,061 - --- validate (epoch=140)-----------
2025-04-28 01:45:46,061 - 2245 samples (100 per mini-batch)
2025-04-28 01:45:48,382 - Epoch: [140][   23/   23]    Loss 0.298265    Top1 94.164811    Top5 98.841871    
2025-04-28 01:45:48,404 - ==> Top1: 94.165    Top5: 98.842    Loss: 0.298

2025-04-28 01:45:48,404 - ==> Confusion:
[[100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 113   0   0   0   0   0   1   0   0   2   0   0   0   0   1   2   0   0   1]
 [  0   0  96   0   1   2   1   0   3   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   2   0   0   0   0   0   2   0   1   0   1   0   0   3   0]
 [  0   0   0   0 189   3   0   0   0   0   0   0   1   0   1   0   1   0   1   2]
 [  0   0   0   0   1  81   0   0   0   0   0   0   0   0   0   1   1   0   0   4]
 [  0   0   0   1   1   1 121   0   1   0   1   0   0   0   1   0   0   0   0   1]
 [  0   0   0   1   0   0   0  99   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   1   0   0   0   1   0 214   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   2   0   3   0   0   0  77   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   2   0   0   0   0   0  75   0   1   0   0   1   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  82   0   0   0   0   0   0   0]
 [  0   0   0   4   0   0   0   0   0   0   0   0   0 109   0   0   0   0   1   1]
 [  1   0   2   0   3   1   0   0   0   0   0   0   3   0  49   0   0   0   0   0]
 [  1   2   0   1   2   0   0   1   0   0   0   0   0   0   0  91   0   0   0   0]
 [  0   1   0   0   1   2   0   0   0   0   0   1   0   0   0   0  56   1   1   0]
 [  0   0   0   0   0   1   0   0   0   0   3   0   0   0   0   0   0  92   1   0]
 [  0   1   0   0   2   1   0   0   0   1   0   0   0   1   0   0   1   2  94   1]
 [  2   0   1   0   1   7   1   0   0   0   2   0   0   0   0   0   0   0   0 125]]

2025-04-28 01:45:48,407 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:45:48,407 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:45:48,414 - 

2025-04-28 01:45:48,414 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:46:11,082 - Epoch: [141][   90/   90]    Overall Loss 0.043920    Objective Loss 0.043920    Top1 97.122302    Top5 100.000000    LR 0.000500    Time 0.251839    
2025-04-28 01:46:11,111 - --- validate (epoch=141)-----------
2025-04-28 01:46:11,111 - 2245 samples (100 per mini-batch)
2025-04-28 01:46:13,465 - Epoch: [141][   23/   23]    Loss 0.401263    Top1 91.492205    Top5 98.619154    
2025-04-28 01:46:13,490 - ==> Top1: 91.492    Top5: 98.619    Loss: 0.401

2025-04-28 01:46:13,491 - ==> Confusion:
[[ 97   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   1   2]
 [  0 111   1   0   0   0   0   3   0   1   1   0   0   0   0   0   2   0   1   0]
 [  0   0  95   1   1   1   1   0   3   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 142   0   0   0   0   0   0   0   0   0   2   0   0   0   0   5   0]
 [  0   0   0   1 191   1   0   0   0   0   0   0   0   0   1   1   0   1   1   1]
 [  0   0   0   0   2  77   0   1   0   0   0   0   0   0   0   0   1   0   0   7]
 [  0   1   6   3   0   1  93   1  10   0   2   0   1   0   3   0   0   1   0   6]
 [  0   0   0   0   0   0   0  98   0   0   2   0   0   0   0   0   0   1   1   0]
 [  0   0   6   0   0   0   0   0 204   0   0   0   0   0   0   0   1   2   1   2]
 [  0   0   0   2   0   3   0   1   0  77   0   1   0   0   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   1   0 107   0   0   0   0   0   2   1   2   1]
 [  0   3   0   3   0   1   0   0   0   0   0  65   0   3   0   0   3   2   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  80   0   1   0   0   1   1   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 110   0   0   0   0   2   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   3   0  52   0   0   0   3   0]
 [  0   1   0   1   1   0   0   2   1   0   1   0   0   0   1  88   0   0   2   0]
 [  0   0   0   1   0   1   0   0   0   1   0   1   1   0   0   0  53   2   3   0]
 [  0   0   0   1   0   1   0   0   0   0   2   0   0   0   0   0   0  90   3   0]
 [  1   0   0   0   1   1   0   0   0   1   0   0   0   2   0   0   0   2  96   0]
 [  0   0   2   1   1   3   0   0   1   0   2   0   0   0   0   0   0   0   1 128]]

2025-04-28 01:46:13,493 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:46:13,493 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:46:13,500 - 

2025-04-28 01:46:13,500 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:46:36,165 - Epoch: [142][   90/   90]    Overall Loss 0.041677    Objective Loss 0.041677    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.251797    
2025-04-28 01:46:36,194 - --- validate (epoch=142)-----------
2025-04-28 01:46:36,195 - 2245 samples (100 per mini-batch)
2025-04-28 01:46:38,534 - Epoch: [142][   23/   23]    Loss 0.290056    Top1 94.565702    Top5 98.930958    
2025-04-28 01:46:38,555 - ==> Top1: 94.566    Top5: 98.931    Loss: 0.290

2025-04-28 01:46:38,556 - ==> Confusion:
[[ 97   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   2]
 [  0 113   0   0   0   0   0   1   0   0   0   1   0   0   0   1   2   0   1   1]
 [  0   0  97   0   1   0   3   0   0   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 144   0   0   0   0   0   0   0   3   0   2   0   0   0   0   0   0]
 [  0   0   0   0 190   1   1   0   0   0   2   0   1   0   0   0   0   0   1   2]
 [  0   0   0   0   0  79   0   0   0   0   0   0   1   0   0   2   1   0   0   5]
 [  0   0   0   1   0   0 123   0   1   0   1   0   0   0   0   0   0   0   0   2]
 [  0   0   0   0   0   1   0  97   0   1   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   1   0   0   0  77   0   2   0   1   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 113   0   0   0   0   0   0   1   0   0]
 [  1   1   0   1   0   0   0   0   0   0   0  76   0   0   0   1   1   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0  80   0   1   0   0   0   1   0]
 [  0   0   0   2   0   1   0   0   0   0   0   2   0 109   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   0   3   0   0   2   0   0   0   0   0   0   1  91   0   0   0   0]
 [  0   1   0   1   0   2   0   0   0   0   0   1   1   0   0   0  55   1   1   0]
 [  0   1   0   2   0   1   0   0   0   0   2   0   0   0   0   0   0  88   3   0]
 [  0   0   0   1   1   1   0   0   0   1   0   0   1   2   0   0   1   2  93   1]
 [  0   0   1   1   1   3   1   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:46:38,558 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:46:38,558 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:46:38,566 - 

2025-04-28 01:46:38,566 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:47:01,086 - Epoch: [143][   90/   90]    Overall Loss 0.037387    Objective Loss 0.037387    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.250196    
2025-04-28 01:47:01,110 - --- validate (epoch=143)-----------
2025-04-28 01:47:01,111 - 2245 samples (100 per mini-batch)
2025-04-28 01:47:03,383 - Epoch: [143][   23/   23]    Loss 0.325460    Top1 93.942094    Top5 98.663697    
2025-04-28 01:47:03,407 - ==> Top1: 93.942    Top5: 98.664    Loss: 0.325

2025-04-28 01:47:03,407 - ==> Confusion:
[[ 98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   3]
 [  0 111   0   0   1   0   1   1   0   0   2   1   0   0   0   1   1   0   0   1]
 [  0   0  96   0   1   0   2   0   2   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 135   1   0   0   0   0   0   0   4   0   4   0   1   0   0   3   1]
 [  1   0   0   0 194   0   0   0   0   0   0   0   1   0   0   0   0   0   2   0]
 [  0   0   0   0   1  75   1   0   0   0   0   1   0   0   0   1   1   2   0   6]
 [  0   0   0   0   0   0 119   0   1   0   2   0   0   0   1   1   0   0   0   4]
 [  1   1   0   0   2   0   0  93   0   0   2   0   0   0   0   1   0   1   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   1   0   0]
 [  1   1   0   1   1   1   0   0   0  77   0   1   0   1   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 113   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   1   2   0   0]
 [  0   0   0   0   0   0   0   0   0   0   1   0  80   0   1   0   0   1   0   0]
 [  0   0   0   2   0   0   0   1   0   0   0   0   0 111   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   0   4   0   0   1   1   0   0   0   0   0   0  90   0   1   0   0]
 [  0   1   0   0   3   0   0   0   0   0   0   1   1   0   0   0  54   1   2   0]
 [  1   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  93   1   0]
 [  1   1   1   0   1   0   0   0   0   1   0   0   1   1   0   0   0   2  95   0]
 [  0   0   0   0   1   3   2   0   1   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:47:03,409 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:47:03,409 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:47:03,417 - 

2025-04-28 01:47:03,417 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:47:26,010 - Epoch: [144][   90/   90]    Overall Loss 0.031866    Objective Loss 0.031866    Top1 98.561151    Top5 100.000000    LR 0.000500    Time 0.251007    
2025-04-28 01:47:26,038 - --- validate (epoch=144)-----------
2025-04-28 01:47:26,038 - 2245 samples (100 per mini-batch)
2025-04-28 01:47:28,476 - Epoch: [144][   23/   23]    Loss 0.316861    Top1 94.031180    Top5 98.708241    
2025-04-28 01:47:28,501 - ==> Top1: 94.031    Top5: 98.708    Loss: 0.317

2025-04-28 01:47:28,502 - ==> Confusion:
[[ 93   0   0   2   1   1   1   0   0   0   0   0   0   0   0   0   0   0   1   3]
 [  0 116   0   0   0   0   0   1   0   0   0   0   0   0   0   1   1   0   0   1]
 [  0   1  96   0   1   1   3   0   0   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 142   0   0   0   0   0   0   0   3   0   2   0   0   0   0   2   0]
 [  0   0   0   0 192   1   0   0   0   0   0   0   2   0   0   0   1   1   1   0]
 [  0   0   0   0   2  78   0   0   0   0   0   0   0   0   0   1   1   1   0   5]
 [  0   0   0   0   1   1 123   0   1   0   2   0   0   0   0   0   0   0   0   0]
 [  0   1   1   0   0   0   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  0   1   0   3   0   1   0   0   0  78   0   1   0   1   0   0   1   0   0   0]
 [  0   2   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   0   0]
 [  1   1   0   3   0   0   0   0   0   1   0  73   0   1   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  82   0   0   0   0   0   1   0]
 [  0   0   0   2   1   1   0   1   0   2   0   0   0 108   0   0   0   0   0   0]
 [  0   1   1   0   0   0   0   0   0   0   0   0   2   0  55   0   0   0   0   0]
 [  0   1   0   2   3   1   0   1   0   0   0   0   0   0   0  89   0   0   1   0]
 [  0   1   0   1   1   1   0   0   0   0   0   0   1   0   0   0  55   2   1   0]
 [  0   1   0   2   0   1   0   0   0   0   2   0   0   0   0   0   0  88   3   0]
 [  0   0   0   0   1   1   0   0   0   2   0   0   1   2   0   0   0   2  94   1]
 [  0   0   0   0   4   3   2   0   0   0   3   0   0   0   0   0   0   0   0 127]]

2025-04-28 01:47:28,504 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:47:28,504 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:47:28,512 - 

2025-04-28 01:47:28,512 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:47:51,089 - Epoch: [145][   90/   90]    Overall Loss 0.030608    Objective Loss 0.030608    Top1 98.561151    Top5 100.000000    LR 0.000500    Time 0.250830    
2025-04-28 01:47:51,114 - --- validate (epoch=145)-----------
2025-04-28 01:47:51,114 - 2245 samples (100 per mini-batch)
2025-04-28 01:47:53,451 - Epoch: [145][   23/   23]    Loss 0.275280    Top1 94.432071    Top5 98.975501    
2025-04-28 01:47:53,477 - ==> Top1: 94.432    Top5: 98.976    Loss: 0.275

2025-04-28 01:47:53,477 - ==> Confusion:
[[ 96   0   0   2   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   2]
 [  0 113   2   0   0   0   0   1   0   0   1   1   0   0   0   1   1   0   0   0]
 [  0   0  99   0   2   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 143   0   0   0   0   0   0   0   2   0   2   0   0   0   0   2   0]
 [  0   0   0   0 195   0   0   0   0   0   0   0   1   0   0   0   0   1   1   0]
 [  0   0   0   0   2  75   0   1   0   0   0   0   0   0   0   1   1   0   0   8]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   0   0   0   0   0   3]
 [  0   0   1   0   0   1   0  98   0   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   4   0   1   0   0   0  76   0   1   0   1   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0  75   0   1   0   0   2   1   0   0]
 [  0   0   0   0   1   0   0   0   0   0   2   0  78   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   1   0   0   0 111   0   0   0   0   1   1]
 [  0   0   1   0   1   0   0   0   0   0   0   0   2   0  55   0   0   0   0   0]
 [  0   1   0   1   3   0   0   1   0   0   0   0   0   0   0  91   0   0   1   0]
 [  0   0   0   1   0   1   0   0   0   1   0   0   0   0   0   0  56   2   2   0]
 [  0   1   0   1   0   2   0   0   0   0   2   0   0   0   0   0   0  87   4   0]
 [  0   0   1   0   0   1   0   0   0   1   0   0   0   2   0   0   0   4  95   0]
 [  0   0   1   0   3   3   1   0   0   0   3   0   0   0   0   0   0   0   0 128]]

2025-04-28 01:47:53,479 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:47:53,480 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:47:53,487 - 

2025-04-28 01:47:53,487 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:48:16,123 - Epoch: [146][   90/   90]    Overall Loss 0.025682    Objective Loss 0.025682    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.251483    
2025-04-28 01:48:16,148 - --- validate (epoch=146)-----------
2025-04-28 01:48:16,148 - 2245 samples (100 per mini-batch)
2025-04-28 01:48:18,497 - Epoch: [146][   23/   23]    Loss 0.290493    Top1 94.699332    Top5 98.975501    
2025-04-28 01:48:18,523 - ==> Top1: 94.699    Top5: 98.976    Loss: 0.290

2025-04-28 01:48:18,523 - ==> Confusion:
[[ 97   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   4]
 [  0 115   1   0   0   0   0   1   0   0   0   1   0   0   0   1   1   0   0   0]
 [  0   0  97   0   1   1   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   0   1   0   0   0   2   0   3   0   0   0   0   3   0]
 [  0   0   0   0 192   2   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   0  78   0   0   0   0   0   0   0   0   1   1   1   0   0   7]
 [  0   0   1   0   0   0 122   0   0   0   2   0   0   0   0   0   0   0   0   3]
 [  0   1   1   0   0   0   0  98   0   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 212   0   0   0   0   0   0   0   0   0   1   2]
 [  1   1   0   2   0   1   0   1   0  77   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   0   1   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   1   0   0   0 113   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   0   1   1   0   1   0   0   0   0   0   0   0  94   0   0   0   0]
 [  0   1   0   0   0   2   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   0   0   2   0   1   0   0   0   0   2   0   0   0   0   0   0  88   4   0]
 [  2   0   0   0   1   1   1   0   0   0   0   0   1   1   0   0   0   2  95   0]
 [  0   0   0   0   2   4   1   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:48:18,525 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:48:18,525 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:48:18,533 - 

2025-04-28 01:48:18,533 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:48:41,167 - Epoch: [147][   90/   90]    Overall Loss 0.022924    Objective Loss 0.022924    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.251462    
2025-04-28 01:48:41,189 - --- validate (epoch=147)-----------
2025-04-28 01:48:41,189 - 2245 samples (100 per mini-batch)
2025-04-28 01:48:43,469 - Epoch: [147][   23/   23]    Loss 0.306685    Top1 93.986637    Top5 98.886414    
2025-04-28 01:48:43,492 - ==> Top1: 93.987    Top5: 98.886    Loss: 0.307

2025-04-28 01:48:43,492 - ==> Confusion:
[[ 93   0   0   1   0   0   1   0   0   0   0   0   0   0   1   0   0   0   0   6]
 [  0 114   1   0   0   0   0   1   0   1   0   0   0   0   0   1   1   0   1   0]
 [  0   0  99   0   1   0   2   0   0   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   1 138   0   0   0   1   0   0   0   2   0   3   0   0   0   0   4   0]
 [  0   0   1   0 192   0   0   0   0   0   0   0   1   0   1   1   0   0   1   1]
 [  0   0   0   0   0  76   0   0   0   0   0   0   0   0   0   2   1   0   0   9]
 [  0   0   1   0   0   0 119   0   0   0   2   0   0   0   1   1   0   0   0   4]
 [  0   1   0   1   0   0   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   3   0   0   0   0   0  79   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  0   1   0   1   0   0   0   0   0   0   1  74   0   2   0   0   1   0   0   1]
 [  0   0   1   0   0   0   0   0   0   0   0   0  80   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   1   0   2   0   0   0 109   0   1   0   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0   0   0   2   0  55   0   0   0   1   0]
 [  0   1   0   0   2   0   0   1   1   0   0   0   0   0   0  93   0   0   0   0]
 [  0   1   0   1   0   1   0   0   0   0   0   0   0   0   0   0  56   2   1   1]
 [  0   1   0   1   0   1   0   0   0   0   2   0   0   0   0   0   0  88   4   0]
 [  0   1   1   0   1   1   0   0   0   1   0   0   0   0   0   0   0   4  94   1]
 [  0   0   1   0   1   4   1   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:48:43,494 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:48:43,494 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:48:43,502 - 

2025-04-28 01:48:43,502 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:49:06,402 - Epoch: [148][   90/   90]    Overall Loss 0.024906    Objective Loss 0.024906    Top1 99.280576    Top5 100.000000    LR 0.000500    Time 0.254416    
2025-04-28 01:49:06,434 - --- validate (epoch=148)-----------
2025-04-28 01:49:06,434 - 2245 samples (100 per mini-batch)
2025-04-28 01:49:08,769 - Epoch: [148][   23/   23]    Loss 0.322885    Top1 93.674833    Top5 99.020045    
2025-04-28 01:49:08,795 - ==> Top1: 93.675    Top5: 99.020    Loss: 0.323

2025-04-28 01:49:08,796 - ==> Confusion:
[[ 99   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   1]
 [  0 113   0   0   1   0   0   3   0   0   0   0   0   0   0   1   1   0   1   0]
 [  0   0  99   0   1   1   1   0   0   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 136   0   0   1   2   0   0   0   3   0   3   0   0   0   0   3   1]
 [  0   0   0   0 188   1   0   0   0   0   0   0   1   0   0   4   1   0   1   2]
 [  0   0   0   0   1  80   0   0   0   0   0   0   0   0   0   1   1   1   0   4]
 [  0   0   3   0   1   0 117   0   1   0   1   0   0   0   1   1   0   0   0   3]
 [  0   0   0   1   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   1   0   0   1   0   0 213   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   1   0   2   0   2   0  77   0   1   0   0   0   0   1   0   0   0]
 [  0   2   0   0   0   0   0   0   0   0 109   0   0   0   0   0   1   1   1   0]
 [  1   1   0   3   0   1   0   1   0   0   0  73   0   0   0   0   1   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   2   0   1   0   0   0   2   0   1   0 108   0   0   0   0   1   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   3   0  55   0   0   0   0   0]
 [  0   1   0   0   0   0   0   1   1   0   0   0   0   0   0  94   0   0   1   0]
 [  0   2   0   1   1   2   0   0   0   0   0   0   0   0   0   0  56   1   0   0]
 [  0   0   0   1   0   1   0   0   0   0   2   0   0   0   0   1   0  87   5   0]
 [  0   0   1   0   2   1   0   0   0   1   0   0   1   1   0   0   0   1  95   1]
 [  1   0   1   0   2   4   1   0   0   0   3   0   0   0   0   0   0   0   1 126]]

2025-04-28 01:49:08,798 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:49:08,798 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:49:08,805 - 

2025-04-28 01:49:08,805 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:49:31,893 - Epoch: [149][   90/   90]    Overall Loss 0.030309    Objective Loss 0.030309    Top1 97.122302    Top5 100.000000    LR 0.000500    Time 0.256502    
2025-04-28 01:49:31,921 - --- validate (epoch=149)-----------
2025-04-28 01:49:31,921 - 2245 samples (100 per mini-batch)
2025-04-28 01:49:34,265 - Epoch: [149][   23/   23]    Loss 0.315834    Top1 93.942094    Top5 99.020045    
2025-04-28 01:49:34,286 - ==> Top1: 93.942    Top5: 99.020    Loss: 0.316

2025-04-28 01:49:34,286 - ==> Confusion:
[[ 98   0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 112   1   0   0   0   1   2   0   1   1   0   0   0   0   0   1   0   1   0]
 [  0   0  97   0   1   0   4   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 137   0   0   2   0   0   0   0   3   0   3   0   0   0   0   4   0]
 [  0   0   0   0 192   1   0   0   0   0   0   0   1   0   1   0   1   0   1   1]
 [  1   0   0   0   2  77   1   0   0   0   0   0   0   0   0   1   1   1   1   3]
 [  0   0   1   0   1   0 125   0   0   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   2   0   0   0   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   3   0 213   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   1   0   1   1   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   1   0   0   0   0   0   0 109   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   1   0   0   0   0   0  75   0   1   0   0   1   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   1   0   0   0   1   0   0   4   0   1   0 107   0   0   0   0   1   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   3   0  54   0   0   0   1   0]
 [  0   1   0   0   3   0   0   3   0   0   0   0   0   0   0  90   0   0   1   0]
 [  0   1   0   1   1   0   0   0   0   0   0   2   0   0   0   0  54   2   2   0]
 [  0   1   0   0   0   1   0   0   0   0   2   0   0   0   0   0   0  90   3   0]
 [  1   0   0   0   1   1   1   0   0   1   0   0   0   1   0   0   0   1  97   0]
 [  3   0   0   0   0   4   4   0   0   0   2   0   0   0   0   0   0   0   0 126]]

2025-04-28 01:49:34,288 - ==> Best [Top1: 94.878   Top5: 99.020   Params: 306880 on epoch: 112]
2025-04-28 01:49:34,289 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:49:34,296 - 

2025-04-28 01:49:34,297 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:49:57,386 - Epoch: [150][   90/   90]    Overall Loss 0.019371    Objective Loss 0.019371    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.256525    
2025-04-28 01:49:57,412 - --- validate (epoch=150)-----------
2025-04-28 01:49:57,413 - 2245 samples (100 per mini-batch)
2025-04-28 01:49:59,688 - Epoch: [150][   23/   23]    Loss 0.293911    Top1 94.922049    Top5 99.109131    
2025-04-28 01:49:59,711 - ==> Top1: 94.922    Top5: 99.109    Loss: 0.294

2025-04-28 01:49:59,712 - ==> Confusion:
[[ 96   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   1   1   2]
 [  0 114   1   0   0   0   0   1   0   0   1   0   0   0   0   1   1   0   1   0]
 [  0   0  98   0   2   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 138   1   0   1   0   0   0   0   3   0   2   0   0   0   0   4   0]
 [  0   0   0   0 195   0   0   0   0   0   0   0   1   0   0   0   0   0   1   1]
 [  0   0   0   0   1  78   0   0   0   0   0   0   0   0   0   1   1   0   0   7]
 [  0   0   0   0   1   0 122   0   1   0   1   0   0   0   1   1   0   0   0   1]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   2   0   0   1   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   1   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   1   0   0   0 112   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   0   3   0   0   1   1   0   0   0   0   0   0  91   0   0   1   0]
 [  0   2   0   0   1   1   0   0   0   0   0   0   0   0   0   0  57   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  92   3   0]
 [  0   0   0   0   3   1   0   0   0   1   0   0   0   1   0   0   0   2  95   1]
 [  0   0   0   0   3   2   1   0   0   0   3   0   0   0   0   1   0   0   0 129]]

2025-04-28 01:49:59,714 - ==> Best [Top1: 94.922   Top5: 99.109   Params: 306880 on epoch: 150]
2025-04-28 01:49:59,714 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:49:59,726 - 

2025-04-28 01:49:59,726 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:50:22,396 - Epoch: [151][   90/   90]    Overall Loss 0.013116    Objective Loss 0.013116    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.251868    
2025-04-28 01:50:22,424 - --- validate (epoch=151)-----------
2025-04-28 01:50:22,424 - 2245 samples (100 per mini-batch)
2025-04-28 01:50:24,765 - Epoch: [151][   23/   23]    Loss 0.280042    Top1 94.654788    Top5 98.930958    
2025-04-28 01:50:24,787 - ==> Top1: 94.655    Top5: 98.931    Loss: 0.280

2025-04-28 01:50:24,787 - ==> Confusion:
[[ 98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   2]
 [  0 113   1   0   0   0   0   1   0   0   1   0   0   0   0   1   2   0   1   0]
 [  0   0  97   0   2   0   2   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 139   0   0   1   0   0   0   0   3   0   2   0   0   0   0   4   0]
 [  0   0   0   0 193   1   0   0   0   0   0   0   1   0   0   0   0   0   2   1]
 [  0   0   0   0   1  75   0   0   0   0   0   0   0   0   1   1   1   1   0   8]
 [  0   0   0   0   1   0 121   0   1   0   1   0   0   0   1   0   0   0   0   3]
 [  0   0   0   0   0   1   0  97   0   1   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   3   0   1   0   0   0  78   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   0   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   1   0   0   0   1   0   0   0 111   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   0   2   0   0   1   1   0   0   0   0   0   0  92   0   0   1   0]
 [  0   2   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  92   3   0]
 [  1   0   0   0   2   1   0   0   0   1   0   0   1   2   0   0   0   1  95   0]
 [  0   0   1   0   1   3   1   0   0   0   3   0   0   0   0   1   0   0   0 129]]

2025-04-28 01:50:24,790 - ==> Best [Top1: 94.922   Top5: 99.109   Params: 306880 on epoch: 150]
2025-04-28 01:50:24,790 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:50:24,798 - 

2025-04-28 01:50:24,798 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:50:47,915 - Epoch: [152][   90/   90]    Overall Loss 0.011227    Objective Loss 0.011227    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.256822    
2025-04-28 01:50:47,940 - --- validate (epoch=152)-----------
2025-04-28 01:50:47,940 - 2245 samples (100 per mini-batch)
2025-04-28 01:50:50,301 - Epoch: [152][   23/   23]    Loss 0.279214    Top1 94.966592    Top5 99.020045    
2025-04-28 01:50:50,325 - ==> Top1: 94.967    Top5: 99.020    Loss: 0.279

2025-04-28 01:50:50,325 - ==> Confusion:
[[ 98   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   1]
 [  0 113   1   0   0   0   0   2   0   0   0   1   0   0   0   0   2   0   1   0]
 [  0   0  97   0   1   0   3   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 139   0   0   0   0   0   0   0   3   0   3   0   0   0   0   4   0]
 [  0   0   0   0 193   1   0   0   0   0   0   0   1   0   0   0   0   0   2   1]
 [  0   0   0   0   1  76   0   0   0   0   0   0   0   0   0   1   1   2   0   7]
 [  0   0   0   0   1   0 122   0   1   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   0   0   0   0   0  98   0   1   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   2   0   2   0   1   0   0   0  77   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   0   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   0   0   0   0 113   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   0   2   0   0   2   1   0   0   0   0   0   0  91   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0  58   2   1   0]
 [  0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  92   3   0]
 [  1   0   1   0   2   1   0   0   0   1   0   0   0   1   0   0   0   1  96   0]
 [  0   0   0   0   1   3   1   0   0   0   3   0   0   0   0   1   0   0   0 130]]

2025-04-28 01:50:50,328 - ==> Best [Top1: 94.967   Top5: 99.020   Params: 306880 on epoch: 152]
2025-04-28 01:50:50,328 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:50:50,339 - 

2025-04-28 01:50:50,339 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:51:13,302 - Epoch: [153][   90/   90]    Overall Loss 0.010697    Objective Loss 0.010697    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.255114    
2025-04-28 01:51:13,332 - --- validate (epoch=153)-----------
2025-04-28 01:51:13,333 - 2245 samples (100 per mini-batch)
2025-04-28 01:51:15,737 - Epoch: [153][   23/   23]    Loss 0.276666    Top1 94.788419    Top5 99.109131    
2025-04-28 01:51:15,762 - ==> Top1: 94.788    Top5: 99.109    Loss: 0.277

2025-04-28 01:51:15,762 - ==> Confusion:
[[ 96   0   0   1   0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   3]
 [  0 115   1   0   0   0   0   1   0   1   0   0   0   0   0   1   1   0   0   0]
 [  0   0  97   0   1   0   3   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 138   0   0   1   0   0   0   0   3   0   3   0   0   0   0   4   0]
 [  0   0   0   1 190   1   0   0   0   0   0   0   1   0   1   0   0   0   2   2]
 [  0   0   0   0   1  78   0   0   0   0   0   0   0   0   0   1   1   0   0   7]
 [  0   0   0   0   0   0 123   0   0   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   0   0  98   0   1   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   2   0   0   0   0   0  79   0   1   0   0   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   1   0]
 [  1   1   0   1   0   0   0   0   0   0   0  75   0   1   0   0   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   0   0   0   0 113   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  56   0   0   0   1   0]
 [  0   1   0   1   3   0   0   1   0   0   0   0   0   0   0  91   0   0   1   0]
 [  0   2   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   1   0   1   0   0   0   0   0   0   2   0   0   0   0   0   0  90   3   0]
 [  0   0   1   0   1   1   0   0   0   1   0   0   0   2   0   0   0   2  95   1]
 [  0   0   0   0   1   3   1   0   0   0   3   0   0   0   0   1   0   0   0 130]]

2025-04-28 01:51:15,765 - ==> Best [Top1: 94.967   Top5: 99.020   Params: 306880 on epoch: 152]
2025-04-28 01:51:15,765 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:51:15,773 - 

2025-04-28 01:51:15,773 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:51:38,639 - Epoch: [154][   90/   90]    Overall Loss 0.010682    Objective Loss 0.010682    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.254031    
2025-04-28 01:51:38,669 - --- validate (epoch=154)-----------
2025-04-28 01:51:38,669 - 2245 samples (100 per mini-batch)
2025-04-28 01:51:40,997 - Epoch: [154][   23/   23]    Loss 0.288654    Top1 94.476615    Top5 98.930958    
2025-04-28 01:51:41,019 - ==> Top1: 94.477    Top5: 98.931    Loss: 0.289

2025-04-28 01:51:41,019 - ==> Confusion:
[[ 95   0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   4]
 [  0 114   1   0   0   0   0   1   0   0   1   1   0   0   0   1   1   0   0   0]
 [  0   0  98   0   1   0   2   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   1   0 138   0   0   1   1   0   0   0   3   0   2   0   0   0   0   3   0]
 [  0   0   0   0 194   1   0   0   0   0   0   0   1   0   0   0   0   0   1   1]
 [  0   0   0   0   2  77   0   0   0   0   0   0   0   0   0   1   1   0   0   7]
 [  0   0   1   0   0   0 119   0   1   0   2   0   0   0   1   1   0   0   0   3]
 [  0   1   0   0   0   0   0  98   0   1   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   2   0   0   0   1   0  79   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   1   0   0   0 112   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   1   0]
 [  0   1   0   0   4   0   0   1   1   0   0   0   0   0   0  90   0   0   1   0]
 [  0   2   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   2   0   1   0   1   0   0   0   0   2   0   0   0   0   0   0  88   3   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   2   0   0   0   2  94   1]
 [  0   0   0   0   1   3   1   0   0   0   3   0   0   0   0   0   0   0   0 131]]

2025-04-28 01:51:41,022 - ==> Best [Top1: 94.967   Top5: 99.020   Params: 306880 on epoch: 152]
2025-04-28 01:51:41,022 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:51:41,029 - 

2025-04-28 01:51:41,029 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:52:03,821 - Epoch: [155][   90/   90]    Overall Loss 0.011712    Objective Loss 0.011712    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.253210    
2025-04-28 01:52:03,851 - --- validate (epoch=155)-----------
2025-04-28 01:52:03,851 - 2245 samples (100 per mini-batch)
2025-04-28 01:52:06,180 - Epoch: [155][   23/   23]    Loss 0.281021    Top1 94.476615    Top5 98.975501    
2025-04-28 01:52:06,202 - ==> Top1: 94.477    Top5: 98.976    Loss: 0.281

2025-04-28 01:52:06,203 - ==> Confusion:
[[ 96   0   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   1   0   2]
 [  0 112   1   0   0   0   1   1   0   0   1   0   0   0   0   1   2   0   1   0]
 [  0   0  97   0   2   0   2   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   1   0 136   0   0   1   0   0   0   0   3   0   4   0   0   0   0   4   0]
 [  0   0   0   0 193   1   0   0   0   0   0   0   1   0   0   0   0   0   1   2]
 [  0   0   0   0   2  78   0   0   0   0   0   0   0   0   0   1   1   0   0   6]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   1   0   0   0   0   0  97   0   1   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   2   0   1   1   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   0   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0 112   0   0   0   0   1   1]
 [  0   1   0   0   0   0   0   0   0   0   0   0   2   0  55   0   0   0   1   0]
 [  0   1   0   0   3   0   0   1   1   0   0   0   0   0   0  90   0   0   2   0]
 [  0   2   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   0   0   1   0   1   0   0   0   0   2   0   0   0   0   0   0  90   3   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   1  97   1]
 [  0   0   0   0   1   4   1   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 01:52:06,205 - ==> Best [Top1: 94.967   Top5: 99.020   Params: 306880 on epoch: 152]
2025-04-28 01:52:06,205 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:52:06,213 - 

2025-04-28 01:52:06,213 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:52:28,876 - Epoch: [156][   90/   90]    Overall Loss 0.011940    Objective Loss 0.011940    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.251784    
2025-04-28 01:52:28,905 - --- validate (epoch=156)-----------
2025-04-28 01:52:28,905 - 2245 samples (100 per mini-batch)
2025-04-28 01:52:31,283 - Epoch: [156][   23/   23]    Loss 0.280465    Top1 94.743875    Top5 98.975501    
2025-04-28 01:52:31,307 - ==> Top1: 94.744    Top5: 98.976    Loss: 0.280

2025-04-28 01:52:31,308 - ==> Confusion:
[[ 97   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   1   2]
 [  0 113   1   0   0   0   0   1   0   1   1   0   0   0   0   1   1   0   1   0]
 [  0   0  98   0   2   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 141   0   0   0   0   0   0   0   2   0   3   0   0   0   0   3   0]
 [  0   0   0   0 193   1   0   0   0   0   0   0   1   0   0   0   0   0   2   1]
 [  0   0   0   0   1  75   0   0   0   0   0   0   0   0   0   1   1   1   0   9]
 [  0   0   0   0   1   0 123   0   0   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   0   0   0   1   0  97   0   1   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   1   0   0  78   0   1   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   2   0   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 111   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   1   3   0   0   1   1   0   0   0   0   0   0  90   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0  58   2   1   0]
 [  0   1   0   2   0   0   0   0   0   0   2   0   0   0   0   0   0  89   3   0]
 [  0   0   0   0   2   1   0   0   0   1   1   0   1   1   0   0   0   2  94   1]
 [  0   0   0   0   1   3   1   0   0   0   3   0   0   0   0   1   0   0   0 130]]

2025-04-28 01:52:31,310 - ==> Best [Top1: 94.967   Top5: 99.020   Params: 306880 on epoch: 152]
2025-04-28 01:52:31,310 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:52:31,318 - 

2025-04-28 01:52:31,318 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:52:54,471 - Epoch: [157][   90/   90]    Overall Loss 0.010901    Objective Loss 0.010901    Top1 98.561151    Top5 100.000000    LR 0.000250    Time 0.257232    
2025-04-28 01:52:54,497 - --- validate (epoch=157)-----------
2025-04-28 01:52:54,497 - 2245 samples (100 per mini-batch)
2025-04-28 01:52:56,873 - Epoch: [157][   23/   23]    Loss 0.261020    Top1 94.922049    Top5 98.930958    
2025-04-28 01:52:56,895 - ==> Top1: 94.922    Top5: 98.931    Loss: 0.261

2025-04-28 01:52:56,895 - ==> Confusion:
[[ 97   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0   0   0   1   2]
 [  0 116   0   0   0   0   0   1   0   0   0   0   0   0   0   1   1   0   0   1]
 [  0   0  97   0   2   0   2   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 143   0   0   0   0   0   0   0   2   0   2   0   0   0   0   2   0]
 [  0   0   0   1 191   1   0   0   0   0   0   0   1   0   1   0   1   0   1   1]
 [  0   0   0   0   1  77   0   0   0   0   0   0   0   0   0   1   0   0   0   9]
 [  0   0   0   0   0   0 123   0   0   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   0   0   0  79   0   1   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   1   0]
 [  1   1   0   2   0   0   0   0   0   0   0  74   0   1   0   0   1   1   0   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0  80   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   0   0   0   0 113   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   1   3   0   0   1   1   0   0   0   0   0   0  90   0   0   1   0]
 [  0   2   0   0   0   2   0   0   0   0   0   2   0   0   0   0  56   1   0   0]
 [  0   1   0   2   0   1   0   0   0   0   2   0   0   0   0   0   0  89   2   0]
 [  0   0   0   0   1   1   0   0   0   1   1   0   1   2   0   0   0   2  94   1]
 [  0   0   0   0   1   3   1   0   0   0   2   0   0   0   0   1   0   0   0 131]]

2025-04-28 01:52:56,898 - ==> Best [Top1: 94.967   Top5: 99.020   Params: 306880 on epoch: 152]
2025-04-28 01:52:56,898 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:52:56,906 - 

2025-04-28 01:52:56,906 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:53:19,728 - Epoch: [158][   90/   90]    Overall Loss 0.011420    Objective Loss 0.011420    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.253543    
2025-04-28 01:53:19,753 - --- validate (epoch=158)-----------
2025-04-28 01:53:19,753 - 2245 samples (100 per mini-batch)
2025-04-28 01:53:22,072 - Epoch: [158][   23/   23]    Loss 0.268465    Top1 94.832962    Top5 98.975501    
2025-04-28 01:53:22,093 - ==> Top1: 94.833    Top5: 98.976    Loss: 0.268

2025-04-28 01:53:22,093 - ==> Confusion:
[[ 96   0   0   0   0   1   0   0   1   0   0   0   0   0   0   0   0   1   0   3]
 [  0 114   0   0   1   0   0   1   0   0   1   1   0   0   0   1   1   0   0   0]
 [  0   0  97   0   2   0   2   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 142   0   0   0   0   0   0   0   3   0   2   0   0   0   0   2   0]
 [  0   0   0   1 192   0   0   0   0   0   0   0   1   0   1   0   0   0   2   1]
 [  0   0   0   0   1  77   0   0   0   0   0   0   0   0   0   1   1   2   0   6]
 [  0   0   0   0   1   0 123   0   0   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   1   0   0   1   0  96   0   0   2   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   2   0   4   0   1   0   0   0  77   0   1   0   0   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  1   1   0   1   0   0   0   0   0   0   0  75   0   2   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   1   0   0   0   0   0   0   0 112   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   0   2   0   0   1   1   0   0   0   0   0   0  92   0   0   1   0]
 [  0   2   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  93   1   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   2   0   0   0   2  94   1]
 [  0   0   1   0   1   3   1   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 01:53:22,095 - ==> Best [Top1: 94.967   Top5: 99.020   Params: 306880 on epoch: 152]
2025-04-28 01:53:22,095 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:53:22,103 - 

2025-04-28 01:53:22,103 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:53:44,849 - Epoch: [159][   90/   90]    Overall Loss 0.010964    Objective Loss 0.010964    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.252700    
2025-04-28 01:53:44,879 - --- validate (epoch=159)-----------
2025-04-28 01:53:44,879 - 2245 samples (100 per mini-batch)
2025-04-28 01:53:47,217 - Epoch: [159][   23/   23]    Loss 0.281964    Top1 94.699332    Top5 99.153675    
2025-04-28 01:53:47,239 - ==> Top1: 94.699    Top5: 99.154    Loss: 0.282

2025-04-28 01:53:47,239 - ==> Confusion:
[[ 96   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   1   3]
 [  0 113   1   0   0   0   0   1   0   0   0   2   0   0   0   1   1   0   1   0]
 [  0   0  98   0   1   0   1   0   1   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 143   0   0   0   0   0   0   0   2   0   2   0   0   0   0   2   0]
 [  0   0   0   0 192   1   0   0   0   0   0   0   1   0   0   0   0   0   2   2]
 [  0   0   0   0   2  76   0   0   0   0   0   0   0   0   0   1   1   0   0   8]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   1   0  97   0   1   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   0   1   0  77   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   1   0   0   0   0   0   0   0  75   0   1   0   0   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   1   0   1   0   0   0   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   1   0]
 [  0   1   0   0   2   0   0   1   1   0   0   0   0   0   0  92   0   0   1   0]
 [  0   2   0   0   0   1   0   0   0   0   0   0   0   0   0   0  57   1   1   1]
 [  0   1   0   1   0   0   0   0   0   0   2   0   0   0   0   0   0  91   2   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   2   0   0   0   2  94   1]
 [  0   0   0   0   1   4   1   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 01:53:47,241 - ==> Best [Top1: 94.967   Top5: 99.020   Params: 306880 on epoch: 152]
2025-04-28 01:53:47,241 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:53:47,249 - 

2025-04-28 01:53:47,249 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:54:10,083 - Epoch: [160][   90/   90]    Overall Loss 0.009434    Objective Loss 0.009434    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.253680    
2025-04-28 01:54:10,109 - --- validate (epoch=160)-----------
2025-04-28 01:54:10,109 - 2245 samples (100 per mini-batch)
2025-04-28 01:54:12,455 - Epoch: [160][   23/   23]    Loss 0.267001    Top1 95.011136    Top5 99.020045    
2025-04-28 01:54:12,478 - ==> Top1: 95.011    Top5: 99.020    Loss: 0.267

2025-04-28 01:54:12,478 - ==> Confusion:
[[ 98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   2]
 [  0 115   1   0   0   0   0   1   0   0   0   0   0   0   0   1   2   0   0   0]
 [  0   0  97   0   2   0   2   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 144   0   0   0   0   0   0   0   2   0   2   0   0   0   0   1   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   0   0   1   0   1   1]
 [  0   0   0   0   2  77   0   0   0   0   0   0   0   0   0   1   1   0   0   7]
 [  0   0   0   0   1   0 123   0   0   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   0   0   0   0  79   0   1   0   0   0   0   2   0   0   0]
 [  0   2   0   0   0   0   0   0   0   0 109   0   0   0   0   0   1   2   0   0]
 [  1   1   0   1   0   0   0   0   0   0   0  75   0   1   0   1   1   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   1   0   1   0   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   0   2   0   0   1   1   0   0   0   0   0   0  92   0   0   1   0]
 [  0   2   0   0   0   1   0   0   0   0   0   0   0   0   0   0  58   1   1   0]
 [  1   1   0   1   0   1   0   0   0   0   2   0   0   0   0   0   0  89   2   0]
 [  1   0   0   0   2   1   0   0   0   1   0   0   1   2   0   0   1   2  93   0]
 [  0   0   1   0   2   3   1   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:54:12,480 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 01:54:12,481 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:54:12,492 - 

2025-04-28 01:54:12,492 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:54:35,856 - Epoch: [161][   90/   90]    Overall Loss 0.010370    Objective Loss 0.010370    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.259569    
2025-04-28 01:54:35,882 - --- validate (epoch=161)-----------
2025-04-28 01:54:35,882 - 2245 samples (100 per mini-batch)
2025-04-28 01:54:38,164 - Epoch: [161][   23/   23]    Loss 0.287680    Top1 94.966592    Top5 98.975501    
2025-04-28 01:54:38,189 - ==> Top1: 94.967    Top5: 98.976    Loss: 0.288

2025-04-28 01:54:38,190 - ==> Confusion:
[[ 97   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   1   2]
 [  0 112   1   0   0   0   0   1   0   0   1   0   0   0   0   1   3   0   1   0]
 [  0   0  98   0   1   0   1   0   1   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 139   0   0   1   0   0   0   0   3   0   2   0   0   0   0   4   0]
 [  0   0   0   0 192   1   0   0   0   0   0   0   1   0   0   0   0   0   2   2]
 [  0   0   0   0   0  79   0   0   0   0   0   0   0   0   0   1   1   0   0   7]
 [  0   0   0   0   0   0 123   0   0   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   2   0   2   0   1   0   0   0  77   0   1   0   0   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   1   0]
 [  1   1   0   1   0   0   0   0   0   0   0  75   0   1   0   1   1   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   0   0   0   0 113   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   0   4   0   0   1   1   0   0   0   0   0   0  90   0   0   1   0]
 [  0   2   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  91   3   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   1   0   0   0   1  96   1]
 [  0   0   0   0   1   3   1   0   0   0   2   0   0   0   0   0   0   0   0 132]]

2025-04-28 01:54:38,192 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 01:54:38,192 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:54:38,199 - 

2025-04-28 01:54:38,199 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:55:01,016 - Epoch: [162][   90/   90]    Overall Loss 0.011495    Objective Loss 0.011495    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.253492    
2025-04-28 01:55:01,044 - --- validate (epoch=162)-----------
2025-04-28 01:55:01,045 - 2245 samples (100 per mini-batch)
2025-04-28 01:55:03,385 - Epoch: [162][   23/   23]    Loss 0.279673    Top1 94.788419    Top5 99.109131    
2025-04-28 01:55:03,406 - ==> Top1: 94.788    Top5: 99.109    Loss: 0.280

2025-04-28 01:55:03,406 - ==> Confusion:
[[ 97   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   3]
 [  0 114   1   0   0   0   0   1   0   1   0   0   0   0   0   1   1   0   1   0]
 [  0   0  97   0   2   0   2   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   1   0   0   0   0   3   0   2   0   1   0   0   2   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   0   0   1   0   1   2]
 [  0   0   0   0   0  78   0   0   0   0   0   1   0   0   0   1   1   0   0   7]
 [  0   0   0   0   0   0 121   0   1   0   2   0   0   0   1   0   0   0   0   3]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   1   1   0]
 [  1   1   0   1   0   0   0   0   0   0   0  75   0   1   0   1   1   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 110   0   0   0   0   1   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   0   2   1   0   1   0   0   0   0   0   0   0  92   0   0   1   0]
 [  0   2   0   0   0   0   0   0   0   0   0   2   0   0   0   0  57   1   1   0]
 [  0   1   0   0   0   1   0   0   0   0   2   0   0   0   0   0   0  91   2   0]
 [  1   0   0   0   2   1   0   0   0   1   0   0   1   1   0   0   0   1  96   0]
 [  1   0   1   0   1   3   1   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:55:03,408 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 01:55:03,408 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:55:03,416 - 

2025-04-28 01:55:03,416 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:55:26,169 - Epoch: [163][   90/   90]    Overall Loss 0.009244    Objective Loss 0.009244    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.252783    
2025-04-28 01:55:26,199 - --- validate (epoch=163)-----------
2025-04-28 01:55:26,200 - 2245 samples (100 per mini-batch)
2025-04-28 01:55:28,547 - Epoch: [163][   23/   23]    Loss 0.296234    Top1 94.832962    Top5 98.930958    
2025-04-28 01:55:28,572 - ==> Top1: 94.833    Top5: 98.931    Loss: 0.296

2025-04-28 01:55:28,572 - ==> Confusion:
[[ 96   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   4]
 [  0 113   1   0   0   0   0   1   0   1   1   0   0   0   0   1   1   0   1   0]
 [  0   0  97   0   1   0   2   0   1   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 144   0   0   0   0   0   0   0   1   0   2   0   0   0   0   2   0]
 [  0   0   0   0 191   0   0   0   0   0   0   0   1   0   2   0   1   0   1   2]
 [  0   0   0   0   0  77   0   0   0   0   0   0   0   0   0   1   1   0   0   9]
 [  0   0   0   0   0   0 118   0   1   0   2   1   0   0   1   0   0   0   0   5]
 [  0   0   1   0   0   0   0  98   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   1   0   0   0   0   0   0   0  75   0   1   0   1   1   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 111   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   0   3   0   0   1   0   0   0   0   0   0   0  92   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   1   0   0   0   0   0   0  58   1   1   0]
 [  0   1   0   0   0   1   0   0   0   0   2   0   0   0   0   0   0  91   2   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   2   0   0   0   3  93   1]
 [  0   0   0   0   1   2   1   0   0   0   2   0   0   0   0   0   0   0   0 133]]

2025-04-28 01:55:28,574 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 01:55:28,575 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:55:28,582 - 

2025-04-28 01:55:28,582 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:55:51,403 - Epoch: [164][   90/   90]    Overall Loss 0.008703    Objective Loss 0.008703    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.253539    
2025-04-28 01:55:51,433 - --- validate (epoch=164)-----------
2025-04-28 01:55:51,433 - 2245 samples (100 per mini-batch)
2025-04-28 01:55:53,772 - Epoch: [164][   23/   23]    Loss 0.301993    Top1 94.922049    Top5 98.886414    
2025-04-28 01:55:53,797 - ==> Top1: 94.922    Top5: 98.886    Loss: 0.302

2025-04-28 01:55:53,798 - ==> Confusion:
[[ 98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   2]
 [  0 115   1   0   0   0   0   1   0   0   0   0   0   0   0   1   1   0   1   0]
 [  0   0  98   0   2   0   1   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 138   0   0   1   1   0   0   0   3   0   2   0   0   0   0   4   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   2   0   1   0   1   0   1   1]
 [  0   0   0   0   3  76   0   0   0   0   0   0   0   0   0   1   1   2   0   5]
 [  0   0   0   0   1   0 123   0   0   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   1   0   1   0   0   0  78   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   0   2   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   0   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   0   0   0   0 113   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   1   0]
 [  0   1   0   0   2   0   0   1   1   0   0   0   0   0   0  91   0   0   2   0]
 [  0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0  58   2   1   0]
 [  0   0   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  93   2   0]
 [  1   1   0   0   2   0   0   0   0   1   0   0   1   2   0   0   0   1  95   0]
 [  0   0   0   0   2   3   1   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 01:55:53,800 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 01:55:53,800 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:55:53,807 - 

2025-04-28 01:55:53,807 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:56:16,440 - Epoch: [165][   90/   90]    Overall Loss 0.008599    Objective Loss 0.008599    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.251446    
2025-04-28 01:56:16,466 - --- validate (epoch=165)-----------
2025-04-28 01:56:16,466 - 2245 samples (100 per mini-batch)
2025-04-28 01:56:18,875 - Epoch: [165][   23/   23]    Loss 0.280607    Top1 94.877506    Top5 98.841871    
2025-04-28 01:56:18,898 - ==> Top1: 94.878    Top5: 98.842    Loss: 0.281

2025-04-28 01:56:18,898 - ==> Confusion:
[[ 97   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   3]
 [  0 114   1   0   0   0   0   1   0   0   0   0   0   0   0   1   2   0   1   0]
 [  0   0  98   0   1   0   1   0   1   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 142   0   0   0   0   0   1   0   2   0   1   0   0   0   0   3   0]
 [  0   0   0   0 195   0   0   0   0   0   0   0   1   0   0   0   0   0   1   1]
 [  0   0   0   0   3  76   0   0   0   0   0   0   0   0   0   1   1   0   1   6]
 [  0   0   0   1   1   0 121   0   0   0   2   0   0   0   0   0   0   0   0   3]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  0   1   0   3   0   2   0   0   0  77   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   2   0   0   0   0   0   0   0   0   0 113   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   1   0]
 [  0   1   0   0   2   0   0   1   1   0   0   0   0   0   0  91   0   0   2   0]
 [  0   1   0   1   0   1   0   0   0   0   0   1   0   0   0   0  56   2   1   0]
 [  0   1   0   1   0   0   0   0   0   0   2   0   0   0   0   0   0  91   2   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   1   0   0   0   2  95   1]
 [  0   0   0   0   1   3   1   0   0   0   2   0   0   0   0   1   0   0   0 131]]

2025-04-28 01:56:18,901 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 01:56:18,901 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:56:18,909 - 

2025-04-28 01:56:18,909 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:56:41,580 - Epoch: [166][   90/   90]    Overall Loss 0.012179    Objective Loss 0.012179    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.251865    
2025-04-28 01:56:41,606 - --- validate (epoch=166)-----------
2025-04-28 01:56:41,606 - 2245 samples (100 per mini-batch)
2025-04-28 01:56:43,878 - Epoch: [166][   23/   23]    Loss 0.270615    Top1 94.788419    Top5 98.975501    
2025-04-28 01:56:43,903 - ==> Top1: 94.788    Top5: 98.976    Loss: 0.271

2025-04-28 01:56:43,904 - ==> Confusion:
[[ 97   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   1   2]
 [  0 113   1   0   0   0   0   1   0   1   1   0   0   0   0   1   1   0   1   0]
 [  0   0  98   0   2   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   1   0   0   0   0   2   0   2   0   0   0   0   4   0]
 [  0   0   0   0 192   1   0   0   0   0   0   0   1   0   0   0   1   0   1   2]
 [  0   0   0   0   0  79   0   0   0   0   0   0   1   0   0   1   1   1   0   5]
 [  0   0   0   0   1   0 122   0   0   0   2   0   0   0   0   0   0   0   0   3]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   2   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   2   0   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   2   0   1   0   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   1   0   0   0   1   0   0   0 112   0   0   0   0   0   0]
 [  0   0   1   0   1   0   0   0   0   0   0   0   2   0  55   0   0   0   0   0]
 [  0   1   0   0   2   0   0   1   0   0   0   0   0   0   0  93   0   0   1   0]
 [  0   1   0   0   0   2   0   0   0   0   0   0   0   0   0   0  58   1   1   0]
 [  0   2   0   1   0   1   0   0   0   0   2   0   0   0   0   0   0  89   2   0]
 [  1   0   0   0   1   1   0   0   0   1   0   0   0   2   0   0   0   4  94   0]
 [  0   0   1   0   2   3   1   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:56:43,906 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 01:56:43,906 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:56:43,914 - 

2025-04-28 01:56:43,915 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:57:06,518 - Epoch: [167][   90/   90]    Overall Loss 0.011279    Objective Loss 0.011279    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.251125    
2025-04-28 01:57:06,551 - --- validate (epoch=167)-----------
2025-04-28 01:57:06,551 - 2245 samples (100 per mini-batch)
2025-04-28 01:57:08,865 - Epoch: [167][   23/   23]    Loss 0.279068    Top1 94.877506    Top5 98.930958    
2025-04-28 01:57:08,888 - ==> Top1: 94.878    Top5: 98.931    Loss: 0.279

2025-04-28 01:57:08,888 - ==> Confusion:
[[ 97   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   3]
 [  0 114   1   0   0   0   0   1   0   1   0   0   0   0   0   1   1   0   1   0]
 [  0   0  97   0   2   0   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   0   0   0   0   0   3   0   2   0   0   0   0   4   0]
 [  0   0   0   0 193   1   0   0   0   0   0   0   1   0   0   0   0   0   2   1]
 [  0   0   0   0   0  77   0   0   0   0   0   0   0   0   0   1   1   2   0   7]
 [  0   0   0   0   1   0 123   0   0   0   2   0   0   0   0   0   0   0   0   2]
 [  0   1   1   0   0   0   0  99   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   2   0   1   0   0   0  77   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   0   3   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   1   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   1   0   1   0   0   0   1   0 111   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   0   2   0   0   1   0   0   0   0   0   0   0  93   0   1   0   0]
 [  0   2   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   2   0   1   0   1   0   0   0   0   1   0   0   0   0   0   0  91   1   0]
 [  1   1   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   3  94   0]
 [  0   0   0   0   1   4   1   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 01:57:08,890 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 01:57:08,890 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:57:08,897 - 

2025-04-28 01:57:08,898 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:57:31,598 - Epoch: [168][   90/   90]    Overall Loss 0.008733    Objective Loss 0.008733    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.252200    
2025-04-28 01:57:31,627 - --- validate (epoch=168)-----------
2025-04-28 01:57:31,627 - 2245 samples (100 per mini-batch)
2025-04-28 01:57:33,913 - Epoch: [168][   23/   23]    Loss 0.279589    Top1 94.743875    Top5 98.930958    
2025-04-28 01:57:33,931 - ==> Top1: 94.744    Top5: 98.931    Loss: 0.280

2025-04-28 01:57:33,932 - ==> Confusion:
[[ 97   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   1   2]
 [  0 113   1   0   0   0   0   1   0   1   1   0   0   0   0   1   1   0   1   0]
 [  0   0  98   0   2   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   0   0   0   0   0   3   0   2   0   0   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   1   0   1   1]
 [  0   0   0   0   2  76   0   0   0   0   0   0   0   0   0   1   1   1   0   7]
 [  0   0   0   1   1   0 122   0   0   0   2   0   0   0   0   0   0   0   0   2]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   3   0   1   0   0   0  78   0   1   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 113   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   2   1   0   0   0   0   1   0   0   0 111   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   0   2   0   0   1   1   0   0   0   0   0   0  92   0   1   0   0]
 [  0   1   0   0   0   2   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  1   2   0   1   0   1   0   0   0   0   2   0   0   0   0   0   0  89   1   0]
 [  1   0   0   0   2   1   0   0   0   1   0   0   1   1   0   0   0   2  95   0]
 [  0   0   1   0   1   3   1   0   0   0   4   0   0   0   0   0   0   0   0 129]]

2025-04-28 01:57:33,934 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 01:57:33,934 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:57:33,942 - 

2025-04-28 01:57:33,942 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:57:56,702 - Epoch: [169][   90/   90]    Overall Loss 0.009170    Objective Loss 0.009170    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.252860    
2025-04-28 01:57:56,735 - --- validate (epoch=169)-----------
2025-04-28 01:57:56,735 - 2245 samples (100 per mini-batch)
2025-04-28 01:57:59,017 - Epoch: [169][   23/   23]    Loss 0.272876    Top1 94.565702    Top5 98.752784    
2025-04-28 01:57:59,042 - ==> Top1: 94.566    Top5: 98.753    Loss: 0.273

2025-04-28 01:57:59,043 - ==> Confusion:
[[ 97   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   1   2]
 [  0 114   1   0   0   0   0   1   0   1   0   0   0   0   0   1   1   0   1   0]
 [  0   0  97   0   2   0   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 138   0   0   1   0   0   0   0   3   0   2   0   1   0   0   4   0]
 [  0   0   0   0 193   1   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   2  76   0   0   0   0   0   0   0   0   0   1   1   0   0   8]
 [  0   0   0   0   0   0 119   0   1   0   2   0   0   0   1   0   0   0   0   5]
 [  0   0   1   0   0   1   0  98   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   3   0   1   0   0   0  78   0   1   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   2   1   0]
 [  1   1   0   1   0   0   0   0   0   0   0  75   0   1   0   0   1   0   0   1]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   2   0   0   0   0   0   1   0   0   0 111   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   0   1   0   0   1   1   0   0   0   0   0   0  93   0   0   1   0]
 [  0   1   0   0   0   2   0   0   0   0   0   2   0   0   0   0  56   1   1   0]
 [  0   1   0   2   0   1   0   0   1   0   1   0   0   0   0   0   0  89   2   0]
 [  1   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   2  96   0]
 [  0   0   0   0   2   3   1   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 01:57:59,045 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 01:57:59,045 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:57:59,052 - 

2025-04-28 01:57:59,052 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:58:21,868 - Epoch: [170][   90/   90]    Overall Loss 0.013906    Objective Loss 0.013906    Top1 98.561151    Top5 100.000000    LR 0.000250    Time 0.253482    
2025-04-28 01:58:21,896 - --- validate (epoch=170)-----------
2025-04-28 01:58:21,897 - 2245 samples (100 per mini-batch)
2025-04-28 01:58:24,223 - Epoch: [170][   23/   23]    Loss 0.298878    Top1 94.610245    Top5 98.886414    
2025-04-28 01:58:24,247 - ==> Top1: 94.610    Top5: 98.886    Loss: 0.299

2025-04-28 01:58:24,247 - ==> Confusion:
[[ 95   0   0   0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   1   4]
 [  0 114   1   0   0   0   0   1   0   1   0   0   0   0   0   1   1   0   1   0]
 [  0   0  98   0   1   0   1   0   2   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 141   0   0   1   0   0   0   0   3   0   2   0   0   0   0   2   0]
 [  0   0   0   0 195   0   0   1   0   0   0   0   0   0   0   0   0   0   1   1]
 [  0   0   0   0   3  76   0   0   0   0   0   0   0   0   0   1   1   0   0   7]
 [  0   0   1   0   1   0 119   0   1   0   2   1   0   0   1   0   0   0   0   2]
 [  0   0   1   0   0   0   0 101   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 214   0   0   0   0   0   0   0   1   0   1   0]
 [  0   2   0   3   0   2   0   1   0  77   0   1   0   0   0   0   0   0   0   0]
 [  0   2   0   0   0   0   0   0   0   0 110   0   0   0   0   0   0   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   0   1   0   0   1]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   2   0   0   0   0   0   1   0   0   0 111   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   1   0   0   1   0   0   0   0   0   0   0  92   0   0   2   0]
 [  0   1   0   0   0   2   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   2   0   1   0   1   0   0   0   0   3   0   0   0   0   0   0  88   2   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   2   0   0   1   2  94   1]
 [  0   0   1   0   1   3   1   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 01:58:24,249 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 01:58:24,249 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:58:24,257 - 

2025-04-28 01:58:24,257 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:58:46,933 - Epoch: [171][   90/   90]    Overall Loss 0.013897    Objective Loss 0.013897    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.251924    
2025-04-28 01:58:46,958 - --- validate (epoch=171)-----------
2025-04-28 01:58:46,959 - 2245 samples (100 per mini-batch)
2025-04-28 01:58:49,288 - Epoch: [171][   23/   23]    Loss 0.287505    Top1 94.610245    Top5 98.975501    
2025-04-28 01:58:49,309 - ==> Top1: 94.610    Top5: 98.976    Loss: 0.288

2025-04-28 01:58:49,309 - ==> Confusion:
[[ 95   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   1   4]
 [  0 114   1   0   0   0   0   2   0   0   0   0   0   0   0   0   2   0   1   0]
 [  0   0  98   0   1   0   2   0   0   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 139   0   0   0   0   0   0   0   3   0   3   0   0   0   0   4   0]
 [  0   0   0   0 194   0   0   1   0   0   0   0   0   0   0   0   0   0   1   2]
 [  0   0   0   0   2  78   0   0   0   0   0   0   0   0   0   1   0   0   0   7]
 [  0   0   1   1   1   0 121   0   0   0   1   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   1   0  98   0   0   1   0   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   3   0   2   0   0   0  76   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   1   0   0   2]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   1   0   0   0   0   0   0   0 112   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   1   0]
 [  0   1   0   0   2   0   0   1   1   0   0   0   0   0   0  92   0   0   1   0]
 [  0   0   0   0   0   2   0   0   0   1   0   0   0   0   0   0  57   1   2   0]
 [  0   1   0   1   0   2   0   0   1   0   1   0   0   0   0   1   0  88   2   0]
 [  0   0   1   0   2   1   0   0   0   1   0   0   0   1   0   0   0   3  94   1]
 [  0   0   0   0   1   3   1   0   0   0   2   0   0   0   0   0   0   0   0 132]]

2025-04-28 01:58:49,311 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 01:58:49,311 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:58:49,319 - 

2025-04-28 01:58:49,319 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:59:11,994 - Epoch: [172][   90/   90]    Overall Loss 0.009826    Objective Loss 0.009826    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.251913    
2025-04-28 01:59:12,015 - --- validate (epoch=172)-----------
2025-04-28 01:59:12,015 - 2245 samples (100 per mini-batch)
2025-04-28 01:59:14,307 - Epoch: [172][   23/   23]    Loss 0.283388    Top1 94.743875    Top5 98.975501    
2025-04-28 01:59:14,329 - ==> Top1: 94.744    Top5: 98.976    Loss: 0.283

2025-04-28 01:59:14,330 - ==> Confusion:
[[ 95   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   1   1   3]
 [  0 114   1   0   0   0   0   2   0   1   0   0   0   0   0   0   1   0   1   0]
 [  0   0  99   0   1   0   1   0   0   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 141   0   0   0   0   0   0   0   1   0   3   0   0   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   2   0   1   0   0   0   1   1]
 [  0   0   0   0   2  77   1   0   0   0   0   1   0   0   0   1   1   0   0   5]
 [  0   0   0   0   1   0 123   0   0   0   2   0   0   0   0   0   0   0   0   2]
 [  0   0   0   0   0   1   0  97   0   0   2   0   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   0   0   0   0  78   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   2   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 112   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   2   0  55   0   0   0   1   0]
 [  0   1   0   1   2   0   0   1   0   0   0   0   0   0   0  91   0   0   2   0]
 [  0   1   0   0   0   2   0   0   0   0   0   0   0   0   0   0  57   1   2   0]
 [  0   2   0   1   0   0   0   0   0   0   2   0   0   0   0   1   0  88   3   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   3  95   1]
 [  0   0   0   0   1   3   1   0   0   0   3   0   0   0   0   0   0   0   0 131]]

2025-04-28 01:59:14,332 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 01:59:14,332 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:59:14,340 - 

2025-04-28 01:59:14,340 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 01:59:37,038 - Epoch: [173][   90/   90]    Overall Loss 0.011001    Objective Loss 0.011001    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.252176    
2025-04-28 01:59:37,070 - --- validate (epoch=173)-----------
2025-04-28 01:59:37,070 - 2245 samples (100 per mini-batch)
2025-04-28 01:59:39,380 - Epoch: [173][   23/   23]    Loss 0.281980    Top1 94.966592    Top5 98.930958    
2025-04-28 01:59:39,399 - ==> Top1: 94.967    Top5: 98.931    Loss: 0.282

2025-04-28 01:59:39,399 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   2]
 [  0 114   0   0   0   0   0   1   0   1   0   0   0   0   0   1   1   0   1   1]
 [  0   0  97   0   1   0   2   0   1   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 142   0   0   1   0   0   0   0   3   0   2   0   0   0   0   1   0]
 [  0   0   0   1 193   0   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   2  79   1   0   0   0   0   0   0   0   0   1   1   0   0   4]
 [  0   0   0   1   1   0 121   0   1   0   2   0   0   0   0   1   0   0   0   1]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   3   0   2   0   0   0  78   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   1  78   0   0   0   0   0   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   3   0   1   0   0   0   2   0   0   0 109   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   0   1   0   0   0   0   0  90   0   0   2   0]
 [  0   1   0   0   0   1   0   0   0   1   0   1   0   0   0   0  57   1   1   0]
 [  0   2   0   2   0   1   0   0   0   0   2   0   0   0   0   1   0  88   1   0]
 [  1   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   3  95   0]
 [  0   0   0   0   1   3   1   0   0   0   2   0   0   0   0   0   0   0   0 132]]

2025-04-28 01:59:39,402 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 01:59:39,402 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 01:59:39,409 - 

2025-04-28 01:59:39,409 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:00:02,350 - Epoch: [174][   90/   90]    Overall Loss 0.010824    Objective Loss 0.010824    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.254869    
2025-04-28 02:00:02,379 - --- validate (epoch=174)-----------
2025-04-28 02:00:02,379 - 2245 samples (100 per mini-batch)
2025-04-28 02:00:04,696 - Epoch: [174][   23/   23]    Loss 0.288106    Top1 94.743875    Top5 98.975501    
2025-04-28 02:00:04,722 - ==> Top1: 94.744    Top5: 98.976    Loss: 0.288

2025-04-28 02:00:04,723 - ==> Confusion:
[[ 98   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   3]
 [  0 113   0   0   0   0   0   1   0   0   0   2   0   0   0   1   1   0   1   1]
 [  0   0  98   0   1   0   2   0   0   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 140   0   0   0   0   0   0   0   3   0   3   0   0   0   0   3   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   2   0   1   0   0   0   2   1]
 [  1   0   0   0   0  79   0   0   0   0   0   1   0   0   1   1   1   1   0   3]
 [  0   0   0   0   1   0 122   0   0   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   1   0  97   0   1   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   0   0   0   0   0   1]
 [  0   1   0   1   0   1   0   0   0  79   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  1   1   0   1   0   0   0   0   0   0   0  75   0   1   0   1   1   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   1   0   0   0 112   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   1   0]
 [  0   1   0   1   1   0   0   1   0   0   0   0   0   0   0  92   0   0   2   0]
 [  0   0   0   0   0   2   0   0   0   1   0   1   0   0   0   0  57   1   1   0]
 [  0   2   0   1   0   1   0   0   0   0   2   0   0   0   0   1   0  88   2   0]
 [  1   0   0   0   0   1   0   0   0   1   0   0   2   2   0   0   1   0  96   0]
 [  0   0   1   0   2   2   1   0   0   0   3   0   0   0   0   0   1   0   0 129]]

2025-04-28 02:00:04,725 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:00:04,725 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:00:04,733 - 

2025-04-28 02:00:04,733 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:00:27,456 - Epoch: [175][   90/   90]    Overall Loss 0.011150    Objective Loss 0.011150    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.252451    
2025-04-28 02:00:27,482 - --- validate (epoch=175)-----------
2025-04-28 02:00:27,483 - 2245 samples (100 per mini-batch)
2025-04-28 02:00:29,756 - Epoch: [175][   23/   23]    Loss 0.281321    Top1 94.521158    Top5 99.153675    
2025-04-28 02:00:29,778 - ==> Top1: 94.521    Top5: 99.154    Loss: 0.281

2025-04-28 02:00:29,778 - ==> Confusion:
[[ 97   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   1   2]
 [  0 113   0   0   0   0   0   1   0   1   0   0   0   0   0   1   2   0   1   1]
 [  0   0  98   0   1   0   2   0   0   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 139   0   0   0   0   0   0   0   3   0   3   0   0   0   0   4   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   0   0   0   0   2   1]
 [  0   0   0   0   2  77   1   0   0   0   0   0   0   0   1   1   1   1   0   4]
 [  0   0   0   0   0   0 121   0   1   0   2   0   0   0   1   0   0   0   0   3]
 [  0   0   0   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   2   0]
 [  0   0   0   0   0   0   0   0 214   0   0   0   0   0   0   0   0   0   1   1]
 [  0   0   0   3   0   2   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  80   0   2   0   0   0   0   0]
 [  0   0   0   1   0   1   0   0   0   0   0   0   0 111   0   0   0   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   4   0   0   1   0   0   0   0   0   0   0  89   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   1   0   0   0   0   0   0  57   1   2   0]
 [  0   2   0   1   0   0   0   0   0   0   2   0   0   0   0   0   0  89   3   0]
 [  1   0   0   0   1   1   0   0   0   1   0   0   1   2   0   0   0   1  96   0]
 [  1   0   0   0   0   4   1   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 02:00:29,781 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:00:29,781 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:00:29,789 - 

2025-04-28 02:00:29,789 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:00:52,542 - Epoch: [176][   90/   90]    Overall Loss 0.008953    Objective Loss 0.008953    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.252777    
2025-04-28 02:00:52,569 - --- validate (epoch=176)-----------
2025-04-28 02:00:52,569 - 2245 samples (100 per mini-batch)
2025-04-28 02:00:54,960 - Epoch: [176][   23/   23]    Loss 0.287884    Top1 94.788419    Top5 99.109131    
2025-04-28 02:00:54,981 - ==> Top1: 94.788    Top5: 99.109    Loss: 0.288

2025-04-28 02:00:54,982 - ==> Confusion:
[[ 97   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   1   2]
 [  0 115   0   0   0   0   0   1   0   0   0   0   0   0   0   1   1   0   1   1]
 [  0   0  97   0   1   1   2   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 139   0   0   1   0   0   0   0   3   0   3   0   0   0   0   3   0]
 [  0   0   0   0 191   1   0   0   0   0   0   0   1   0   1   0   0   0   3   1]
 [  0   0   0   0   1  79   1   0   0   0   0   0   0   0   1   1   1   1   0   3]
 [  0   0   0   0   1   0 123   0   1   0   2   0   0   0   0   0   0   0   0   1]
 [  0   1   1   0   0   0   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   1   0   0   0  77   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   2   0   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   0   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   1   0   0   0 112   0   0   0   0   1   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   0   0]
 [  0   1   0   0   1   0   0   1   1   0   0   0   0   0   0  92   0   0   2   0]
 [  0   2   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   2   0   1   0   0   0   0   0   0   2   0   0   0   0   0   0  90   2   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   1   1   0   0   1   2  97   0]
 [  1   0   0   0   0   4   2   0   0   0   3   0   0   0   0   0   1   0   0 128]]

2025-04-28 02:00:54,984 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:00:54,984 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:00:54,993 - 

2025-04-28 02:00:54,993 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:01:17,719 - Epoch: [177][   90/   90]    Overall Loss 0.010556    Objective Loss 0.010556    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.252483    
2025-04-28 02:01:17,744 - --- validate (epoch=177)-----------
2025-04-28 02:01:17,744 - 2245 samples (100 per mini-batch)
2025-04-28 02:01:20,022 - Epoch: [177][   23/   23]    Loss 0.290852    Top1 94.521158    Top5 98.930958    
2025-04-28 02:01:20,043 - ==> Top1: 94.521    Top5: 98.931    Loss: 0.291

2025-04-28 02:01:20,044 - ==> Confusion:
[[ 97   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   1   2]
 [  0 113   0   0   0   0   0   2   0   0   1   0   0   0   0   0   2   0   1   1]
 [  0   1  96   0   2   0   2   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 141   0   0   0   0   0   0   0   3   0   1   0   0   0   0   4   0]
 [  0   0   0   0 191   1   0   0   0   0   0   0   1   0   1   0   0   0   2   2]
 [  0   0   0   0   1  75   1   0   0   0   0   0   0   0   0   1   1   0   0   9]
 [  0   0   0   0   0   0 119   0   1   0   2   0   0   0   1   0   0   0   0   5]
 [  0   0   0   0   0   1   0  99   0   1   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   2   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   1   1   0   1]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   1   0   1   0 111   0   0   0   0   1   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   3   0  54   0   0   0   0   1]
 [  0   1   0   1   1   0   0   1   0   0   0   0   0   0   0  92   0   0   2   0]
 [  0   1   0   0   0   2   0   0   0   0   0   0   0   0   0   0  58   1   1   0]
 [  0   1   0   1   0   0   0   0   0   0   2   0   0   0   0   0   0  90   3   0]
 [  1   1   0   0   1   1   0   0   0   0   0   0   1   1   0   0   1   1  94   2]
 [  0   0   0   0   1   3   0   0   0   0   2   0   0   0   0   0   0   0   0 133]]

2025-04-28 02:01:20,046 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:01:20,046 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:01:20,054 - 

2025-04-28 02:01:20,054 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:01:42,428 - Epoch: [178][   90/   90]    Overall Loss 0.011818    Objective Loss 0.011818    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.248568    
2025-04-28 02:01:42,452 - --- validate (epoch=178)-----------
2025-04-28 02:01:42,452 - 2245 samples (100 per mini-batch)
2025-04-28 02:01:44,766 - Epoch: [178][   23/   23]    Loss 0.288148    Top1 94.610245    Top5 98.930958    
2025-04-28 02:01:44,786 - ==> Top1: 94.610    Top5: 98.931    Loss: 0.288

2025-04-28 02:01:44,787 - ==> Confusion:
[[ 97   0   0   0   0   1   1   0   1   0   0   0   0   0   0   0   0   0   0   2]
 [  0 111   0   2   0   0   0   1   0   1   1   0   0   0   0   1   1   0   1   1]
 [  0   0  96   0   1   0   3   0   1   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 141   0   0   0   0   0   0   0   3   0   1   0   0   0   0   4   0]
 [  0   0   0   0 192   1   0   0   0   0   0   0   0   1   1   0   0   0   2   1]
 [  0   0   0   0   2  76   0   0   0   0   0   0   0   0   0   1   1   1   0   7]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   0   0   0   0   0   3]
 [  0   0   1   0   0   0   0  98   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   1  74   0   1   0   1   1   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   2   0   0   0   0   0   1   1   0   0 111   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   1   0]
 [  0   1   0   1   1   0   0   1   0   0   0   0   0   0   0  93   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0  58   2   1   0]
 [  0   1   0   1   0   1   0   0   0   0   3   0   0   0   0   0   0  88   3   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   2   1   0   0   0   2  95   1]
 [  1   0   0   0   0   3   2   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:01:44,789 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:01:44,789 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:01:44,798 - 

2025-04-28 02:01:44,798 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:02:07,466 - Epoch: [179][   90/   90]    Overall Loss 0.009989    Objective Loss 0.009989    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.251841    
2025-04-28 02:02:07,493 - --- validate (epoch=179)-----------
2025-04-28 02:02:07,493 - 2245 samples (100 per mini-batch)
2025-04-28 02:02:09,869 - Epoch: [179][   23/   23]    Loss 0.292071    Top1 94.743875    Top5 99.064588    
2025-04-28 02:02:09,895 - ==> Top1: 94.744    Top5: 99.065    Loss: 0.292

2025-04-28 02:02:09,895 - ==> Confusion:
[[ 95   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   1   0   4]
 [  0 113   0   1   0   0   0   1   0   1   0   0   0   0   0   1   1   0   1   1]
 [  0   0  98   0   2   0   1   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 143   0   0   0   0   0   0   0   2   0   2   0   0   0   0   2   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   0   1   0   0   0   0   2   1]
 [  0   0   0   0   3  75   0   0   0   0   0   0   0   0   0   1   1   0   0   8]
 [  0   0   0   0   1   0 120   0   1   0   2   0   0   0   1   0   0   0   0   3]
 [  0   0   1   0   0   0   0 100   0   0   0   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   0   0   0  79   0   2   0   0   0   0   0   0   0   0]
 [  0   1   0   1   0   0   0   0   0   0 110   0   0   0   0   0   1   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   1  75   0   2   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   2   0   0   0   0   0   0   0   0   0 112   0   0   0   0   1   0]
 [  0   0   1   0   1   0   0   0   0   0   0   0   2   0  55   0   0   0   0   0]
 [  0   1   0   1   1   0   0   1   0   0   0   0   0   0   0  93   0   0   1   0]
 [  0   2   0   0   0   1   0   0   0   0   0   2   0   0   0   0  56   1   1   0]
 [  0   2   0   1   0   1   0   0   0   0   3   0   0   0   0   0   0  87   3   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   2   0   0   1   1  94   1]
 [  0   0   0   0   3   2   0   0   0   0   1   0   0   0   0   1   0   0   0 132]]

2025-04-28 02:02:09,898 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:02:09,898 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:02:09,905 - 

2025-04-28 02:02:09,905 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:02:32,599 - Epoch: [180][   90/   90]    Overall Loss 0.010046    Objective Loss 0.010046    Top1 97.841727    Top5 100.000000    LR 0.000250    Time 0.252120    
2025-04-28 02:02:32,627 - --- validate (epoch=180)-----------
2025-04-28 02:02:32,627 - 2245 samples (100 per mini-batch)
2025-04-28 02:02:34,898 - Epoch: [180][   23/   23]    Loss 0.293902    Top1 94.521158    Top5 98.975501    
2025-04-28 02:02:34,922 - ==> Top1: 94.521    Top5: 98.976    Loss: 0.294

2025-04-28 02:02:34,923 - ==> Confusion:
[[ 99   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   2]
 [  0 114   0   0   0   0   0   2   0   1   0   0   0   0   0   0   1   0   1   1]
 [  0   0  97   0   2   0   2   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   0   0   0   0   3   0   2   0   1   0   0   2   0]
 [  1   0   0   1 191   1   0   1   0   0   0   0   0   0   0   0   0   0   2   1]
 [  1   0   0   0   2  76   0   0   0   0   0   0   0   0   0   1   1   0   0   7]
 [  0   0   0   0   1   0 123   0   1   0   2   0   0   0   0   0   0   0   0   1]
 [  0   0   1   0   0   1   0  99   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  76   0   1   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   2   1   0   0 111   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   4   0  53   0   0   0   1   0]
 [  0   1   0   1   2   0   0   2   1   0   0   0   0   0   0  89   0   0   2   0]
 [  0   2   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   2   0   1   0   0   0   0   0   0   2   0   0   0   0   0   1  90   1   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   1   0   0   1   3  93   1]
 [  1   0   0   0   0   3   2   0   0   0   3   0   0   0   0   0   1   0   0 129]]

2025-04-28 02:02:34,925 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:02:34,925 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:02:34,932 - 

2025-04-28 02:02:34,932 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:02:57,729 - Epoch: [181][   90/   90]    Overall Loss 0.011647    Objective Loss 0.011647    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.253265    
2025-04-28 02:02:57,758 - --- validate (epoch=181)-----------
2025-04-28 02:02:57,759 - 2245 samples (100 per mini-batch)
2025-04-28 02:03:00,072 - Epoch: [181][   23/   23]    Loss 0.309693    Top1 94.387528    Top5 99.064588    
2025-04-28 02:03:00,095 - ==> Top1: 94.388    Top5: 99.065    Loss: 0.310

2025-04-28 02:03:00,096 - ==> Confusion:
[[ 96   0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   3]
 [  0 113   0   0   0   0   1   2   0   1   0   0   0   0   0   0   1   0   1   1]
 [  0   0  96   0   2   0   3   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   1   0   0   0   0   3   0   1   0   0   0   0   3   0]
 [  0   0   0   0 191   0   0   0   0   0   0   0   1   0   1   0   0   0   2   3]
 [  0   0   0   0   2  75   2   0   0   0   0   0   0   0   0   1   1   0   0   7]
 [  0   0   0   0   0   0 124   0   1   0   2   0   0   0   0   0   0   0   0   1]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   2   0   1   1   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   1   0  80   0   1   0   0   0   0   0]
 [  0   0   0   1   0   1   0   0   0   2   1   0   0 110   0   0   0   0   0   0]
 [  0   0   1   0   0   0   1   0   0   0   0   0   3   0  54   0   0   0   0   0]
 [  0   1   0   0   2   0   0   1   0   1   0   0   0   0   1  91   0   0   1   0]
 [  0   2   0   0   0   1   0   0   0   0   0   0   0   0   0   0  57   1   1   1]
 [  0   1   0   1   0   1   0   0   0   0   4   0   0   0   0   0   0  88   2   0]
 [  0   0   1   0   1   1   0   0   0   1   0   0   0   2   0   0   0   1  96   1]
 [  0   0   1   0   0   2   1   0   0   0   4   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:03:00,098 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:03:00,098 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:03:00,105 - 

2025-04-28 02:03:00,105 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:03:22,832 - Epoch: [182][   90/   90]    Overall Loss 0.010352    Objective Loss 0.010352    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.252486    
2025-04-28 02:03:22,857 - --- validate (epoch=182)-----------
2025-04-28 02:03:22,858 - 2245 samples (100 per mini-batch)
2025-04-28 02:03:25,179 - Epoch: [182][   23/   23]    Loss 0.296487    Top1 94.788419    Top5 99.020045    
2025-04-28 02:03:25,210 - ==> Top1: 94.788    Top5: 99.020    Loss: 0.296

2025-04-28 02:03:25,210 - ==> Confusion:
[[ 97   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   2]
 [  0 114   0   0   0   0   0   2   0   1   0   0   0   0   0   0   1   0   1   1]
 [  0   0  97   0   2   0   2   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 143   0   0   0   0   0   0   0   2   0   2   0   0   0   0   2   0]
 [  0   0   0   0 194   0   0   1   0   0   0   0   0   0   0   0   0   0   2   1]
 [  0   0   0   0   2  76   0   0   0   0   0   0   0   0   0   1   1   0   0   8]
 [  0   0   0   0   1   0 122   0   1   0   1   1   0   0   1   0   0   0   0   1]
 [  0   0   0   1   0   0   0  99   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   3   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   1   0   0   0   0   0   0   0  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   0   1   0   0 113   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   1   0]
 [  0   1   0   2   3   0   0   1   0   0   0   0   0   0   1  90   0   0   0   0]
 [  0   2   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   2   0   1   0   1   0   0   0   0   3   0   0   0   0   0   0  87   3   0]
 [  1   0   1   0   2   0   0   0   0   1   0   0   1   2   0   0   1   1  93   1]
 [  0   0   0   0   1   3   1   0   0   0   3   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:03:25,212 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:03:25,212 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:03:25,220 - 

2025-04-28 02:03:25,220 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:03:48,087 - Epoch: [183][   90/   90]    Overall Loss 0.011200    Objective Loss 0.011200    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.254056    
2025-04-28 02:03:48,122 - --- validate (epoch=183)-----------
2025-04-28 02:03:48,122 - 2245 samples (100 per mini-batch)
2025-04-28 02:03:50,422 - Epoch: [183][   23/   23]    Loss 0.301848    Top1 94.565702    Top5 98.886414    
2025-04-28 02:03:50,445 - ==> Top1: 94.566    Top5: 98.886    Loss: 0.302

2025-04-28 02:03:50,446 - ==> Confusion:
[[ 96   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   4]
 [  0 112   0   0   1   0   0   2   0   1   1   0   0   0   0   1   1   0   1   0]
 [  0   0  97   0   2   0   2   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 142   0   0   0   0   0   0   0   1   0   2   0   0   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   2   1]
 [  0   0   0   0   2  77   0   0   0   0   0   0   0   0   0   1   1   0   0   7]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   1   0   0   1   0  98   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0   3   0   2   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  1   1   0   2   0   0   0   0   0   0   0  73   0   1   0   1   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   1   1   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   1   0]
 [  0   1   0   1   2   0   0   2   1   0   0   0   0   0   1  89   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0  58   2   1   0]
 [  0   1   0   0   0   1   0   0   0   0   3   0   0   0   0   0   0  89   3   0]
 [  1   0   0   0   1   0   0   0   0   1   0   0   2   2   0   0   0   1  95   1]
 [  0   0   0   0   1   3   1   0   0   0   3   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:03:50,448 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:03:50,448 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:03:50,456 - 

2025-04-28 02:03:50,456 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:04:13,047 - Epoch: [184][   90/   90]    Overall Loss 0.012454    Objective Loss 0.012454    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.250983    
2025-04-28 02:04:13,077 - --- validate (epoch=184)-----------
2025-04-28 02:04:13,077 - 2245 samples (100 per mini-batch)
2025-04-28 02:04:15,301 - Epoch: [184][   23/   23]    Loss 0.304290    Top1 94.654788    Top5 98.975501    
2025-04-28 02:04:15,326 - ==> Top1: 94.655    Top5: 98.976    Loss: 0.304

2025-04-28 02:04:15,327 - ==> Confusion:
[[ 95   0   0   1   0   2   1   0   1   0   0   0   0   0   0   0   0   0   0   2]
 [  0 113   0   0   0   0   0   1   0   1   1   0   0   0   0   1   1   0   1   1]
 [  0   0  96   0   1   1   3   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 142   0   0   1   0   0   0   0   2   0   2   0   0   0   0   2   0]
 [  0   0   0   1 191   0   0   1   0   0   0   0   0   0   2   0   0   0   2   1]
 [  0   0   0   0   1  78   0   0   0   0   0   0   0   0   0   1   1   0   0   7]
 [  0   0   0   0   0   0 124   0   0   0   2   0   0   0   0   0   0   0   0   2]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   2   0   0   0   0   0   0   0  75   0   1   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   3   0   0   0 110   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   0   0   0   0   0   0   1  92   0   0   0   0]
 [  0   2   0   0   0   1   0   0   0   0   0   0   0   0   0   0  58   1   1   0]
 [  0   2   0   0   0   1   0   0   0   0   3   0   0   0   0   0   0  88   3   0]
 [  0   0   1   0   1   1   0   0   0   1   0   0   1   1   0   0   0   1  96   1]
 [  0   0   0   0   1   3   2   0   0   0   3   0   0   0   0   1   0   0   0 129]]

2025-04-28 02:04:15,329 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:04:15,329 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:04:15,337 - 

2025-04-28 02:04:15,337 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:04:38,016 - Epoch: [185][   90/   90]    Overall Loss 0.009544    Objective Loss 0.009544    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.251969    
2025-04-28 02:04:38,054 - --- validate (epoch=185)-----------
2025-04-28 02:04:38,054 - 2245 samples (100 per mini-batch)
2025-04-28 02:04:40,432 - Epoch: [185][   23/   23]    Loss 0.300388    Top1 94.743875    Top5 98.797327    
2025-04-28 02:04:40,456 - ==> Top1: 94.744    Top5: 98.797    Loss: 0.300

2025-04-28 02:04:40,457 - ==> Confusion:
[[ 98   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0   2]
 [  0 111   1   0   0   0   0   2   0   1   0   1   0   0   0   1   2   0   1   0]
 [  0   0  98   0   1   0   3   0   0   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 139   0   0   0   0   0   0   0   3   0   3   0   1   0   0   3   0]
 [  0   0   0   0 195   0   0   0   0   0   0   0   1   0   0   0   0   0   1   1]
 [  0   0   0   0   3  75   0   0   0   0   0   0   0   0   0   1   1   0   0   8]
 [  0   0   0   0   1   0 125   0   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0  98   0   1   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   2   0   2   0   0   0  78   0   2   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   1  77   0   0   0   1   0   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   1   1   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  54   0   0   0   1   1]
 [  0   1   0   0   3   0   0   1   1   0   0   0   0   0   0  91   0   0   1   0]
 [  0   1   0   0   2   0   0   0   0   0   0   3   0   0   0   0  55   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   0   0  91   2   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   2   0   0   0   3  93   1]
 [  0   0   1   0   3   1   2   0   0   0   2   0   0   0   0   1   0   0   0 129]]

2025-04-28 02:04:40,459 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:04:40,459 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:04:40,467 - 

2025-04-28 02:04:40,467 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:05:03,163 - Epoch: [186][   90/   90]    Overall Loss 0.012112    Objective Loss 0.012112    Top1 98.561151    Top5 100.000000    LR 0.000250    Time 0.252150    
2025-04-28 02:05:03,189 - --- validate (epoch=186)-----------
2025-04-28 02:05:03,189 - 2245 samples (100 per mini-batch)
2025-04-28 02:05:05,506 - Epoch: [186][   23/   23]    Loss 0.326302    Top1 94.610245    Top5 98.797327    
2025-04-28 02:05:05,529 - ==> Top1: 94.610    Top5: 98.797    Loss: 0.326

2025-04-28 02:05:05,529 - ==> Confusion:
[[ 98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   3]
 [  0 110   0   0   0   0   0   1   0   1   2   0   0   1   0   1   2   0   1   1]
 [  0   0  96   0   1   0   2   0   1   0   2   0   0   0   0   0   0   0   0   1]
 [  0   0   0 142   0   0   0   0   0   0   0   1   0   2   0   0   0   0   4   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   1  75   0   0   0   0   0   0   0   0   0   1   1   0   0  10]
 [  0   0   0   0   1   0 123   0   0   0   2   0   0   0   0   1   0   0   0   1]
 [  0   0   1   0   0   0   0  98   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   3   0   0   0   0   0  79   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   1   0   0   1  75   0   1   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  80   0   2   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 111   0   0   0   0   1   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   3   0  54   0   0   0   1   0]
 [  0   1   0   0   1   0   0   1   1   0   0   0   0   0   0  93   0   0   1   0]
 [  0   1   0   0   1   0   0   0   0   1   0   1   0   0   0   0  57   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   1   0  90   3   0]
 [  0   0   1   0   2   1   0   0   0   1   0   0   0   1   0   0   0   2  95   1]
 [  0   0   1   0   1   3   2   0   0   0   3   0   0   0   0   1   0   0   0 128]]

2025-04-28 02:05:05,532 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:05:05,532 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:05:05,539 - 

2025-04-28 02:05:05,540 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:05:28,159 - Epoch: [187][   90/   90]    Overall Loss 0.013290    Objective Loss 0.013290    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.251305    
2025-04-28 02:05:28,187 - --- validate (epoch=187)-----------
2025-04-28 02:05:28,187 - 2245 samples (100 per mini-batch)
2025-04-28 02:05:30,516 - Epoch: [187][   23/   23]    Loss 0.314265    Top1 94.521158    Top5 99.064588    
2025-04-28 02:05:30,540 - ==> Top1: 94.521    Top5: 99.065    Loss: 0.314

2025-04-28 02:05:30,541 - ==> Confusion:
[[ 95   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   5]
 [  0 114   1   0   0   0   1   1   0   1   0   0   0   0   0   1   1   0   0   0]
 [  0   0  97   0   1   0   2   0   1   0   1   0   0   0   0   0   0   0   0   1]
 [  0   0   0 141   0   0   0   0   0   0   0   2   0   2   0   1   0   0   3   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   2  75   0   0   0   0   0   0   0   0   0   1   1   0   0   9]
 [  0   0   0   0   0   0 120   0   0   0   2   0   0   0   1   1   0   0   0   4]
 [  0   1   1   0   0   0   0  98   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  75   0   2   0   0   2   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   2   0   0   0 110   0   1   0   0   1   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   0   1   0   0   1   1   0   0   0   0   0   0  93   0   0   1   0]
 [  0   1   0   0   1   1   0   0   0   0   0   1   0   0   0   0  56   1   2   0]
 [  0   2   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1  89   3   0]
 [  0   0   1   0   2   1   0   0   0   1   0   0   0   2   0   0   0   3  93   1]
 [  0   0   0   0   0   4   1   0   0   0   2   0   0   0   0   0   0   0   0 132]]

2025-04-28 02:05:30,543 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:05:30,543 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:05:30,550 - 

2025-04-28 02:05:30,551 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:05:53,040 - Epoch: [188][   90/   90]    Overall Loss 0.011472    Objective Loss 0.011472    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.249862    
2025-04-28 02:05:53,071 - --- validate (epoch=188)-----------
2025-04-28 02:05:53,071 - 2245 samples (100 per mini-batch)
2025-04-28 02:05:55,427 - Epoch: [188][   23/   23]    Loss 0.293143    Top1 94.654788    Top5 98.930958    
2025-04-28 02:05:55,453 - ==> Top1: 94.655    Top5: 98.931    Loss: 0.293

2025-04-28 02:05:55,454 - ==> Confusion:
[[ 98   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   1]
 [  0 113   0   0   0   0   1   1   0   1   0   0   0   0   0   1   1   0   1   1]
 [  0   0  97   0   1   1   2   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 139   0   0   1   0   0   0   0   2   0   3   0   1   0   0   3   0]
 [  0   0   0   0 193   1   0   0   0   0   0   0   1   0   1   0   0   0   2   0]
 [  0   0   0   0   1  77   0   0   0   0   0   0   0   0   0   1   1   0   0   8]
 [  0   0   0   0   0   0 124   0   1   0   1   0   0   0   0   0   0   0   0   2]
 [  0   0   1   0   0   0   0  97   0   0   2   0   0   0   0   0   0   0   2   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   2   0   2   0   1   0   0   0  77   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  1   1   0   0   0   0   0   1   0   0   1  75   0   1   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   2   0   0   0   0   0   1   1   0   0 111   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   1   0   0   0   0   0   0  91   0   0   1   0]
 [  0   2   0   0   0   0   0   0   0   0   0   1   0   0   0   0  58   1   1   0]
 [  0   1   0   1   0   0   0   0   0   0   3   0   0   0   0   0   0  90   2   0]
 [  1   0   1   0   2   1   0   0   0   1   0   0   0   1   0   0   0   2  95   0]
 [  1   0   1   0   0   3   2   0   0   0   3   0   0   0   0   1   0   0   0 128]]

2025-04-28 02:05:55,456 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:05:55,456 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:05:55,465 - 

2025-04-28 02:05:55,465 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:06:18,342 - Epoch: [189][   90/   90]    Overall Loss 0.009733    Objective Loss 0.009733    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.254165    
2025-04-28 02:06:18,373 - --- validate (epoch=189)-----------
2025-04-28 02:06:18,373 - 2245 samples (100 per mini-batch)
2025-04-28 02:06:20,717 - Epoch: [189][   23/   23]    Loss 0.294558    Top1 94.699332    Top5 98.841871    
2025-04-28 02:06:20,740 - ==> Top1: 94.699    Top5: 98.842    Loss: 0.295

2025-04-28 02:06:20,741 - ==> Confusion:
[[ 99   0   0   2   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   0]
 [  0 113   0   0   0   0   0   1   0   0   1   0   0   0   0   1   2   0   1   1]
 [  0   0  97   0   1   0   2   0   2   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 139   0   0   0   0   0   0   0   2   0   3   0   1   0   0   4   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   2   0   1   0   0   0   1   2]
 [  0   0   0   0   4  76   0   0   0   0   0   0   0   0   0   1   0   0   0   7]
 [  0   0   0   0   1   0 122   0   0   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   1   0   0   0   0  99   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  0   2   0   2   0   2   0   0   0  77   0   1   0   0   0   0   1   0   1   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 111   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   1   0   0   0   0   0   0  91   0   0   1   0]
 [  0   1   0   0   1   1   0   0   0   0   0   0   0   0   0   0  58   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   1   0  90   3   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   0   2   0   0   0   2  94   2]
 [  1   0   0   0   0   3   1   0   0   0   3   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:06:20,743 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:06:20,743 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:06:20,751 - 

2025-04-28 02:06:20,751 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:06:43,390 - Epoch: [190][   90/   90]    Overall Loss 0.009820    Objective Loss 0.009820    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.251516    
2025-04-28 02:06:43,418 - --- validate (epoch=190)-----------
2025-04-28 02:06:43,418 - 2245 samples (100 per mini-batch)
2025-04-28 02:06:45,718 - Epoch: [190][   23/   23]    Loss 0.309834    Top1 94.699332    Top5 98.930958    
2025-04-28 02:06:45,739 - ==> Top1: 94.699    Top5: 98.931    Loss: 0.310

2025-04-28 02:06:45,739 - ==> Confusion:
[[ 99   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1]
 [  0 112   1   1   0   0   0   2   0   1   0   0   0   0   0   1   1   0   1   0]
 [  0   0  98   0   1   0   2   0   1   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 140   0   0   0   0   0   0   0   2   0   2   0   1   0   0   4   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   2   0   1   0   0   0   2   1]
 [  0   0   0   0   2  77   2   0   0   0   0   0   0   0   1   1   1   1   0   3]
 [  0   0   0   0   1   0 123   0   1   0   2   0   0   0   0   0   0   0   0   1]
 [  0   0   1   0   0   1   0  97   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   0   0   0  78   0   1   0   0   0   0   1   0   1   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   1   0   0   0 112   0   0   0   0   1   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   0   0]
 [  0   1   0   2   1   0   0   1   0   0   0   0   0   0   0  91   0   0   2   0]
 [  0   0   0   0   0   2   0   0   0   1   0   2   0   0   0   0  56   1   1   0]
 [  0   0   0   0   0   1   0   0   0   0   2   0   0   0   0   1   0  91   2   0]
 [  0   0   1   0   2   1   0   0   0   1   0   0   0   1   0   0   0   3  94   1]
 [  0   0   1   0   1   3   2   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 02:06:45,742 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:06:45,742 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:06:45,749 - 

2025-04-28 02:06:45,749 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:07:08,332 - Epoch: [191][   90/   90]    Overall Loss 0.010967    Objective Loss 0.010967    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.250895    
2025-04-28 02:07:08,360 - --- validate (epoch=191)-----------
2025-04-28 02:07:08,361 - 2245 samples (100 per mini-batch)
2025-04-28 02:07:10,699 - Epoch: [191][   23/   23]    Loss 0.300141    Top1 94.832962    Top5 98.975501    
2025-04-28 02:07:10,720 - ==> Top1: 94.833    Top5: 98.976    Loss: 0.300

2025-04-28 02:07:10,721 - ==> Confusion:
[[ 99   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   2]
 [  0 115   0   0   0   0   0   1   0   0   0   0   0   0   0   1   1   0   1   1]
 [  0   1  96   0   1   0   2   0   2   0   0   0   0   0   0   0   0   0   0   1]
 [  0   1   0 138   0   0   0   0   0   0   0   3   0   2   0   1   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   0   1   2   0]
 [  0   0   0   0   1  76   0   0   0   0   0   0   0   0   1   1   1   2   0   6]
 [  0   0   0   0   1   0 122   0   1   0   2   0   0   0   0   1   0   0   0   1]
 [  0   0   1   0   0   0   0  99   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   2   0   1   0   0   0  78   0   1   0   0   0   0   1   0   1   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   2   0   0]
 [  1   1   0   0   0   0   0   0   0   0   1  77   0   0   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   1   0   1   0   0   0   0   0   2   1   0   0 109   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   1   0   0   1   0   0   0   0   0   0   0  93   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   1   0   1   0   0   0   0  56   1   2   0]
 [  0   2   0   0   0   0   0   0   0   0   2   0   0   0   0   1   0  90   2   0]
 [  1   1   0   0   2   0   0   0   0   1   0   0   1   1   0   0   0   2  95   0]
 [  0   0   0   0   2   2   2   0   0   0   3   0   0   0   0   0   0   1   0 129]]

2025-04-28 02:07:10,723 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:07:10,723 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:07:10,730 - 

2025-04-28 02:07:10,731 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:07:33,364 - Epoch: [192][   90/   90]    Overall Loss 0.009304    Objective Loss 0.009304    Top1 98.561151    Top5 100.000000    LR 0.000250    Time 0.251458    
2025-04-28 02:07:33,397 - --- validate (epoch=192)-----------
2025-04-28 02:07:33,398 - 2245 samples (100 per mini-batch)
2025-04-28 02:07:35,715 - Epoch: [192][   23/   23]    Loss 0.311080    Top1 94.342984    Top5 98.930958    
2025-04-28 02:07:35,737 - ==> Top1: 94.343    Top5: 98.931    Loss: 0.311

2025-04-28 02:07:35,738 - ==> Confusion:
[[ 96   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   1   0   3]
 [  0 111   1   0   0   0   1   1   0   0   1   0   0   0   0   1   3   0   1   0]
 [  0   0  99   0   1   0   2   0   0   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 140   0   0   0   0   0   0   0   2   0   2   0   2   0   0   3   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   1   0   1   1]
 [  0   0   0   0   1  76   1   0   0   0   0   0   0   0   0   1   1   2   0   6]
 [  0   0   0   0   0   0 120   0   0   0   2   0   0   0   1   0   0   0   0   5]
 [  0   0   1   0   0   0   0  98   0   0   2   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   2   0   2   0   2   0   0   0  76   1   2   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   1  75   0   2   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   3   0   0   0   0   0   1   1   0   0 109   0   1   0   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   4   0  54   0   0   0   0   0]
 [  0   1   0   0   1   1   0   1   0   0   0   0   0   0   0  94   0   0   0   0]
 [  0   1   0   1   0   2   0   0   0   0   0   1   0   0   0   0  56   1   1   0]
 [  0   0   0   2   0   1   0   0   0   0   2   0   0   0   0   1   0  89   2   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   1   0   0   0   2  95   1]
 [  0   0   0   0   3   3   0   0   0   0   3   0   0   0   0   0   1   0   0 129]]

2025-04-28 02:07:35,740 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:07:35,740 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:07:35,748 - 

2025-04-28 02:07:35,748 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:07:58,524 - Epoch: [193][   90/   90]    Overall Loss 0.014687    Objective Loss 0.014687    Top1 98.561151    Top5 100.000000    LR 0.000250    Time 0.253042    
2025-04-28 02:07:58,552 - --- validate (epoch=193)-----------
2025-04-28 02:07:58,552 - 2245 samples (100 per mini-batch)
2025-04-28 02:08:00,896 - Epoch: [193][   23/   23]    Loss 0.324650    Top1 94.521158    Top5 99.064588    
2025-04-28 02:08:00,916 - ==> Top1: 94.521    Top5: 99.065    Loss: 0.325

2025-04-28 02:08:00,916 - ==> Confusion:
[[ 97   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   3]
 [  0 114   1   0   0   0   0   1   0   1   0   0   0   0   0   1   2   0   0   0]
 [  0   0  97   0   1   1   2   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 144   0   0   0   0   0   0   0   0   0   1   0   0   0   0   4   0]
 [  0   0   0   0 193   1   0   0   0   0   0   0   1   0   0   0   0   0   2   1]
 [  0   0   0   0   0  77   0   0   0   0   0   0   0   0   0   1   1   1   0   8]
 [  0   0   0   0   0   0 121   0   0   0   2   1   0   0   0   1   0   0   0   3]
 [  0   0   1   0   0   1   0  98   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   1   0   0   0   1   0 213   0   0   0   0   0   0   0   1   0   0   0]
 [  1   0   0   3   0   1   0   0   0  78   0   1   0   0   0   0   1   0   1   0]
 [  0   2   0   0   0   0   0   0   0   0 109   0   0   0   0   0   0   1   1   1]
 [  0   1   0   1   0   0   0   0   0   0   0  74   0   2   0   0   2   1   0   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0  80   0   1   0   0   1   0   0]
 [  0   0   0   2   0   0   0   0   0   2   0   0   0 110   0   0   0   0   1   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   0   0]
 [  0   1   0   1   2   1   0   2   0   0   0   0   0   0   0  90   0   0   1   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   0   0   0   0  58   1   2   0]
 [  0   1   0   1   0   2   0   0   0   0   2   0   0   0   0   1   0  88   2   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   2   0   0   0   2  95   1]
 [  0   0   0   1   1   3   0   0   0   0   2   0   0   0   0   0   1   0   0 131]]

2025-04-28 02:08:00,919 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:08:00,919 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:08:00,926 - 

2025-04-28 02:08:00,926 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:08:23,505 - Epoch: [194][   90/   90]    Overall Loss 0.014381    Objective Loss 0.014381    Top1 98.561151    Top5 100.000000    LR 0.000250    Time 0.250843    
2025-04-28 02:08:23,530 - --- validate (epoch=194)-----------
2025-04-28 02:08:23,530 - 2245 samples (100 per mini-batch)
2025-04-28 02:08:25,810 - Epoch: [194][   23/   23]    Loss 0.320291    Top1 94.298441    Top5 99.064588    
2025-04-28 02:08:25,836 - ==> Top1: 94.298    Top5: 99.065    Loss: 0.320

2025-04-28 02:08:25,836 - ==> Confusion:
[[ 97   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   3]
 [  0 112   1   0   0   0   1   1   0   0   1   0   0   0   0   1   3   0   0   0]
 [  0   0  97   0   1   1   2   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   1   0   0   0   0   0   0   3   0   2   0   0   0   0   3   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   2   1]
 [  0   0   0   0   1  78   0   0   0   0   0   0   0   0   0   1   1   0   0   7]
 [  0   0   0   0   1   0 121   0   1   0   2   0   0   0   0   0   0   0   0   3]
 [  0   0   1   0   0   0   0  97   0   0   3   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   4   0   0   0   0   0  77   0   1   0   0   0   0   2   0   0   0]
 [  0   2   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  74   0   1   0   0   1   2   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 110   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   1   0   0   0   0   0   0  90   0   0   2   0]
 [  0   2   0   0   0   1   0   0   0   0   0   0   0   0   0   0  57   1   2   0]
 [  0   1   0   1   0   2   0   0   0   0   2   0   0   0   0   1   0  88   2   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   1   0   0   0   2  95   1]
 [  0   0   1   0   2   3   1   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 02:08:25,838 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:08:25,838 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:08:25,846 - 

2025-04-28 02:08:25,846 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:08:48,458 - Epoch: [195][   90/   90]    Overall Loss 0.010344    Objective Loss 0.010344    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.251219    
2025-04-28 02:08:48,486 - --- validate (epoch=195)-----------
2025-04-28 02:08:48,486 - 2245 samples (100 per mini-batch)
2025-04-28 02:08:50,811 - Epoch: [195][   23/   23]    Loss 0.305279    Top1 94.432071    Top5 98.975501    
2025-04-28 02:08:50,838 - ==> Top1: 94.432    Top5: 98.976    Loss: 0.305

2025-04-28 02:08:50,838 - ==> Confusion:
[[ 96   0   0   1   0   0   0   0   1   0   0   0   0   0   0   0   1   0   1   2]
 [  0 114   0   0   0   0   0   1   0   1   0   0   0   0   0   1   2   0   0   1]
 [  0   0  97   0   1   1   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 139   0   0   1   0   0   0   0   2   0   4   0   1   0   0   2   0]
 [  0   0   0   0 193   1   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   0  78   0   0   0   0   0   0   0   0   0   1   1   1   0   7]
 [  0   0   0   0   1   0 120   0   1   0   2   0   0   0   1   1   0   0   0   2]
 [  0   0   0   1   0   1   0  99   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   0   0   0  77   0   1   0   0   0   0   3   0   0   0]
 [  0   2   0   0   0   0   0   0   0   0 109   0   0   0   0   0   1   1   1   0]
 [  0   1   0   1   0   0   0   0   0   0   0  73   0   3   0   1   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   0   0   0   0 113   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   0   1   0   0   1   1   0   0   0   0   0   0  94   0   0   0   0]
 [  0   3   0   0   0   1   0   0   0   0   0   0   0   0   0   0  56   1   2   0]
 [  0   2   0   1   0   1   0   0   0   0   2   0   0   0   0   1   0  89   1   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   2   0   0   0   4  92   1]
 [  0   0   0   0   2   4   1   0   0   0   3   0   0   0   0   0   0   0   1 128]]

2025-04-28 02:08:50,841 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:08:50,841 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:08:50,849 - 

2025-04-28 02:08:50,849 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:09:13,748 - Epoch: [196][   90/   90]    Overall Loss 0.011164    Objective Loss 0.011164    Top1 98.561151    Top5 100.000000    LR 0.000250    Time 0.254403    
2025-04-28 02:09:13,774 - --- validate (epoch=196)-----------
2025-04-28 02:09:13,774 - 2245 samples (100 per mini-batch)
2025-04-28 02:09:16,040 - Epoch: [196][   23/   23]    Loss 0.317475    Top1 94.432071    Top5 98.841871    
2025-04-28 02:09:16,063 - ==> Top1: 94.432    Top5: 98.842    Loss: 0.317

2025-04-28 02:09:16,064 - ==> Confusion:
[[ 93   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   2   0   5]
 [  0 112   1   0   0   0   1   1   0   1   1   0   0   0   0   1   2   0   0   0]
 [  0   0  97   0   1   0   2   0   1   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 142   0   0   0   0   0   0   0   1   0   3   0   1   0   0   2   0]
 [  0   0   0   0 192   1   0   0   0   0   1   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   0  77   0   0   0   0   0   1   0   0   0   1   0   0   0   9]
 [  0   0   0   0   1   0 122   0   1   0   1   1   0   0   0   0   0   0   0   2]
 [  0   0   0   1   0   0   0  99   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   6   0   0   0   0   0  78   0   1   0   0   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   1 110   1   0   0   0   0   1   0   0   0]
 [  0   1   0   1   0   0   0   0   0   0   1  74   0   2   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  82   0   0   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   1   0   0   1   1   0   0   0   0   0   0  92   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   1   0   1   0   1   0   0  56   1   1   0]
 [  0   1   0   1   0   2   0   0   0   0   3   0   0   0   0   1   0  88   1   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   2   0   0   0   3  93   1]
 [  0   0   1   1   1   2   1   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 02:09:16,066 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:09:16,066 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:09:16,074 - 

2025-04-28 02:09:16,074 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:09:38,820 - Epoch: [197][   90/   90]    Overall Loss 0.009376    Objective Loss 0.009376    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.252703    
2025-04-28 02:09:38,848 - --- validate (epoch=197)-----------
2025-04-28 02:09:38,848 - 2245 samples (100 per mini-batch)
2025-04-28 02:09:41,192 - Epoch: [197][   23/   23]    Loss 0.314030    Top1 94.298441    Top5 98.930958    
2025-04-28 02:09:41,214 - ==> Top1: 94.298    Top5: 98.931    Loss: 0.314

2025-04-28 02:09:41,214 - ==> Confusion:
[[ 96   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   1   3]
 [  0 111   0   0   0   0   1   1   0   0   2   1   0   0   0   1   2   0   0   1]
 [  0   0  97   0   1   0   2   0   2   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 140   0   0   1   0   0   0   0   1   0   2   1   0   0   0   4   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   2  74   0   0   0   0   0   0   0   0   0   1   1   1   0   9]
 [  0   0   0   0   1   0 122   0   1   0   1   0   0   0   0   0   0   0   0   3]
 [  0   0   0   0   0   0   0  99   0   1   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   1   0   0   0   0   0  78   1   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   1   0   0   0   0   0   0   0  75   0   1   0   0   2   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  80   0   2   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   2   0   0   0 111   0   0   0   0   1   1]
 [  0   0   0   0   0   0   1   0   0   0   0   0   3   0  54   0   0   0   1   0]
 [  0   1   0   1   2   0   0   1   1   0   0   0   0   0   0  91   0   0   1   0]
 [  0   1   0   0   1   1   0   0   0   1   0   1   0   0   0   0  56   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   1   0  90   2   1]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   1   0   0   0   3  94   1]
 [  0   0   0   0   2   3   0   0   0   0   3   0   0   0   0   0   1   0   0 130]]

2025-04-28 02:09:41,216 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:09:41,217 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:09:41,224 - 

2025-04-28 02:09:41,224 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:10:04,213 - Epoch: [198][   90/   90]    Overall Loss 0.006694    Objective Loss 0.006694    Top1 100.000000    Top5 100.000000    LR 0.000250    Time 0.255407    
2025-04-28 02:10:04,239 - --- validate (epoch=198)-----------
2025-04-28 02:10:04,239 - 2245 samples (100 per mini-batch)
2025-04-28 02:10:06,549 - Epoch: [198][   23/   23]    Loss 0.306617    Top1 94.476615    Top5 99.064588    
2025-04-28 02:10:06,572 - ==> Top1: 94.477    Top5: 99.065    Loss: 0.307

2025-04-28 02:10:06,573 - ==> Confusion:
[[ 94   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   1   0   5]
 [  0 113   1   0   0   0   1   1   0   0   1   0   0   0   0   1   2   0   0   0]
 [  0   0  98   0   1   0   2   0   1   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 138   1   0   1   0   0   0   0   3   0   2   0   0   0   0   4   0]
 [  0   0   0   0 192   1   0   0   0   0   0   0   1   0   1   0   1   0   1   1]
 [  0   0   0   0   1  77   0   0   0   0   0   0   0   0   0   1   0   1   0   8]
 [  0   0   0   0   1   0 124   0   0   0   1   0   0   0   0   0   0   0   0   2]
 [  0   0   1   0   0   0   0  99   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   2   0   1   0   1   0  76   1   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   0   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   2   0   0   0 111   0   0   0   0   1   1]
 [  0   0   0   0   0   0   1   0   0   0   0   0   3   0  55   0   0   0   0   0]
 [  0   1   0   0   2   0   0   1   1   0   0   0   0   0   0  92   0   0   1   0]
 [  0   2   0   0   0   1   0   0   0   0   0   0   0   0   0   0  57   1   2   0]
 [  0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   1   0  91   2   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   1   0   0   0   3  94   1]
 [  0   0   0   0   1   5   1   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 02:10:06,575 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:10:06,575 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:10:06,583 - 

2025-04-28 02:10:06,583 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:10:30,240 - Epoch: [199][   90/   90]    Overall Loss 0.009032    Objective Loss 0.009032    Top1 99.280576    Top5 100.000000    LR 0.000250    Time 0.262830    
2025-04-28 02:10:30,268 - --- validate (epoch=199)-----------
2025-04-28 02:10:30,269 - 2245 samples (100 per mini-batch)
2025-04-28 02:10:32,652 - Epoch: [199][   23/   23]    Loss 0.316477    Top1 94.432071    Top5 98.975501    
2025-04-28 02:10:32,677 - ==> Top1: 94.432    Top5: 98.976    Loss: 0.316

2025-04-28 02:10:32,677 - ==> Confusion:
[[ 96   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   5]
 [  0 113   0   0   0   0   0   1   0   0   0   0   0   0   0   1   4   0   0   1]
 [  0   0  96   0   1   1   3   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 139   0   0   0   1   0   0   0   3   0   3   0   0   0   0   3   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   1   0   1   1]
 [  0   0   1   0   3  75   0   0   0   0   0   1   0   0   0   1   1   1   0   5]
 [  0   0   0   0   1   0 124   0   0   0   1   0   0   0   1   0   0   0   0   1]
 [  0   0   1   0   0   0   0  99   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   3   0   0   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   2   0   0   0   0   0   0   0   0 109   0   0   0   0   0   1   0   2   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   0   1   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   1   0   1   0   0   0   0   0   2   0   0   0 111   0   0   0   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   1   0   0   0   0   0   0  92   0   0   0   0]
 [  0   2   0   0   0   1   0   0   0   0   0   0   0   0   0   0  57   1   2   0]
 [  0   1   0   1   0   1   0   0   0   0   2   0   0   0   0   1   0  89   2   0]
 [  0   1   0   0   3   1   0   0   0   1   0   0   0   1   0   0   1   2  93   1]
 [  0   0   0   0   1   3   2   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 02:10:32,680 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:10:32,680 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:10:32,687 - 

2025-04-28 02:10:32,687 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:10:55,904 - Epoch: [200][   90/   90]    Overall Loss 0.009124    Objective Loss 0.009124    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.257937    
2025-04-28 02:10:55,932 - --- validate (epoch=200)-----------
2025-04-28 02:10:55,932 - 2245 samples (100 per mini-batch)
2025-04-28 02:10:58,349 - Epoch: [200][   23/   23]    Loss 0.299787    Top1 94.387528    Top5 98.975501    
2025-04-28 02:10:58,373 - ==> Top1: 94.388    Top5: 98.976    Loss: 0.300

2025-04-28 02:10:58,374 - ==> Confusion:
[[ 95   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   5]
 [  0 113   1   0   0   0   0   1   0   0   0   0   0   0   0   1   4   0   0   0]
 [  0   0  97   0   1   0   2   0   2   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 140   0   0   0   1   0   0   0   2   0   2   0   0   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   1   0   1   1]
 [  0   0   0   0   0  76   0   0   0   0   0   0   0   0   1   1   1   1   0   8]
 [  0   0   0   0   1   0 122   0   1   0   1   0   0   0   1   0   0   0   0   2]
 [  0   0   1   0   0   0   0  99   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   4   0   0   0   0   0  77   1   1   0   0   0   0   2   0   0   0]
 [  0   2   0   0   0   0   0   0   0   0 109   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   1   0   1   0   0   0   1   0   0   0 111   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   1   0   0   1   1   0   0   0   0   0   0  92   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   1   0   0   0   0   0   0  58   1   1   0]
 [  0   1   0   2   0   1   0   0   0   0   2   0   0   0   0   1   0  88   2   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   0   2   0   0   1   2  94   1]
 [  0   0   0   0   1   4   2   0   0   0   3   0   0   0   0   0   1   0   0 128]]

2025-04-28 02:10:58,376 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:10:58,376 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:10:58,393 - 

2025-04-28 02:10:58,393 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:11:21,944 - Epoch: [201][   90/   90]    Overall Loss 0.006974    Objective Loss 0.006974    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.261646    
2025-04-28 02:11:21,970 - --- validate (epoch=201)-----------
2025-04-28 02:11:21,970 - 2245 samples (100 per mini-batch)
2025-04-28 02:11:24,476 - Epoch: [201][   23/   23]    Loss 0.301246    Top1 94.521158    Top5 98.886414    
2025-04-28 02:11:24,499 - ==> Top1: 94.521    Top5: 98.886    Loss: 0.301

2025-04-28 02:11:24,499 - ==> Confusion:
[[ 97   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   3]
 [  0 115   0   0   0   0   0   1   0   0   0   0   0   0   0   1   2   0   0   1]
 [  0   0  97   0   2   0   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 138   0   0   0   0   0   0   0   3   0   3   0   1   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   1   0   1   1]
 [  0   0   0   0   1  78   0   0   0   0   0   0   0   0   0   1   1   0   0   7]
 [  0   0   0   0   1   0 122   0   1   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   1   0   0   0   0  99   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   2   0   0   0   0   0  79   1   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 111   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   2   1   0   0   0   0   0   0  90   0   0   1   0]
 [  0   2   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   1   0   1   0   1   0   0   0   0   2   0   0   0   0   1   0  88   3   0]
 [  0   0   0   0   3   1   0   0   0   1   0   0   0   2   0   0   0   3  93   1]
 [  0   0   0   0   1   4   2   0   0   0   3   0   0   0   0   0   1   0   0 128]]

2025-04-28 02:11:24,502 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:11:24,502 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:11:24,511 - 

2025-04-28 02:11:24,511 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:11:48,360 - Epoch: [202][   90/   90]    Overall Loss 0.005223    Objective Loss 0.005223    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.264959    
2025-04-28 02:11:48,395 - --- validate (epoch=202)-----------
2025-04-28 02:11:48,395 - 2245 samples (100 per mini-batch)
2025-04-28 02:11:50,727 - Epoch: [202][   23/   23]    Loss 0.297951    Top1 94.476615    Top5 98.930958    
2025-04-28 02:11:50,753 - ==> Top1: 94.477    Top5: 98.931    Loss: 0.298

2025-04-28 02:11:50,754 - ==> Confusion:
[[ 96   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   4]
 [  0 114   0   0   0   0   0   1   0   0   1   0   0   0   0   1   2   0   0   1]
 [  0   0  98   0   1   0   2   0   1   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 139   0   0   0   0   0   0   0   3   0   2   0   1   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   1   0   1   1]
 [  0   0   0   0   0  77   0   0   0   0   0   0   0   0   0   1   1   1   0   8]
 [  0   0   0   0   0   0 123   0   1   0   1   0   0   0   1   0   0   0   0   2]
 [  0   0   1   0   0   0   0 100   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   2   0   1   0   0   0  77   1   1   0   0   0   0   2   0   0   0]
 [  0   2   0   0   0   0   0   0   0   0 108   0   0   0   0   0   1   2   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 111   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   1   0   0   0   0   0   0  91   0   0   1   0]
 [  0   2   0   0   1   1   0   0   0   0   0   0   0   0   0   0  57   1   1   0]
 [  0   1   0   0   0   1   0   0   0   0   2   0   0   0   0   1   0  90   2   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   2   0   0   1   3  92   1]
 [  0   0   0   0   1   5   1   0   0   0   3   0   0   0   0   0   1   0   0 128]]

2025-04-28 02:11:50,756 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:11:50,756 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:11:50,763 - 

2025-04-28 02:11:50,763 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:12:14,441 - Epoch: [203][   90/   90]    Overall Loss 0.005440    Objective Loss 0.005440    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.263059    
2025-04-28 02:12:14,476 - --- validate (epoch=203)-----------
2025-04-28 02:12:14,477 - 2245 samples (100 per mini-batch)
2025-04-28 02:12:16,836 - Epoch: [203][   23/   23]    Loss 0.288567    Top1 94.610245    Top5 98.975501    
2025-04-28 02:12:16,862 - ==> Top1: 94.610    Top5: 98.976    Loss: 0.289

2025-04-28 02:12:16,863 - ==> Confusion:
[[ 96   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   4]
 [  0 114   0   0   0   0   0   1   0   0   1   0   0   0   0   1   2   0   0   1]
 [  0   0  98   0   1   1   1   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   0   0   0   0   0   3   0   2   0   0   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   1   0   1   1]
 [  0   0   0   0   0  77   0   0   0   0   0   0   0   0   0   1   1   0   0   9]
 [  0   0   0   0   0   0 123   0   1   0   2   0   0   0   0   0   0   0   0   2]
 [  0   0   1   0   0   1   0  98   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   3   0   1   0   0   0  77   1   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 111   0   0   0   0   1   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   1   0   0   0   0   0   0  91   0   0   1   0]
 [  0   2   0   0   0   1   0   0   0   0   0   0   0   0   0   0  58   1   1   0]
 [  0   1   0   0   0   1   0   0   0   0   2   0   0   0   0   1   0  90   2   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   2   0   0   1   3  92   1]
 [  0   0   0   0   1   4   0   0   0   0   3   0   0   0   0   0   1   0   0 130]]

2025-04-28 02:12:16,865 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:12:16,865 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:12:16,874 - 

2025-04-28 02:12:16,874 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:12:40,724 - Epoch: [204][   90/   90]    Overall Loss 0.004942    Objective Loss 0.004942    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.264970    
2025-04-28 02:12:40,753 - --- validate (epoch=204)-----------
2025-04-28 02:12:40,753 - 2245 samples (100 per mini-batch)
2025-04-28 02:12:43,184 - Epoch: [204][   23/   23]    Loss 0.298965    Top1 94.387528    Top5 99.020045    
2025-04-28 02:12:43,206 - ==> Top1: 94.388    Top5: 99.020    Loss: 0.299

2025-04-28 02:12:43,206 - ==> Confusion:
[[ 95   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   5]
 [  0 113   1   0   0   0   0   1   0   1   1   0   0   0   0   1   2   0   0   0]
 [  0   0  97   0   1   0   2   0   2   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 138   0   0   0   0   0   0   0   3   0   3   0   1   0   0   4   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   1  76   0   0   0   0   0   0   0   0   0   1   1   0   0   9]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   1   0   0   0   0  99   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   2   0   1   0   0   0  79   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 111   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   1   0   0   0   0   0   0  91   0   0   1   0]
 [  0   2   0   0   0   1   0   0   0   0   0   0   0   0   0   0  57   1   2   0]
 [  0   1   0   1   0   1   0   0   0   0   2   0   0   0   0   1   0  89   2   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   2   0   0   1   3  93   1]
 [  0   0   0   0   1   4   2   0   0   0   3   0   0   0   0   0   1   0   0 128]]

2025-04-28 02:12:43,209 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:12:43,209 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:12:43,216 - 

2025-04-28 02:12:43,216 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:13:07,278 - Epoch: [205][   90/   90]    Overall Loss 0.006182    Objective Loss 0.006182    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.267323    
2025-04-28 02:13:07,307 - --- validate (epoch=205)-----------
2025-04-28 02:13:07,308 - 2245 samples (100 per mini-batch)
2025-04-28 02:13:09,621 - Epoch: [205][   23/   23]    Loss 0.295111    Top1 94.253898    Top5 99.109131    
2025-04-28 02:13:09,644 - ==> Top1: 94.254    Top5: 99.109    Loss: 0.295

2025-04-28 02:13:09,645 - ==> Confusion:
[[ 96   0   0   0   0   1   0   0   1   0   0   0   0   0   0   0   0   1   0   3]
 [  0 113   1   0   0   0   0   1   0   0   1   0   0   0   0   1   3   0   0   0]
 [  0   0  97   0   1   0   2   0   2   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 138   0   0   1   0   0   0   0   3   0   2   0   1   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   1   0   1   1]
 [  0   0   0   0   1  74   0   0   0   0   0   0   0   0   0   1   1   1   0  10]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   1   0   0   0   0  98   0   0   2   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   3   0   1   0   0   0  77   1   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 111   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   1   0   0   0   0   0   0  91   0   0   1   0]
 [  0   2   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   1   0   1   0   0   0   0   0   0   2   0   0   0   0   1   0  90   2   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   2   0   0   1   2  94   1]
 [  0   0   0   0   1   3   2   0   0   0   3   0   0   0   0   1   1   0   0 128]]

2025-04-28 02:13:09,647 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:13:09,647 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:13:09,655 - 

2025-04-28 02:13:09,655 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:13:33,815 - Epoch: [206][   90/   90]    Overall Loss 0.005518    Objective Loss 0.005518    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.268413    
2025-04-28 02:13:33,847 - --- validate (epoch=206)-----------
2025-04-28 02:13:33,847 - 2245 samples (100 per mini-batch)
2025-04-28 02:13:36,260 - Epoch: [206][   23/   23]    Loss 0.302645    Top1 94.565702    Top5 99.109131    
2025-04-28 02:13:36,282 - ==> Top1: 94.566    Top5: 99.109    Loss: 0.303

2025-04-28 02:13:36,282 - ==> Confusion:
[[ 96   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   1   3]
 [  0 115   0   0   0   0   0   1   0   0   0   0   0   0   0   1   2   0   0   1]
 [  0   0  97   0   1   0   2   0   2   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 140   0   0   1   0   0   0   0   3   0   2   0   0   0   0   3   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   1  75   0   0   0   0   0   0   0   0   0   1   1   1   0   9]
 [  0   0   0   0   0   0 123   0   1   0   2   0   0   0   0   0   0   0   0   2]
 [  0   0   1   0   0   0   0  99   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   4   0   1   0   0   0  77   1   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 111   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   1   0]
 [  0   1   0   1   1   0   0   1   1   0   0   0   0   0   0  91   0   0   2   0]
 [  0   2   0   0   0   1   0   0   0   0   0   0   0   0   0   0  57   1   2   0]
 [  0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   0   1  90   2   0]
 [  0   0   1   0   1   1   0   0   0   1   0   0   0   2   0   0   1   3  93   1]
 [  0   0   0   0   1   3   1   0   0   0   3   0   0   0   0   1   1   0   0 129]]

2025-04-28 02:13:36,284 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:13:36,284 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:13:36,292 - 

2025-04-28 02:13:36,292 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:14:00,265 - Epoch: [207][   90/   90]    Overall Loss 0.004567    Objective Loss 0.004567    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.266335    
2025-04-28 02:14:00,292 - --- validate (epoch=207)-----------
2025-04-28 02:14:00,292 - 2245 samples (100 per mini-batch)
2025-04-28 02:14:02,647 - Epoch: [207][   23/   23]    Loss 0.289196    Top1 94.743875    Top5 99.020045    
2025-04-28 02:14:02,671 - ==> Top1: 94.744    Top5: 99.020    Loss: 0.289

2025-04-28 02:14:02,671 - ==> Confusion:
[[ 95   0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   4]
 [  0 114   1   0   0   0   0   1   0   0   1   0   0   0   0   1   2   0   0   0]
 [  0   0  97   0   1   0   2   0   2   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 140   0   0   1   0   0   0   0   3   0   2   0   0   0   0   3   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   2  77   0   0   0   0   0   0   0   0   0   1   1   0   0   7]
 [  0   0   0   0   0   0 123   0   1   0   2   0   0   0   0   0   0   0   0   2]
 [  0   0   1   0   0   0   0 100   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   0   0   0  77   1   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 109   0   0   0   0   0   1   2   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  75   0   1   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 111   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   1   0   0   0   0   0   0  90   0   0   2   0]
 [  0   1   0   0   0   1   0   0   0   1   0   0   0   0   0   0  57   1   2   0]
 [  0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   0   0  92   2   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   1   2   0   0   0   3  95   1]
 [  0   0   0   0   1   4   2   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 02:14:02,674 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:14:02,674 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:14:02,681 - 

2025-04-28 02:14:02,682 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:14:26,550 - Epoch: [208][   90/   90]    Overall Loss 0.004488    Objective Loss 0.004488    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.265177    
2025-04-28 02:14:26,582 - --- validate (epoch=208)-----------
2025-04-28 02:14:26,582 - 2245 samples (100 per mini-batch)
2025-04-28 02:14:28,981 - Epoch: [208][   23/   23]    Loss 0.305694    Top1 94.699332    Top5 99.064588    
2025-04-28 02:14:29,006 - ==> Top1: 94.699    Top5: 99.065    Loss: 0.306

2025-04-28 02:14:29,007 - ==> Confusion:
[[ 97   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   3]
 [  0 115   1   0   0   0   0   1   0   0   0   0   0   0   0   1   2   0   0   0]
 [  0   0  97   0   1   0   2   0   2   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 138   0   0   1   1   0   0   0   3   0   3   0   0   0   0   3   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   2  77   0   0   0   0   0   0   0   0   0   1   1   1   0   6]
 [  0   0   0   0   0   0 123   0   1   0   1   0   0   0   1   0   0   0   0   2]
 [  0   0   1   0   0   0   0  99   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   1   0   2   0   1   0   0   0  77   1   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  76   0   0   0   1   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 111   0   0   0   0   1   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   2   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   1   0   0   0   0   0   0  91   0   0   1   0]
 [  0   2   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   1   0   0   0   1   0   0   0   0   2   0   0   0   0   0   0  91   2   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   2   0   0   0   4  93   1]
 [  0   0   0   0   1   4   2   0   0   0   3   0   0   0   0   0   1   0   0 128]]

2025-04-28 02:14:29,009 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:14:29,009 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:14:29,017 - 

2025-04-28 02:14:29,017 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:14:52,859 - Epoch: [209][   90/   90]    Overall Loss 0.005819    Objective Loss 0.005819    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.264882    
2025-04-28 02:14:52,890 - --- validate (epoch=209)-----------
2025-04-28 02:14:52,890 - 2245 samples (100 per mini-batch)
2025-04-28 02:14:55,372 - Epoch: [209][   23/   23]    Loss 0.305143    Top1 94.832962    Top5 98.930958    
2025-04-28 02:14:55,398 - ==> Top1: 94.833    Top5: 98.931    Loss: 0.305

2025-04-28 02:14:55,399 - ==> Confusion:
[[ 99   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   2]
 [  0 114   0   0   0   0   0   1   0   1   1   0   0   0   0   1   1   0   0   1]
 [  0   0  98   0   1   0   2   0   1   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 143   0   0   1   0   0   0   0   0   0   2   0   0   0   0   3   0]
 [  1   0   0   0 194   0   0   0   0   0   0   0   1   0   0   0   0   0   1   1]
 [  0   0   0   0   3  73   0   0   0   0   0   0   0   0   0   1   1   1   0   9]
 [  0   0   0   0   1   0 124   0   0   0   2   0   0   0   0   0   0   0   0   1]
 [  0   0   1   0   0   0   0  99   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   5   0   0   0   0   0  78   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1  74   0   1   0   0   1   2   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 111   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   2   1   0   0   0   0   0   0  90   0   0   1   0]
 [  0   2   0   0   1   1   0   0   0   0   0   0   0   0   0   0  57   1   1   0]
 [  0   1   0   0   0   1   0   0   0   0   2   0   0   0   0   1   0  90   2   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   2   0   0   0   3  93   1]
 [  0   0   0   0   1   3   2   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 02:14:55,401 - ==> Best [Top1: 95.011   Top5: 99.020   Params: 306880 on epoch: 160]
2025-04-28 02:14:55,401 - Saving checkpoint to: logs/2025.04.28-004559/checkpoint.pth.tar
2025-04-28 02:14:55,410 - Initiating quantization aware training (QAT)...
2025-04-28 02:14:55,415 - Collecting statistics for quantization aware training (QAT)...
2025-04-28 02:15:08,547 - 

2025-04-28 02:15:08,547 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:15:41,210 - Epoch: [210][   90/   90]    Overall Loss 1.647770    Objective Loss 1.647770    Top1 93.525180    Top5 100.000000    LR 0.000125    Time 0.362894    
2025-04-28 02:15:41,237 - --- validate (epoch=210)-----------
2025-04-28 02:15:41,237 - 2245 samples (100 per mini-batch)
2025-04-28 02:15:45,728 - Epoch: [210][   23/   23]    Loss 0.417219    Top1 87.884187    Top5 98.841871    
2025-04-28 02:15:45,753 - ==> Top1: 87.884    Top5: 98.842    Loss: 0.417

2025-04-28 02:15:45,753 - ==> Confusion:
[[ 94   0   0   2   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   5]
 [  1  99   0   2   1   0   0   2   0   1   1   4   0   0   0   1   3   0   4   1]
 [  0   0  89   0   4   1   1   0   4   0   1   0   0   0   0   0   0   0   3   0]
 [  0   0   0 140   0   1   0   0   0   0   0   2   0   3   0   0   0   0   3   0]
 [  0   1   0   2 184   4   0   0   0   0   0   1   3   0   1   0   0   0   2   0]
 [  0   2   0   1   2  68   0   0   0   0   0   2   1   0   0   1   0   3   0   8]
 [  0   0   2   1   1   0 113   0   1   0   2   0   0   0   1   0   0   1   0   6]
 [  0   0   1   1   0   1   0  97   0   0   1   0   0   0   0   0   0   0   1   0]
 [  2   0   0   0   0   2   0   0 209   0   0   0   0   0   0   0   0   0   3   0]
 [  1   1   1   3   0   0   0   1   1  70   0   4   0   0   0   0   4   0   0   0]
 [  1   1   0   0   0   0   0   0   1   0 100   1   0   0   0   0   4   1   3   2]
 [  1   0   0   1   0   1   0   0   0   1   0  73   0   1   0   0   2   1   0   0]
 [  1   0   0   0   2   0   0   2   0   0   0   0  74   0   3   0   1   0   0   0]
 [  0   0   0   4   0   0   0   0   0   0   0   2   0 103   0   1   1   1   2   1]
 [  2   0   0   0   1   0   0   0   0   0   0   0   2   0  49   0   0   0   4   1]
 [  0   3   0   5   3   0   0   4   1   0   0   2   0   0   0  79   0   0   1   0]
 [  0   0   0   1   1   1   0   0   0   1   2   3   0   0   0   0  52   1   1   0]
 [  3   1   0   1   0   0   0   0   1   1   0   0   0   0   0   0   4  84   2   0]
 [  0   2   1   0   2   4   0   0   1   1   0   1   0   1   0   0   6   3  80   2]
 [  3   0   1   2   1   7   2   0   0   0   2   1   0   0   2   0   0   0   2 116]]

2025-04-28 02:15:45,756 - ==> Best [Top1: 87.884   Top5: 98.842   Params: 306880 on epoch: 210]
2025-04-28 02:15:45,756 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:15:45,766 - 

2025-04-28 02:15:45,766 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:16:18,000 - Epoch: [211][   90/   90]    Overall Loss 0.186091    Objective Loss 0.186091    Top1 95.683453    Top5 100.000000    LR 0.000125    Time 0.358127    
2025-04-28 02:16:18,026 - --- validate (epoch=211)-----------
2025-04-28 02:16:18,026 - 2245 samples (100 per mini-batch)
2025-04-28 02:16:22,349 - Epoch: [211][   23/   23]    Loss 0.310522    Top1 91.893096    Top5 98.930958    
2025-04-28 02:16:22,371 - ==> Top1: 91.893    Top5: 98.931    Loss: 0.311

2025-04-28 02:16:22,372 - ==> Confusion:
[[ 96   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   6]
 [  0 107   0   2   0   0   0   2   0   1   0   1   0   1   0   1   1   0   2   2]
 [  0   0  92   0   2   1   4   0   2   0   0   0   0   0   0   0   0   0   1   1]
 [  0   0   0 141   0   1   1   0   0   0   0   2   0   2   0   0   0   0   2   0]
 [  0   0   0   2 181   5   0   1   0   0   0   0   0   0   3   0   1   1   2   2]
 [  0   0   0   1   0  76   0   0   0   1   0   0   0   0   0   1   0   2   0   7]
 [  0   0   0   0   0   0 118   0   1   0   2   0   0   0   0   0   0   1   0   6]
 [  0   0   0   1   0   1   0  95   0   1   1   0   0   1   0   1   0   0   1   0]
 [  1   0   0   0   0   0   1   0 213   0   0   0   0   0   0   0   0   0   0   1]
 [  1   1   1   2   0   1   0   0   1  74   0   1   0   2   0   0   2   0   0   0]
 [  1   1   0   0   0   0   0   0   0   1 105   0   0   0   0   0   2   1   0   3]
 [  1   0   0   0   0   0   0   0   0   0   0  74   0   1   0   0   3   2   0   0]
 [  2   0   0   0   0   0   0   1   0   0   0   0  75   0   3   0   0   0   0   2]
 [  0   0   0   1   0   0   0   0   0   0   0   0   0 112   0   0   1   0   0   1]
 [  1   0   0   0   0   0   0   0   0   0   0   0   2   0  55   0   0   0   0   1]
 [  0   1   0   3   1   0   0   1   1   0   0   1   0   1   0  88   0   0   1   0]
 [  0   0   0   1   1   1   0   0   0   1   1   1   0   0   0   0  53   3   1   0]
 [  2   0   0   1   0   0   0   0   0   0   1   0   0   0   0   0   1  90   2   0]
 [  0   0   0   1   1   2   0   0   1   1   0   1   1   2   0   0   3   3  86   2]
 [  1   0   0   0   1   4   0   0   0   0   1   0   0   0   0   0   0   0   0 132]]

2025-04-28 02:16:22,374 - ==> Best [Top1: 91.893   Top5: 98.931   Params: 306880 on epoch: 211]
2025-04-28 02:16:22,374 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:16:22,385 - 

2025-04-28 02:16:22,385 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:16:54,751 - Epoch: [212][   90/   90]    Overall Loss 0.109922    Objective Loss 0.109922    Top1 97.122302    Top5 100.000000    LR 0.000125    Time 0.359592    
2025-04-28 02:16:54,785 - --- validate (epoch=212)-----------
2025-04-28 02:16:54,785 - 2245 samples (100 per mini-batch)
2025-04-28 02:16:59,482 - Epoch: [212][   23/   23]    Loss 0.295075    Top1 92.828508    Top5 98.975501    
2025-04-28 02:16:59,506 - ==> Top1: 92.829    Top5: 98.976    Loss: 0.295

2025-04-28 02:16:59,507 - ==> Confusion:
[[ 93   0   0   0   0   2   1   0   0   0   1   0   0   0   0   0   0   0   0   5]
 [  0 110   1   1   0   0   0   2   0   2   0   0   0   0   0   1   1   0   1   1]
 [  0   0  99   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   1 139   0   0   1   0   0   0   1   1   0   2   0   0   0   0   4   0]
 [  0   0   0   0 190   1   0   0   0   0   0   0   2   0   1   1   0   0   2   1]
 [  0   0   0   1   0  76   0   0   0   1   0   0   0   0   0   1   0   2   0   7]
 [  0   0   2   0   0   0 119   0   1   0   1   0   0   0   1   1   0   0   0   3]
 [  0   0   1   0   0   1   0  98   0   0   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   1   1   0 214   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   1   2   0   0   0   0   1  77   0   0   0   2   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   1 107   0   0   0   0   0   1   1   0   3]
 [  0   2   0   1   0   4   0   0   0   1   0  67   0   2   0   1   1   2   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   3   0   0   0 110   0   0   0   0   1   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   4   0  55   0   0   0   0   0]
 [  0   1   0   1   3   0   0   1   1   0   0   0   0   0   0  90   0   0   1   0]
 [  0   0   0   1   2   1   0   0   0   1   1   0   0   0   0   0  51   3   3   0]
 [  1   1   1   0   0   0   0   0   0   1   2   0   0   0   0   0   1  85   5   0]
 [  0   0   0   0   1   1   0   0   0   1   1   0   1   1   0   0   1   2  95   0]
 [  1   0   2   0   1   4   0   0   0   0   2   0   0   0   0   0   0   0   1 128]]

2025-04-28 02:16:59,509 - ==> Best [Top1: 92.829   Top5: 98.976   Params: 306880 on epoch: 212]
2025-04-28 02:16:59,509 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:16:59,521 - 

2025-04-28 02:16:59,521 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:17:32,211 - Epoch: [213][   90/   90]    Overall Loss 0.092098    Objective Loss 0.092098    Top1 97.122302    Top5 100.000000    LR 0.000125    Time 0.363186    
2025-04-28 02:17:32,244 - --- validate (epoch=213)-----------
2025-04-28 02:17:32,244 - 2245 samples (100 per mini-batch)
2025-04-28 02:17:36,953 - Epoch: [213][   23/   23]    Loss 0.261772    Top1 93.585746    Top5 98.930958    
2025-04-28 02:17:36,977 - ==> Top1: 93.586    Top5: 98.931    Loss: 0.262

2025-04-28 02:17:36,977 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   3]
 [  0 112   0   1   0   0   0   1   0   0   0   0   0   0   0   2   2   0   1   1]
 [  0   0  98   0   2   1   0   0   1   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0 139   0   0   1   0   0   0   0   2   0   2   0   0   0   0   4   1]
 [  0   0   0   0 190   0   0   0   0   0   0   0   2   0   1   1   0   0   2   2]
 [  0   0   0   1   1  75   0   0   0   0   0   0   0   0   0   1   1   2   0   7]
 [  0   0   0   0   0   0 120   0   0   0   2   0   0   0   1   0   0   0   1   4]
 [  0   0   0   0   0   0   0  99   0   1   1   0   0   0   0   1   0   0   0   0]
 [  1   0   1   0   0   0   0   1 212   0   0   0   0   0   0   0   0   0   1   0]
 [  0   1   0   2   0   1   0   0   0  79   0   1   0   1   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   1 107   0   0   0   0   0   3   0   1   1]
 [  0   1   0   0   0   0   0   0   0   1   0  75   0   1   0   0   2   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   2   0   0   0 110   0   0   1   0   1   1]
 [  0   0   0   0   1   0   0   0   0   0   0   0   2   0  52   0   0   0   3   1]
 [  0   2   0   1   3   0   0   1   0   0   0   0   0   0   0  90   0   0   1   0]
 [  0   1   0   0   2   1   0   0   0   0   0   0   0   0   0   0  56   2   1   0]
 [  1   1   0   0   0   0   0   0   0   0   2   0   0   0   0   0   3  84   6   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   2   0   0   1   1  95   1]
 [  1   0   1   0   1   4   0   0   0   0   1   0   0   0   0   0   0   0   2 129]]

2025-04-28 02:17:36,979 - ==> Best [Top1: 93.586   Top5: 98.931   Params: 306880 on epoch: 213]
2025-04-28 02:17:36,979 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:17:36,989 - 

2025-04-28 02:17:36,989 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:18:09,655 - Epoch: [214][   90/   90]    Overall Loss 0.072569    Objective Loss 0.072569    Top1 97.841727    Top5 100.000000    LR 0.000125    Time 0.362919    
2025-04-28 02:18:09,683 - --- validate (epoch=214)-----------
2025-04-28 02:18:09,684 - 2245 samples (100 per mini-batch)
2025-04-28 02:18:14,116 - Epoch: [214][   23/   23]    Loss 0.267570    Top1 93.630290    Top5 99.109131    
2025-04-28 02:18:14,140 - ==> Top1: 93.630    Top5: 99.109    Loss: 0.268

2025-04-28 02:18:14,141 - ==> Confusion:
[[ 96   0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   4]
 [  0 110   1   0   0   0   0   2   0   0   0   1   0   1   0   1   2   0   1   1]
 [  0   0  96   0   2   1   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 139   0   0   1   0   0   0   0   3   0   3   0   0   0   0   2   1]
 [  0   0   0   0 191   0   0   0   0   0   0   0   1   0   1   1   0   0   1   3]
 [  0   0   0   1   1  75   0   0   0   0   0   0   0   0   0   1   0   1   0   9]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   0   0   0   0   0   3]
 [  0   0   0   0   0   0   0  97   0   1   2   0   0   0   0   1   0   0   0   1]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   1   0   1   0   0   1  78   0   2   0   1   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   1   0 107   0   0   0   0   0   1   2   0   2]
 [  0   1   0   0   0   0   0   0   0   0   0  76   0   2   0   0   1   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  78   0   2   0   0   0   0   2]
 [  0   0   0   0   0   0   0   0   0   2   1   1   0 109   0   0   0   0   0   2]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   1   5   0   0   1   1   0   0   0   0   0   0  89   0   0   0   0]
 [  0   1   0   0   1   1   0   0   0   0   0   3   1   0   0   0  52   3   1   0]
 [  2   1   0   1   0   0   0   0   0   0   2   0   0   0   0   0   0  87   4   0]
 [  0   0   1   0   1   1   0   0   0   1   0   0   0   2   0   0   1   3  94   0]
 [  0   0   1   0   1   1   0   0   0   0   2   0   0   0   0   0   0   0   0 134]]

2025-04-28 02:18:14,143 - ==> Best [Top1: 93.630   Top5: 99.109   Params: 306880 on epoch: 214]
2025-04-28 02:18:14,143 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:18:14,153 - 

2025-04-28 02:18:14,153 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:18:47,754 - Epoch: [215][   90/   90]    Overall Loss 0.060982    Objective Loss 0.060982    Top1 97.122302    Top5 100.000000    LR 0.000125    Time 0.373306    
2025-04-28 02:18:47,786 - --- validate (epoch=215)-----------
2025-04-28 02:18:47,786 - 2245 samples (100 per mini-batch)
2025-04-28 02:18:52,258 - Epoch: [215][   23/   23]    Loss 0.274682    Top1 93.407572    Top5 98.930958    
2025-04-28 02:18:52,281 - ==> Top1: 93.408    Top5: 98.931    Loss: 0.275

2025-04-28 02:18:52,282 - ==> Confusion:
[[ 96   0   0   0   0   2   1   0   0   0   0   0   0   0   0   0   0   0   0   3]
 [  0 107   0   2   0   0   0   2   0   0   0   0   1   1   0   2   2   0   1   2]
 [  0   0 100   0   2   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   1   0   0   0   0   0   0   0   2   0   0   0   0   5   0]
 [  0   0   1   0 189   0   0   0   0   0   0   0   1   0   2   1   0   0   2   2]
 [  0   0   0   1   0  77   0   0   0   0   0   0   1   0   0   1   0   0   0   8]
 [  0   0   1   0   0   1 121   0   1   0   1   0   0   0   1   0   0   0   0   2]
 [  0   0   1   0   0   0   0  96   0   0   1   0   0   0   1   1   0   0   1   1]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   1   0   0   0   0   0]
 [  0   0   0   2   0   2   0   0   0  79   1   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 109   0   0   0   0   0   1   0   2   1]
 [  0   1   0   1   0   3   1   0   0   1   0  70   0   2   0   0   1   0   1   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   2   1   0   0 111   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   4   0  55   0   0   0   0   0]
 [  0   1   0   1   3   0   0   1   1   0   0   0   0   0   0  89   0   0   2   0]
 [  0   1   0   0   1   1   0   0   0   1   0   0   2   0   0   0  55   1   1   0]
 [  1   0   1   1   0   1   0   0   0   0   1   0   0   0   1   0   1  84   6   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   2   1   0   0   0   1  96   1]
 [  0   0   1   0   1   8   0   0   0   0   2   0   0   0   0   0   0   0   0 127]]

2025-04-28 02:18:52,284 - ==> Best [Top1: 93.630   Top5: 99.109   Params: 306880 on epoch: 214]
2025-04-28 02:18:52,284 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:18:52,292 - 

2025-04-28 02:18:52,292 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:19:24,823 - Epoch: [216][   90/   90]    Overall Loss 0.054829    Objective Loss 0.054829    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.361430    
2025-04-28 02:19:24,852 - --- validate (epoch=216)-----------
2025-04-28 02:19:24,853 - 2245 samples (100 per mini-batch)
2025-04-28 02:19:29,742 - Epoch: [216][   23/   23]    Loss 0.263402    Top1 93.853007    Top5 99.064588    
2025-04-28 02:19:29,769 - ==> Top1: 93.853    Top5: 99.065    Loss: 0.263

2025-04-28 02:19:29,770 - ==> Confusion:
[[ 97   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   3]
 [  0 110   0   1   0   0   0   3   0   0   0   0   0   1   0   1   2   0   1   1]
 [  0   0  97   0   2   1   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 145   0   1   0   0   0   0   0   0   0   1   0   0   0   0   2   0]
 [  0   0   0   0 193   1   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   0  77   1   0   0   0   0   0   0   0   0   1   0   1   0   8]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   0   0   0   0   0   3]
 [  0   0   0   0   0   2   0  98   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   2   0   1   0   0   0  79   0   1   0   1   0   0   1   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 109   0   0   0   0   0   1   2   0   1]
 [  0   2   0   1   0   2   1   0   0   0   1  69   0   1   0   0   2   2   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   1   0   2   0   0   0 109   0   0   1   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   5   0   0   2   1   0   0   0   0   1   0  86   0   1   0   0]
 [  0   1   0   0   0   2   0   0   0   0   0   0   0   0   0   0  57   2   1   0]
 [  1   0   0   2   0   2   0   0   0   0   1   0   0   0   0   0   1  88   2   0]
 [  0   0   0   1   1   2   0   0   0   1   0   0   1   2   1   0   2   3  90   0]
 [  0   0   1   0   1   5   1   0   0   0   2   0   0   0   0   0   0   0   0 129]]

2025-04-28 02:19:29,772 - ==> Best [Top1: 93.853   Top5: 99.065   Params: 306880 on epoch: 216]
2025-04-28 02:19:29,773 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:19:29,785 - 

2025-04-28 02:19:29,785 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:20:02,267 - Epoch: [217][   90/   90]    Overall Loss 0.048664    Objective Loss 0.048664    Top1 97.841727    Top5 100.000000    LR 0.000125    Time 0.360882    
2025-04-28 02:20:02,298 - --- validate (epoch=217)-----------
2025-04-28 02:20:02,298 - 2245 samples (100 per mini-batch)
2025-04-28 02:20:07,058 - Epoch: [217][   23/   23]    Loss 0.249436    Top1 94.342984    Top5 98.975501    
2025-04-28 02:20:07,085 - ==> Top1: 94.343    Top5: 98.976    Loss: 0.249

2025-04-28 02:20:07,086 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   1   0   0   0   0   0   1   0   0   1]
 [  0 111   2   0   0   0   0   2   0   0   0   0   0   1   0   1   2   0   1   0]
 [  0   0  99   0   2   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   1   0   0   0   0   2   0   3   0   0   0   0   2   0]
 [  0   0   0   1 192   0   0   0   0   0   0   0   1   0   1   1   0   0   1   1]
 [  0   0   0   0   2  76   0   0   0   0   0   0   0   0   0   1   1   3   0   5]
 [  0   0   0   0   0   0 123   0   0   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   0   0  98   0   0   1   0   0   0   0   1   0   1   1   0]
 [  0   0   0   0   0   0   0   0 214   0   0   0   0   0   1   0   0   0   1   0]
 [  0   1   0   3   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   0  76   0   2   0   0   1   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  80   0   2   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   2   0   0   0 111   0   0   0   0   1   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   1   0   0   0   0   0   0  90   0   0   2   0]
 [  0   2   0   0   1   1   0   0   0   0   0   1   0   0   0   0  56   1   1   0]
 [  1   1   0   1   0   0   0   0   0   0   2   1   0   0   0   0   1  86   4   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   1   2  96   0]
 [  1   0   1   0   1   4   1   0   0   0   3   0   0   0   1   0   0   0   1 126]]

2025-04-28 02:20:07,088 - ==> Best [Top1: 94.343   Top5: 98.976   Params: 306880 on epoch: 217]
2025-04-28 02:20:07,088 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:20:07,099 - 

2025-04-28 02:20:07,099 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:20:38,912 - Epoch: [218][   90/   90]    Overall Loss 0.042985    Objective Loss 0.042985    Top1 98.561151    Top5 100.000000    LR 0.000125    Time 0.353450    
2025-04-28 02:20:38,947 - --- validate (epoch=218)-----------
2025-04-28 02:20:38,947 - 2245 samples (100 per mini-batch)
2025-04-28 02:20:43,284 - Epoch: [218][   23/   23]    Loss 0.252132    Top1 94.342984    Top5 99.153675    
2025-04-28 02:20:43,306 - ==> Top1: 94.343    Top5: 99.154    Loss: 0.252

2025-04-28 02:20:43,307 - ==> Confusion:
[[ 94   0   0   0   0   1   1   0   0   1   1   0   0   0   0   0   0   0   0   4]
 [  0 111   0   1   1   0   0   2   0   0   0   1   0   1   0   1   1   0   1   0]
 [  0   0  98   0   2   1   1   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 144   0   0   0   0   0   0   0   1   0   2   0   0   0   0   2   0]
 [  0   0   0   1 191   1   0   0   0   0   0   0   1   0   1   1   0   0   1   1]
 [  0   0   0   1   2  75   0   0   0   0   0   1   0   0   0   1   1   2   0   5]
 [  0   0   0   0   0   0 122   0   0   0   2   0   0   0   1   1   0   0   0   2]
 [  0   0   0   0   0   1   0  98   0   0   1   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   0   1   0   0 214   0   0   0   0   0   0   0   0   0   1   0]
 [  0   1   0   2   0   1   0   0   0  79   0   1   0   1   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  76   0   1   0   0   2   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   2   1   0   0 111   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   0   0   0   0   0   0   0  91   0   0   2   0]
 [  0   1   0   0   1   1   0   0   0   0   0   2   0   0   0   0  55   2   1   0]
 [  0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1  89   4   0]
 [  0   0   0   1   1   1   0   0   0   1   0   0   1   1   0   0   0   2  95   1]
 [  0   0   2   0   1   4   1   0   0   0   3   0   0   0   0   0   0   0   0 128]]

2025-04-28 02:20:43,309 - ==> Best [Top1: 94.343   Top5: 99.154   Params: 306880 on epoch: 218]
2025-04-28 02:20:43,309 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:20:43,319 - 

2025-04-28 02:20:43,319 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:21:15,849 - Epoch: [219][   90/   90]    Overall Loss 0.046143    Objective Loss 0.046143    Top1 98.561151    Top5 100.000000    LR 0.000125    Time 0.361412    
2025-04-28 02:21:15,879 - --- validate (epoch=219)-----------
2025-04-28 02:21:15,879 - 2245 samples (100 per mini-batch)
2025-04-28 02:21:20,361 - Epoch: [219][   23/   23]    Loss 0.246403    Top1 94.209354    Top5 99.064588    
2025-04-28 02:21:20,384 - ==> Top1: 94.209    Top5: 99.065    Loss: 0.246

2025-04-28 02:21:20,384 - ==> Confusion:
[[ 92   0   0   2   0   1   1   0   1   1   1   0   0   0   0   0   0   0   0   3]
 [  0 112   1   1   0   0   0   2   0   0   0   0   0   0   0   1   2   0   1   0]
 [  0   0  97   0   2   1   2   0   0   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0 145   0   0   0   0   0   0   0   1   0   1   0   0   0   0   2   0]
 [  0   0   0   1 191   0   0   0   0   0   0   0   1   0   1   1   0   1   1   1]
 [  0   0   0   2   1  75   0   0   0   0   0   0   0   0   0   1   1   2   0   6]
 [  0   0   0   1   0   0 121   0   0   0   1   0   0   0   0   0   0   0   0   5]
 [  0   0   0   0   0   0   0 100   0   0   1   0   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   0   1 214   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0   4   0   1   0   0   0  79   1   1   0   0   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  0   1   0   2   0   0   0   0   0   0   0  76   0   1   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   5   0   0   0   1   0   1   1   1   0 105   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  56   0   0   0   1   0]
 [  0   1   0   1   0   0   0   1   0   0   0   0   0   0   0  93   0   0   2   0]
 [  0   1   0   0   1   1   0   0   0   0   0   3   0   0   0   0  54   2   1   0]
 [  1   1   0   2   0   1   0   0   0   0   1   0   0   0   0   0   1  86   4   0]
 [  0   0   0   1   1   1   0   0   0   1   0   0   1   1   0   0   0   1  96   1]
 [  0   0   1   0   1   3   1   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:21:20,386 - ==> Best [Top1: 94.343   Top5: 99.154   Params: 306880 on epoch: 218]
2025-04-28 02:21:20,387 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:21:20,394 - 

2025-04-28 02:21:20,394 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:21:52,834 - Epoch: [220][   90/   90]    Overall Loss 0.042121    Objective Loss 0.042121    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.360414    
2025-04-28 02:21:52,861 - --- validate (epoch=220)-----------
2025-04-28 02:21:52,861 - 2245 samples (100 per mini-batch)
2025-04-28 02:21:57,398 - Epoch: [220][   23/   23]    Loss 0.244866    Top1 94.120267    Top5 98.797327    
2025-04-28 02:21:57,425 - ==> Top1: 94.120    Top5: 98.797    Loss: 0.245

2025-04-28 02:21:57,425 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   2]
 [  0 110   0   1   0   0   0   1   0   1   0   1   0   0   0   2   2   0   1   1]
 [  0   0  95   0   3   1   2   0   1   1   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 144   0   0   0   0   0   0   0   2   0   1   0   0   0   0   2   0]
 [  0   0   0   1 192   0   0   0   0   0   0   0   1   0   1   1   0   0   1   1]
 [  0   0   0   1   1  77   1   0   0   1   0   1   0   0   0   1   1   0   0   4]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   2   0   0   0  97   1   0   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   4   0   0   0   0   0  80   0   1   0   0   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 109   0   0   0   0   0   2   2   0   0]
 [  0   1   0   2   0   0   0   0   0   0   0  75   0   1   0   0   2   0   0   0]
 [  1   0   1   0   0   0   0   0   0   0   0   0  81   0   0   0   0   0   0   0]
 [  0   0   0   4   0   0   0   0   0   2   1   1   0 107   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   4   0  55   0   0   0   0   0]
 [  0   1   0   1   3   0   0   1   0   0   0   0   0   0   0  91   0   0   1   0]
 [  0   1   0   0   1   1   0   0   0   0   0   2   0   0   0   0  56   1   1   0]
 [  1   1   0   2   0   1   0   0   0   0   1   0   0   0   0   0   1  87   3   0]
 [  0   0   0   1   1   1   0   0   0   1   0   0   1   1   0   0   0   2  95   1]
 [  0   0   1   0   1   5   2   0   0   0   3   0   0   0   0   0   0   0   0 127]]

2025-04-28 02:21:57,428 - ==> Best [Top1: 94.343   Top5: 99.154   Params: 306880 on epoch: 218]
2025-04-28 02:21:57,428 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:21:57,436 - 

2025-04-28 02:21:57,437 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:22:29,828 - Epoch: [221][   90/   90]    Overall Loss 0.039320    Objective Loss 0.039320    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.359873    
2025-04-28 02:22:29,856 - --- validate (epoch=221)-----------
2025-04-28 02:22:29,856 - 2245 samples (100 per mini-batch)
2025-04-28 02:22:34,542 - Epoch: [221][   23/   23]    Loss 0.248654    Top1 94.342984    Top5 99.153675    
2025-04-28 02:22:34,567 - ==> Top1: 94.343    Top5: 99.154    Loss: 0.249

2025-04-28 02:22:34,568 - ==> Confusion:
[[ 97   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   1   0   0   3]
 [  0 112   1   0   1   0   0   1   0   0   0   0   0   0   0   1   3   0   1   0]
 [  0   0  98   0   2   1   1   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 143   0   0   0   0   0   0   0   3   0   1   0   0   0   0   2   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   1   0   0   1   1]
 [  0   0   0   1   3  75   0   0   0   0   0   0   0   0   0   1   1   2   0   5]
 [  0   0   1   0   0   0 120   0   1   0   0   0   1   0   1   1   0   0   0   3]
 [  0   0   0   1   0   0   0  97   0   0   1   0   0   0   0   3   0   0   0   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   1   0   0   0   0   0]
 [  1   1   0   2   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   1   0   0   0   0   0   0 107   0   0   0   0   0   2   2   1   0]
 [  0   1   0   0   0   0   0   0   0   0   0  77   0   1   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   2   0   0   0   0   0   1   0   0   0 110   0   0   0   0   1   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   0   3   0   0   1   0   0   0   0   0   0   0  93   0   0   0   0]
 [  0   1   0   0   1   1   0   0   0   0   0   2   0   0   0   0  56   1   1   0]
 [  0   1   0   2   0   1   0   0   0   0   0   0   0   0   0   0   1  87   5   0]
 [  0   0   0   1   1   1   0   0   0   1   0   0   2   1   0   0   0   3  94   0]
 [  0   0   1   0   1   4   1   0   0   0   2   0   0   0   0   0   0   0   0 130]]

2025-04-28 02:22:34,570 - ==> Best [Top1: 94.343   Top5: 99.154   Params: 306880 on epoch: 221]
2025-04-28 02:22:34,570 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:22:34,581 - 

2025-04-28 02:22:34,581 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:23:06,607 - Epoch: [222][   90/   90]    Overall Loss 0.041815    Objective Loss 0.041815    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.355810    
2025-04-28 02:23:06,636 - --- validate (epoch=222)-----------
2025-04-28 02:23:06,636 - 2245 samples (100 per mini-batch)
2025-04-28 02:23:11,153 - Epoch: [222][   23/   23]    Loss 0.245811    Top1 94.432071    Top5 99.109131    
2025-04-28 02:23:11,176 - ==> Top1: 94.432    Top5: 99.109    Loss: 0.246

2025-04-28 02:23:11,176 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   3]
 [  0 113   1   0   0   0   0   1   0   0   0   0   0   0   0   1   3   0   1   0]
 [  0   0  98   0   2   1   2   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 139   0   1   1   0   0   0   0   3   0   1   0   0   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   1   2]
 [  0   0   0   0   1  75   1   0   0   0   0   0   0   0   0   1   1   2   0   7]
 [  0   0   0   0   0   0 123   0   0   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   0   0  97   0   0   2   0   0   0   0   1   0   1   1   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   1   0   0   0   0   0]
 [  1   1   0   2   0   1   0   0   0  79   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 109   0   0   0   0   0   2   2   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  76   0   1   0   0   2   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   3   1   0   0 109   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   4   0   0   1   0   0   0   0   0   0   0  89   0   0   2   0]
 [  0   1   0   0   0   1   0   0   0   0   0   2   0   0   0   0  57   1   1   0]
 [  1   1   0   1   0   0   0   0   0   0   3   0   0   0   0   0   1  89   1   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   2   0   0   0   2  95   1]
 [  0   0   1   0   1   3   1   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 02:23:11,178 - ==> Best [Top1: 94.432   Top5: 99.109   Params: 306880 on epoch: 222]
2025-04-28 02:23:11,178 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:23:11,188 - 

2025-04-28 02:23:11,188 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:23:43,833 - Epoch: [223][   90/   90]    Overall Loss 0.034187    Objective Loss 0.034187    Top1 97.122302    Top5 100.000000    LR 0.000125    Time 0.362684    
2025-04-28 02:23:43,863 - --- validate (epoch=223)-----------
2025-04-28 02:23:43,864 - 2245 samples (100 per mini-batch)
2025-04-28 02:23:48,511 - Epoch: [223][   23/   23]    Loss 0.272300    Top1 93.853007    Top5 98.975501    
2025-04-28 02:23:48,531 - ==> Top1: 93.853    Top5: 98.976    Loss: 0.272

2025-04-28 02:23:48,532 - ==> Confusion:
[[ 96   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   1   3]
 [  0 111   0   0   1   0   0   1   1   0   0   0   0   1   0   2   2   0   1   0]
 [  0   0  95   0   1   1   3   0   3   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 142   0   0   0   0   0   0   0   1   0   2   0   1   0   0   3   0]
 [  0   0   0   1 192   2   0   0   0   0   0   0   1   0   0   1   0   0   1   0]
 [  0   0   1   0   2  77   0   0   0   1   1   0   0   0   0   1   1   2   1   1]
 [  0   0   0   0   0   0 120   0   1   0   2   0   0   0   1   1   0   1   0   2]
 [  0   0   0   0   0   0   0  99   0   0   1   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   2   0   2   0   0   0  79   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   1 109   0   0   0   0   0   2   1   0   0]
 [  0   1   0   1   0   0   0   0   0   1   0  74   0   1   0   0   2   1   0   0]
 [  0   0   0   0   1   0   0   0   0   1   0   0  80   0   0   0   0   1   0   0]
 [  0   0   0   2   0   0   0   0   0   2   1   0   0 109   0   0   1   0   0   0]
 [  0   0   0   0   3   0   0   0   0   0   0   0   2   0  52   0   0   0   2   0]
 [  0   1   0   1   0   0   0   1   0   0   0   0   0   0   0  94   0   0   1   0]
 [  0   1   0   0   0   2   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1  92   4   0]
 [  0   0   0   1   1   1   0   0   0   1   0   0   1   2   0   0   1   3  93   0]
 [  1   0   0   0   1   7   1   0   0   0   4   0   0   0   0   1   1   1   1 121]]

2025-04-28 02:23:48,534 - ==> Best [Top1: 94.432   Top5: 99.109   Params: 306880 on epoch: 222]
2025-04-28 02:23:48,534 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:23:48,541 - 

2025-04-28 02:23:48,541 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:24:21,014 - Epoch: [224][   90/   90]    Overall Loss 0.039712    Objective Loss 0.039712    Top1 97.841727    Top5 100.000000    LR 0.000125    Time 0.360782    
2025-04-28 02:24:21,041 - --- validate (epoch=224)-----------
2025-04-28 02:24:21,042 - 2245 samples (100 per mini-batch)
2025-04-28 02:24:25,548 - Epoch: [224][   23/   23]    Loss 0.272528    Top1 94.298441    Top5 98.886414    
2025-04-28 02:24:25,569 - ==> Top1: 94.298    Top5: 98.886    Loss: 0.273

2025-04-28 02:24:25,569 - ==> Confusion:
[[ 97   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   3]
 [  0 110   0   1   0   0   0   2   0   0   0   1   0   1   0   1   2   0   1   1]
 [  0   0  97   0   2   1   2   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   1   0   0   0   1   0   2   0   0   0   0   4   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   1   0   1   1   0   0   1   2]
 [  0   0   0   1   3  75   1   0   0   0   0   0   0   0   0   1   1   2   0   4]
 [  0   0   0   0   0   0 124   0   0   0   2   0   0   0   0   0   0   0   0   2]
 [  0   0   0   0   0   0   0  99   0   0   1   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   1   0   0   0   0   0]
 [  0   1   0   3   0   1   0   2   0  74   1   1   0   0   0   0   2   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   2   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   3   0   1   0   0   0   0   1   1   0 109   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   2   0   0   2   0   0   0   0   0   0   0  89   0   0   2   0]
 [  0   1   0   0   1   1   0   0   0   0   0   3   0   0   0   0  55   1   1   0]
 [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0  93   3   0]
 [  1   0   0   1   1   1   0   0   0   0   0   0   1   1   0   0   0   3  95   0]
 [  0   0   1   0   1   3   1   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:24:25,571 - ==> Best [Top1: 94.432   Top5: 99.109   Params: 306880 on epoch: 222]
2025-04-28 02:24:25,571 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:24:25,580 - 

2025-04-28 02:24:25,580 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:24:57,994 - Epoch: [225][   90/   90]    Overall Loss 0.033507    Objective Loss 0.033507    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.360130    
2025-04-28 02:24:58,022 - --- validate (epoch=225)-----------
2025-04-28 02:24:58,022 - 2245 samples (100 per mini-batch)
2025-04-28 02:25:02,713 - Epoch: [225][   23/   23]    Loss 0.269698    Top1 93.942094    Top5 99.020045    
2025-04-28 02:25:02,738 - ==> Top1: 93.942    Top5: 99.020    Loss: 0.270

2025-04-28 02:25:02,738 - ==> Confusion:
[[ 98   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 109   1   0   0   0   0   2   0   0   0   0   0   1   0   1   3   0   2   1]
 [  0   0  98   0   2   1   2   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 139   0   0   0   1   0   0   0   2   0   2   0   0   0   0   5   0]
 [  0   0   0   0 190   0   0   0   0   0   0   0   1   0   1   1   0   0   2   3]
 [  0   0   0   1   2  74   0   0   0   0   0   0   0   0   0   1   0   2   0   8]
 [  0   0   1   0   0   0 122   0   0   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   1   0  97   0   0   1   0   0   0   0   1   0   1   1   0]
 [  0   0   1   0   0   1   1   0 212   0   0   0   0   0   1   0   0   0   0   0]
 [  1   0   0   2   0   1   0   1   0  77   1   1   0   0   0   0   1   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  80   0   2   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   2   1   0   0 111   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   3   0   0   1   0   0   0   0   0   0   0  90   0   0   1   0]
 [  0   0   0   1   1   2   0   0   0   1   1   0   0   0   0   0  55   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   5   0   0   0   0   0   0  88   2   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   2   1   0   0   0   2  95   1]
 [  0   0   1   0   1   3   0   0   0   0   3   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:25:02,740 - ==> Best [Top1: 94.432   Top5: 99.109   Params: 306880 on epoch: 222]
2025-04-28 02:25:02,740 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:25:02,749 - 

2025-04-28 02:25:02,749 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:25:35,130 - Epoch: [226][   90/   90]    Overall Loss 0.024225    Objective Loss 0.024225    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.359760    
2025-04-28 02:25:35,159 - --- validate (epoch=226)-----------
2025-04-28 02:25:35,159 - 2245 samples (100 per mini-batch)
2025-04-28 02:25:39,857 - Epoch: [226][   23/   23]    Loss 0.267621    Top1 94.253898    Top5 98.886414    
2025-04-28 02:25:39,882 - ==> Top1: 94.254    Top5: 98.886    Loss: 0.268

2025-04-28 02:25:39,883 - ==> Confusion:
[[100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 109   0   2   1   0   0   3   0   0   0   2   0   1   0   0   1   0   1   0]
 [  0   0  96   0   3   1   2   0   0   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0 143   0   0   0   0   0   0   0   2   0   1   0   0   0   0   3   0]
 [  0   0   0   1 194   0   0   0   0   0   0   0   1   0   0   0   0   0   1   1]
 [  0   0   0   1   2  73   0   1   0   1   0   0   0   0   0   1   0   2   0   7]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   0   0 100   0   0   1   0   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   0   1 214   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   4   0   1   0   0   0  78   1   1   0   0   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  76   0   1   0   0   2   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   5   0   0   0   1   0   0   1   1   0 107   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   1   0]
 [  0   1   0   2   3   0   0   2   0   0   0   0   0   0   0  89   0   0   1   0]
 [  0   1   0   0   1   1   0   0   0   0   0   3   0   0   0   0  54   2   1   0]
 [  1   1   0   2   0   0   0   0   0   0   2   0   0   0   0   0   1  87   3   0]
 [  2   0   0   0   1   0   0   0   0   1   0   0   2   1   0   0   0   1  96   0]
 [  0   0   0   0   1   2   1   0   0   0   3   0   0   0   0   0   0   0   0 132]]

2025-04-28 02:25:39,885 - ==> Best [Top1: 94.432   Top5: 99.109   Params: 306880 on epoch: 222]
2025-04-28 02:25:39,885 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:25:39,894 - 

2025-04-28 02:25:39,894 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:26:12,143 - Epoch: [227][   90/   90]    Overall Loss 0.029822    Objective Loss 0.029822    Top1 98.561151    Top5 100.000000    LR 0.000125    Time 0.358288    
2025-04-28 02:26:12,169 - --- validate (epoch=227)-----------
2025-04-28 02:26:12,169 - 2245 samples (100 per mini-batch)
2025-04-28 02:26:16,675 - Epoch: [227][   23/   23]    Loss 0.269772    Top1 94.565702    Top5 98.886414    
2025-04-28 02:26:16,695 - ==> Top1: 94.566    Top5: 98.886    Loss: 0.270

2025-04-28 02:26:16,696 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   3]
 [  0 113   0   1   0   0   0   2   0   0   0   0   0   0   0   0   2   0   1   1]
 [  0   0  97   0   3   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 143   0   0   0   0   0   0   0   2   0   1   0   0   0   0   3   0]
 [  1   0   0   0 194   0   0   0   0   0   0   0   1   0   0   0   0   0   1   1]
 [  0   0   0   1   1  77   2   0   0   0   0   0   0   0   0   1   1   2   0   3]
 [  0   0   0   0   0   0 125   0   0   0   1   0   0   0   0   0   0   0   0   2]
 [  0   0   0   0   0   1   0  99   0   0   1   0   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   1   2   0   1   0   0   1  76   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  76   0   1   0   0   2   1   0   0]
 [  0   0   1   0   1   0   0   0   0   0   0   0  80   0   0   0   0   1   0   0]
 [  0   0   0   6   1   0   0   0   0   0   1   1   0 106   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   2   0  55   0   0   0   1   0]
 [  0   1   0   1   5   0   0   2   1   0   0   0   0   0   0  88   0   0   0   0]
 [  0   1   0   0   1   1   0   0   0   0   0   2   0   0   0   0  55   2   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0  92   2   0]
 [  1   0   0   0   1   1   0   0   0   0   0   0   1   1   0   0   0   3  95   1]
 [  0   0   1   0   1   3   2   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 02:26:16,698 - ==> Best [Top1: 94.566   Top5: 98.886   Params: 306880 on epoch: 227]
2025-04-28 02:26:16,698 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:26:16,708 - 

2025-04-28 02:26:16,708 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:26:49,286 - Epoch: [228][   90/   90]    Overall Loss 0.035649    Objective Loss 0.035649    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.361945    
2025-04-28 02:26:49,319 - --- validate (epoch=228)-----------
2025-04-28 02:26:49,319 - 2245 samples (100 per mini-batch)
2025-04-28 02:26:53,814 - Epoch: [228][   23/   23]    Loss 0.281675    Top1 93.897550    Top5 99.064588    
2025-04-28 02:26:53,837 - ==> Top1: 93.898    Top5: 99.065    Loss: 0.282

2025-04-28 02:26:53,838 - ==> Confusion:
[[ 98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   3]
 [  0 112   1   0   1   0   0   1   0   0   0   1   0   1   0   1   1   0   1   0]
 [  0   0  99   0   2   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 137   1   0   0   0   0   0   0   2   0   5   0   0   1   0   3   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   1  78   0   0   0   0   0   0   0   0   0   1   1   2   0   5]
 [  1   0   2   0   0   0 120   0   0   0   1   0   0   0   1   0   0   0   0   3]
 [  0   0   0   0   0   1   0  97   0   1   1   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   1   0 213   0   0   0   0   0   1   0   0   0   1   0]
 [  1   1   0   2   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   1   0   0   0   1 107   0   0   0   0   0   2   2   0   0]
 [  1   3   0   0   0   1   0   0   0   0   0  72   0   2   0   0   1   0   1   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0  80   0   1   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   3   1   0   0 110   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   2   0   1   3   0   0   1   0   0   0   0   0   0   0  90   0   0   1   0]
 [  0   1   0   0   1   2   0   0   0   0   0   2   0   0   0   0  54   1   2   0]
 [  1   2   0   0   0   1   0   0   0   1   3   0   0   0   0   0   1  86   2   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   0   1   0   0   0   2  96   1]
 [  0   0   1   0   1   4   0   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:26:53,840 - ==> Best [Top1: 94.566   Top5: 98.886   Params: 306880 on epoch: 227]
2025-04-28 02:26:53,840 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:26:53,848 - 

2025-04-28 02:26:53,848 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:27:26,262 - Epoch: [229][   90/   90]    Overall Loss 0.032102    Objective Loss 0.032102    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.360124    
2025-04-28 02:27:26,294 - --- validate (epoch=229)-----------
2025-04-28 02:27:26,294 - 2245 samples (100 per mini-batch)
2025-04-28 02:27:30,875 - Epoch: [229][   23/   23]    Loss 0.257166    Top1 94.476615    Top5 99.153675    
2025-04-28 02:27:30,898 - ==> Top1: 94.477    Top5: 99.154    Loss: 0.257

2025-04-28 02:27:30,899 - ==> Confusion:
[[ 99   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 111   1   0   0   0   0   3   0   0   0   1   0   0   0   0   2   0   1   1]
 [  0   0  96   0   1   1   3   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   0   0   0   0   3   0   2   0   0   0   0   3   0]
 [  0   0   0   0 191   0   0   0   0   0   0   0   1   0   2   1   0   0   1   2]
 [  0   0   0   1   0  77   1   1   0   0   1   0   0   0   0   1   1   1   0   4]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   1   0   0   0  99   0   0   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   1   0   0   0   0   0]
 [  0   0   0   2   0   1   0   0   0  78   1   1   0   0   0   0   2   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   1   0   0   1   0   0   0   0  73   0   2   0   1   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   1   0   0   0   2   0   2   1   0   0 109   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   0   0   0   0   0   0   0  93   0   0   0   0]
 [  0   1   0   0   0   1   0   0   0   0   0   1   0   0   0   0  56   2   2   0]
 [  1   1   0   2   0   0   0   0   0   0   4   0   0   0   0   0   1  88   0   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   2   0   0   0   2  95   1]
 [  0   0   0   0   1   3   1   0   0   0   3   0   0   0   0   1   0   0   0 130]]

2025-04-28 02:27:30,901 - ==> Best [Top1: 94.566   Top5: 98.886   Params: 306880 on epoch: 227]
2025-04-28 02:27:30,901 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:27:30,908 - 

2025-04-28 02:27:30,908 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:28:03,241 - Epoch: [230][   90/   90]    Overall Loss 0.027075    Objective Loss 0.027075    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.359225    
2025-04-28 02:28:03,269 - --- validate (epoch=230)-----------
2025-04-28 02:28:03,269 - 2245 samples (100 per mini-batch)
2025-04-28 02:28:07,978 - Epoch: [230][   23/   23]    Loss 0.257538    Top1 94.342984    Top5 98.930958    
2025-04-28 02:28:08,008 - ==> Top1: 94.343    Top5: 98.931    Loss: 0.258

2025-04-28 02:28:08,008 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   3]
 [  0 109   1   0   0   0   0   3   0   0   0   3   0   1   0   0   1   0   1   1]
 [  0   0  99   0   1   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   0   0   0   0   0   4   0   3   0   0   0   0   2   0]
 [  0   0   0   0 190   0   0   0   0   0   0   0   1   0   2   1   0   0   1   3]
 [  0   0   0   0   0  78   1   0   0   0   0   0   0   0   0   1   0   1   0   7]
 [  0   0   1   0   0   0 124   0   0   0   1   0   0   0   0   0   0   0   0   2]
 [  0   0   0   1   0   0   0  98   0   0   1   0   0   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   1   0   0   0   0   0]
 [  1   0   0   2   0   1   0   1   0  78   1   1   0   0   0   0   0   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  0   1   0   0   0   0   1   0   0   0   0  76   0   2   0   0   1   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   2   0   1   0   1   0   1   1   1   0 108   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   1   0   0   2   0   0   0   0   0   0   0  92   0   0   1   0]
 [  0   2   0   0   1   1   0   0   0   0   0   3   0   0   0   0  54   1   1   0]
 [  1   1   0   0   0   1   0   0   0   0   2   1   0   0   0   1   0  89   1   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   2   1   0   0   0   3  94   1]
 [  0   0   2   0   1   3   1   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 02:28:08,010 - ==> Best [Top1: 94.566   Top5: 98.886   Params: 306880 on epoch: 227]
2025-04-28 02:28:08,011 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:28:08,018 - 

2025-04-28 02:28:08,018 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:28:40,858 - Epoch: [231][   90/   90]    Overall Loss 0.030196    Objective Loss 0.030196    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.364854    
2025-04-28 02:28:40,892 - --- validate (epoch=231)-----------
2025-04-28 02:28:40,893 - 2245 samples (100 per mini-batch)
2025-04-28 02:28:45,465 - Epoch: [231][   23/   23]    Loss 0.268792    Top1 94.298441    Top5 98.886414    
2025-04-28 02:28:45,488 - ==> Top1: 94.298    Top5: 98.886    Loss: 0.269

2025-04-28 02:28:45,488 - ==> Confusion:
[[ 98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   3]
 [  0 108   1   1   1   0   0   1   0   0   0   2   0   1   0   1   3   0   1   0]
 [  0   0  97   0   3   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   0   0   0   0   3   0   3   0   0   0   0   2   0]
 [  0   0   0   1 194   0   0   0   0   0   0   0   1   0   0   0   0   0   1   1]
 [  0   0   0   0   2  75   0   0   0   1   0   0   0   0   0   1   1   1   1   6]
 [  0   0   0   0   0   0 123   0   0   0   1   0   0   0   1   0   0   0   0   3]
 [  0   0   0   1   0   0   0  96   0   1   1   0   0   0   0   1   0   0   1   1]
 [  0   0   1   0   0   0   1   0 214   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   4   0   0   0   0   0  78   0   1   0   0   0   0   1   0   0   1]
 [  0   1   0   1   0   0   0   0   0   0 109   0   0   0   0   0   1   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   0  75   0   2   0   0   2   0   1   0]
 [  1   0   1   0   1   0   0   0   0   0   0   0  79   0   0   0   0   1   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   1   0 110   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  56   0   0   0   1   0]
 [  0   1   0   1   1   0   1   1   0   0   0   0   0   0   0  91   0   0   2   0]
 [  0   1   0   0   1   1   0   0   0   0   0   3   0   0   0   0  55   1   1   0]
 [  1   0   0   1   0   0   0   0   0   0   1   1   0   0   0   0   1  89   3   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   0   1   0   0   0   2  97   1]
 [  0   0   0   0   1   3   1   0   0   0   2   0   0   0   0   0   0   0   0 132]]

2025-04-28 02:28:45,491 - ==> Best [Top1: 94.566   Top5: 98.886   Params: 306880 on epoch: 227]
2025-04-28 02:28:45,491 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:28:45,498 - 

2025-04-28 02:28:45,498 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:29:18,154 - Epoch: [232][   90/   90]    Overall Loss 0.025555    Objective Loss 0.025555    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.362821    
2025-04-28 02:29:18,181 - --- validate (epoch=232)-----------
2025-04-28 02:29:18,182 - 2245 samples (100 per mini-batch)
2025-04-28 02:29:22,740 - Epoch: [232][   23/   23]    Loss 0.259955    Top1 94.120267    Top5 99.064588    
2025-04-28 02:29:22,767 - ==> Top1: 94.120    Top5: 99.065    Loss: 0.260

2025-04-28 02:29:22,767 - ==> Confusion:
[[ 95   0   0   0   0   1   1   0   1   0   0   0   0   0   0   0   1   0   1   2]
 [  0 114   0   0   1   0   0   2   0   0   0   0   0   0   0   0   2   0   1   0]
 [  0   0  96   0   3   1   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 138   0   1   0   1   0   0   0   5   0   3   0   0   0   0   1   0]
 [  0   1   0   0 192   0   0   0   0   0   0   0   1   0   1   1   0   0   1   1]
 [  0   0   0   0   3  76   0   1   0   0   0   1   0   0   0   1   1   1   0   4]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   2   0   0   0   0   0  98   0   0   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   1   1 214   0   0   0   0   0   0   0   0   0   0   0]
 [  1   2   0   3   0   0   0   0   0  76   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 109   0   0   0   0   0   3   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  77   0   1   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   1   0   0   0   0   0   0   0   0   0   2   0 110   0   0   1   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   2   0   1   1   0   0   2   0   0   0   0   0   0   0  91   0   0   1   0]
 [  0   1   0   0   1   1   0   0   0   0   0   1   0   0   0   0  57   1   1   0]
 [  0   2   0   1   0   0   0   0   0   0   1   0   0   0   0   0   1  89   3   0]
 [  0   1   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   4  94   0]
 [  0   1   0   0   1   4   1   0   0   0   3   0   0   0   0   0   1   0   0 128]]

2025-04-28 02:29:22,769 - ==> Best [Top1: 94.566   Top5: 98.886   Params: 306880 on epoch: 227]
2025-04-28 02:29:22,770 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:29:22,777 - 

2025-04-28 02:29:22,777 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:29:55,462 - Epoch: [233][   90/   90]    Overall Loss 0.035640    Objective Loss 0.035640    Top1 97.841727    Top5 100.000000    LR 0.000125    Time 0.363131    
2025-04-28 02:29:55,492 - --- validate (epoch=233)-----------
2025-04-28 02:29:55,492 - 2245 samples (100 per mini-batch)
2025-04-28 02:29:59,994 - Epoch: [233][   23/   23]    Loss 0.259214    Top1 94.031180    Top5 99.020045    
2025-04-28 02:30:00,019 - ==> Top1: 94.031    Top5: 99.020    Loss: 0.259

2025-04-28 02:30:00,020 - ==> Confusion:
[[ 92   0   4   0   0   0   2   0   0   0   1   0   0   0   0   0   0   0   0   3]
 [  0 111   1   0   1   0   0   1   0   2   0   0   1   0   0   0   2   0   1   0]
 [  0   0  99   0   1   0   3   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 143   0   0   0   0   0   0   0   3   0   2   0   0   0   0   1   0]
 [  0   0   0   1 191   0   0   0   0   0   0   0   1   0   2   0   0   0   1   2]
 [  0   0   0   1   0  78   3   0   0   0   0   0   0   0   0   1   1   1   0   3]
 [  0   0   0   0   0   0 123   0   0   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   1   0   1   0  95   0   1   2   0   0   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   1   0   0   0   0   0]
 [  0   0   0   2   0   1   0   0   0  80   0   1   0   0   0   0   1   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  75   0   3   0   0   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   3   0   0   0   0   0   5   1   1   0 105   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   1   1   0   0   1   0   0   0   0   0   0   0  94   0   0   0   0]
 [  0   2   0   0   1   1   0   0   0   0   0   3   0   0   0   0  54   1   1   0]
 [  1   1   0   1   0   0   0   0   0   0   3   0   0   0   0   1   0  89   1   0]
 [  0   0   0   1   1   1   1   0   0   1   0   0   1   1   1   0   0   5  91   0]
 [  0   0   2   0   1   3   3   0   0   0   3   0   0   0   0   0   0   0   0 127]]

2025-04-28 02:30:00,022 - ==> Best [Top1: 94.566   Top5: 98.886   Params: 306880 on epoch: 227]
2025-04-28 02:30:00,022 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:30:00,030 - 

2025-04-28 02:30:00,031 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:30:32,288 - Epoch: [234][   90/   90]    Overall Loss 0.039647    Objective Loss 0.039647    Top1 97.122302    Top5 100.000000    LR 0.000125    Time 0.358387    
2025-04-28 02:30:32,315 - --- validate (epoch=234)-----------
2025-04-28 02:30:32,316 - 2245 samples (100 per mini-batch)
2025-04-28 02:30:36,956 - Epoch: [234][   23/   23]    Loss 0.276269    Top1 94.209354    Top5 99.064588    
2025-04-28 02:30:36,987 - ==> Top1: 94.209    Top5: 99.065    Loss: 0.276

2025-04-28 02:30:36,987 - ==> Confusion:
[[ 97   0   0   0   0   1   1   0   0   0   0   0   0   0   0   0   0   0   1   2]
 [  0 110   1   1   0   0   0   2   0   0   0   0   0   1   0   2   2   0   1   0]
 [  0   0  97   0   2   1   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 143   0   0   0   0   0   0   0   3   0   2   0   0   0   0   1   0]
 [  0   0   0   0 191   0   0   0   0   0   0   0   0   0   0   5   0   0   1   1]
 [  0   0   0   0   0  80   0   0   0   0   0   1   0   0   0   1   0   1   0   5]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   0   1   0   0   0   2]
 [  0   0   0   1   0   1   0  97   0   0   1   0   0   0   0   2   0   0   0   0]
 [  0   0   0   0   0   1   1   0 214   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   3   0   3   0   0   0  78   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  78   0   2   0   0   0   0   0   0]
 [  0   0   0   0   5   1   0   0   0   0   1   0  75   0   0   0   0   1   0   0]
 [  0   0   0   4   0   0   0   0   0   0   1   0   0 110   0   0   0   0   0   0]
 [  0   0   0   0   3   1   0   0   0   0   0   0   2   0  52   0   0   0   0   1]
 [  0   1   0   2   0   0   0   1   0   0   0   0   0   0   0  94   0   0   0   0]
 [  0   1   0   0   0   3   0   0   0   0   0   2   0   0   0   0  55   1   1   0]
 [  0   1   0   1   0   1   0   0   0   0   3   0   0   0   0   0   0  89   2   0]
 [  0   0   0   1   1   1   0   0   0   1   0   0   1   2   0   0   0   2  95   0]
 [  0   0   0   1   1   4   2   0   0   0   4   0   0   0   0   1   0   0   0 126]]

2025-04-28 02:30:36,989 - ==> Best [Top1: 94.566   Top5: 98.886   Params: 306880 on epoch: 227]
2025-04-28 02:30:36,989 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:30:36,996 - 

2025-04-28 02:30:36,996 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:31:09,524 - Epoch: [235][   90/   90]    Overall Loss 0.038436    Objective Loss 0.038436    Top1 96.402878    Top5 100.000000    LR 0.000125    Time 0.361393    
2025-04-28 02:31:09,551 - --- validate (epoch=235)-----------
2025-04-28 02:31:09,551 - 2245 samples (100 per mini-batch)
2025-04-28 02:31:14,055 - Epoch: [235][   23/   23]    Loss 0.257213    Top1 94.610245    Top5 98.930958    
2025-04-28 02:31:14,082 - ==> Top1: 94.610    Top5: 98.931    Loss: 0.257

2025-04-28 02:31:14,083 - ==> Confusion:
[[ 99   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 111   0   0   0   0   1   3   0   0   0   1   0   1   0   0   1   0   1   1]
 [  0   0  97   0   1   2   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   1   0   1   0   3   0   1   0   0   0   0   2   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   1   0   1   1   0   0   1   2]
 [  0   0   0   0   2  75   0   0   0   0   0   0   0   0   0   1   0   2   0   8]
 [  0   0   0   0   0   0 123   0   1   0   2   0   0   0   0   0   0   0   0   2]
 [  0   0   0   0   0   0   0  99   1   0   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   1   0   0   0   0   0]
 [  0   0   0   2   0   0   0   0   0  81   0   1   0   0   0   0   1   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  74   0   2   0   0   1   2   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   2   1   0   0 111   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   3   0   0   2   1   0   0   0   0   0   0  89   0   0   1   0]
 [  0   1   0   0   1   1   0   0   0   0   0   1   0   0   0   0  55   2   2   0]
 [  1   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1  91   1   1]
 [  1   0   0   0   1   0   1   0   0   1   0   0   1   2   0   0   0   2  94   1]
 [  0   0   0   0   1   4   1   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:31:14,085 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:31:14,085 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:31:14,095 - 

2025-04-28 02:31:14,095 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:31:46,568 - Epoch: [236][   90/   90]    Overall Loss 0.024950    Objective Loss 0.024950    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.360784    
2025-04-28 02:31:46,598 - --- validate (epoch=236)-----------
2025-04-28 02:31:46,598 - 2245 samples (100 per mini-batch)
2025-04-28 02:31:51,343 - Epoch: [236][   23/   23]    Loss 0.266483    Top1 94.298441    Top5 98.886414    
2025-04-28 02:31:51,368 - ==> Top1: 94.298    Top5: 98.886    Loss: 0.266

2025-04-28 02:31:51,368 - ==> Confusion:
[[ 99   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 112   0   1   1   0   0   1   0   1   0   0   0   0   0   2   1   0   1   0]
 [  0   0  98   0   1   2   2   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   0   0   0   0   2   0   2   0   2   0   0   2   0]
 [  0   1   0   0 188   1   0   0   0   0   0   0   2   0   2   1   0   0   1   2]
 [  0   0   0   0   1  78   1   0   0   0   0   0   0   0   0   2   1   2   1   2]
 [  0   0   0   0   0   0 122   0   0   0   2   0   0   0   1   1   0   0   0   2]
 [  0   0   0   0   0   0   0  93   0   1   2   0   0   0   0   6   0   0   0   0]
 [  0   0   0   0   0   0   1   1 214   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   2   0   0   0   0   0  81   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  0   1   0   0   0   1   0   0   0   1   0  73   0   3   0   0   1   1   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0  81   0   0   0   0   1   0   0]
 [  0   0   0   2   0   0   0   0   0   3   1   0   0 108   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   0   0   0   0   0   0   0   0   0   0   0  96   0   0   0   0]
 [  0   1   0   0   1   1   0   0   0   0   0   3   0   0   0   0  54   2   1   0]
 [  0   1   0   1   0   0   0   0   0   0   1   0   0   0   0   2   0  88   4   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   1   2   0   1   0   2  95   1]
 [  0   0   1   0   1   2   2   0   0   0   2   0   0   0   0   1   0   0   0 130]]

2025-04-28 02:31:51,370 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:31:51,370 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:31:51,378 - 

2025-04-28 02:31:51,378 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:32:23,926 - Epoch: [237][   90/   90]    Overall Loss 0.023544    Objective Loss 0.023544    Top1 98.561151    Top5 100.000000    LR 0.000125    Time 0.361614    
2025-04-28 02:32:23,956 - --- validate (epoch=237)-----------
2025-04-28 02:32:23,956 - 2245 samples (100 per mini-batch)
2025-04-28 02:32:28,586 - Epoch: [237][   23/   23]    Loss 0.302751    Top1 93.541203    Top5 98.975501    
2025-04-28 02:32:28,611 - ==> Top1: 93.541    Top5: 98.976    Loss: 0.303

2025-04-28 02:32:28,612 - ==> Confusion:
[[ 94   0   0   2   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   4]
 [  0 109   0   0   0   0   0   2   1   0   1   2   0   1   0   0   2   0   1   1]
 [  0   0  94   0   1   2   3   0   3   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 142   0   0   0   0   0   0   0   3   0   3   0   0   0   0   1   0]
 [  0   0   0   0 192   1   0   0   0   0   0   0   1   0   0   1   0   0   1   2]
 [  0   0   0   1   2  75   0   0   0   0   0   1   0   0   0   1   1   1   0   6]
 [  0   0   0   0   0   0 119   0   1   0   2   1   0   0   0   0   0   0   0   5]
 [  0   0   0   0   0   0   0  99   0   0   1   0   0   0   0   0   0   1   0   1]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   5   0   0   0   0   0  76   1   1   0   1   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  77   0   2   0   0   1   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   1   0  80   0   1   0   0   0   0   0]
 [  0   0   0   5   0   0   0   0   0   0   1   0   0 109   0   0   0   0   0   0]
 [  0   0   0   0   0   1   0   0   0   0   1   0   2   0  55   0   0   0   0   0]
 [  0   1   0   2   2   0   0   2   1   0   0   1   0   0   0  89   0   0   0   0]
 [  0   1   0   0   0   1   0   0   0   0   2   3   0   0   0   0  54   1   1   0]
 [  0   1   0   2   0   0   0   0   0   0   3   1   0   0   0   0   1  86   3   0]
 [  0   0   0   2   0   1   0   0   0   1   1   1   1   3   0   0   0   2  91   1]
 [  0   0   0   0   1   3   1   0   0   0   3   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:32:28,614 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:32:28,614 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:32:28,621 - 

2025-04-28 02:32:28,621 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:33:01,105 - Epoch: [238][   90/   90]    Overall Loss 0.039829    Objective Loss 0.039829    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.360903    
2025-04-28 02:33:01,134 - --- validate (epoch=238)-----------
2025-04-28 02:33:01,134 - 2245 samples (100 per mini-batch)
2025-04-28 02:33:05,699 - Epoch: [238][   23/   23]    Loss 0.285860    Top1 93.763920    Top5 98.975501    
2025-04-28 02:33:05,724 - ==> Top1: 93.764    Top5: 98.976    Loss: 0.286

2025-04-28 02:33:05,724 - ==> Confusion:
[[ 97   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   1   2]
 [  0 105   2   0   0   1   0   3   1   0   0   2   0   3   0   1   1   0   1   0]
 [  0   0  98   0   3   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   1   0   0   0   0   0   0   2   0   2   0   0   0   0   4   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   0   1   0   0   1   1]
 [  0   0   1   0   3  77   0   0   0   0   0   0   0   0   0   1   0   1   0   5]
 [  0   0   1   0   0   0 123   0   1   0   1   0   0   0   0   0   0   0   0   2]
 [  0   0   0   0   0   1   0  97   0   0   1   0   0   0   0   1   0   1   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   2   0   0   0  76   0   1   0   2   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   1   1   0]
 [  1   1   0   0   0   2   0   0   0   0   0  74   0   1   0   0   1   1   0   0]
 [  0   0   1   0   1   0   0   0   0   0   0   0  80   0   0   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   0   1   0   0 113   0   0   0   0   0   0]
 [  0   0   2   0   4   0   0   0   0   0   0   0   3   0  50   0   0   0   0   0]
 [  0   1   0   1   4   0   0   1   1   0   0   0   0   0   0  89   0   0   1   0]
 [  0   1   0   0   3   1   0   0   0   0   0   2   0   0   0   0  54   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1  89   4   0]
 [  1   0   0   0   3   1   0   0   0   0   0   0   0   1   0   0   0   3  94   1]
 [  0   0   2   0   1   3   1   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 02:33:05,726 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:33:05,726 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:33:05,734 - 

2025-04-28 02:33:05,734 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:33:38,152 - Epoch: [239][   90/   90]    Overall Loss 0.037632    Objective Loss 0.037632    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.360167    
2025-04-28 02:33:38,180 - --- validate (epoch=239)-----------
2025-04-28 02:33:38,180 - 2245 samples (100 per mini-batch)
2025-04-28 02:33:42,717 - Epoch: [239][   23/   23]    Loss 0.285607    Top1 94.075724    Top5 98.886414    
2025-04-28 02:33:42,740 - ==> Top1: 94.076    Top5: 98.886    Loss: 0.286

2025-04-28 02:33:42,741 - ==> Confusion:
[[100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 107   2   0   0   0   0   3   1   0   0   2   0   1   0   1   1   0   2   0]
 [  0   0  99   0   2   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   0   1   0   0   0   3   0   2   0   0   0   0   3   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   1   0   0   1   0]
 [  0   0   0   0   4  73   0   1   0   0   0   1   0   0   0   1   1   2   1   4]
 [  1   0   1   0   1   0 121   0   1   0   1   0   0   0   1   0   0   0   0   1]
 [  0   0   0   0   0   0   0  98   0   0   1   0   0   0   0   1   0   1   1   0]
 [  0   0   0   0   0   0   0   0 214   0   0   0   0   0   1   0   0   0   1   0]
 [  1   0   0   4   0   0   0   3   0  73   1   1   0   0   0   0   2   0   1   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  76   0   2   0   0   0   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   2   0   0   0   0   0   0   1   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   3   0   0   2   1   0   0   0   0   0   0  89   0   0   1   0]
 [  0   1   0   1   1   2   0   0   0   0   0   1   0   0   0   0  54   1   2   0]
 [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1  92   3   0]
 [  1   0   0   0   2   1   0   0   0   0   0   0   0   1   0   0   0   3  95   1]
 [  0   0   1   0   2   2   2   0   0   0   3   0   0   0   0   1   1   0   0 127]]

2025-04-28 02:33:42,743 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:33:42,743 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:33:42,750 - 

2025-04-28 02:33:42,750 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:34:15,295 - Epoch: [240][   90/   90]    Overall Loss 0.036688    Objective Loss 0.036688    Top1 98.561151    Top5 100.000000    LR 0.000125    Time 0.361579    
2025-04-28 02:34:15,320 - --- validate (epoch=240)-----------
2025-04-28 02:34:15,320 - 2245 samples (100 per mini-batch)
2025-04-28 02:34:19,833 - Epoch: [240][   23/   23]    Loss 0.264254    Top1 94.476615    Top5 98.930958    
2025-04-28 02:34:19,859 - ==> Top1: 94.477    Top5: 98.931    Loss: 0.264

2025-04-28 02:34:19,860 - ==> Confusion:
[[ 98   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   3]
 [  0 110   1   0   0   0   0   2   1   0   0   1   0   1   0   2   1   0   1   0]
 [  0   0  97   0   3   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 142   0   0   0   0   0   0   0   2   0   2   0   0   0   0   3   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   0   1   0   0   1   2]
 [  0   0   0   0   3  76   0   0   0   0   0   0   0   0   0   1   1   2   0   5]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   2   0   0   0  98   0   0   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   6   0   0   0   0   0  76   1   1   0   1   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   2   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  75   0   4   0   0   0   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   0   1   0   0 112   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   1   0   0   1   1   0   0   0   0   0   0  93   0   0   0   0]
 [  0   1   0   0   1   1   0   0   0   1   0   3   0   0   0   0  54   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1  90   3   0]
 [  0   0   0   1   1   1   0   0   0   1   0   0   1   2   0   0   0   3  93   1]
 [  0   0   0   0   1   4   1   0   0   0   3   0   0   0   0   1   0   0   0 129]]

2025-04-28 02:34:19,862 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:34:19,862 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:34:19,870 - 

2025-04-28 02:34:19,870 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:34:52,249 - Epoch: [241][   90/   90]    Overall Loss 0.034207    Objective Loss 0.034207    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.359730    
2025-04-28 02:34:52,275 - --- validate (epoch=241)-----------
2025-04-28 02:34:52,275 - 2245 samples (100 per mini-batch)
2025-04-28 02:34:56,771 - Epoch: [241][   23/   23]    Loss 0.296071    Top1 93.496659    Top5 98.886414    
2025-04-28 02:34:56,795 - ==> Top1: 93.497    Top5: 98.886    Loss: 0.296

2025-04-28 02:34:56,795 - ==> Confusion:
[[ 95   0   0   0   0   0   1   1   0   0   1   0   0   0   0   0   1   1   1   1]
 [  0 111   0   0   0   0   1   3   0   0   0   0   1   0   0   0   2   0   1   1]
 [  0   0  95   0   4   0   2   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 137   1   0   1   1   0   0   0   2   0   3   0   0   0   0   4   0]
 [  0   0   0   0 196   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0]
 [  0   3   0   0   4  73   1   1   0   0   0   0   0   0   0   1   1   2   0   2]
 [  0   0   0   0   0   0 123   0   0   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   0   0  99   0   1   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   1   0   0   0   0   0]
 [  1   1   0   2   0   0   0   0   0  80   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  1   3   0   1   0   0   0   0   0   1   0  71   0   2   0   0   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   1   1   0   0   0   2   0   2   1   0   0 108   0   0   0   0   0   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0   3   0  54   0   0   0   0   0]
 [  0   1   0   2   4   0   0   2   0   0   0   0   0   0   0  88   0   0   1   0]
 [  0   4   0   1   1   1   0   0   0   0   0   2   0   0   0   0  52   1   1   0]
 [  1   2   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1  90   1   0]
 [  0   1   0   0   1   0   0   0   0   1   0   0   3   1   0   0   0   2  95   0]
 [  0   0   1   0   1   3   2   0   0   0   4   0   0   0   0   0   1   0   0 127]]

2025-04-28 02:34:56,797 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:34:56,797 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:34:56,805 - 

2025-04-28 02:34:56,805 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:35:29,196 - Epoch: [242][   90/   90]    Overall Loss 0.038024    Objective Loss 0.038024    Top1 97.122302    Top5 100.000000    LR 0.000125    Time 0.359862    
2025-04-28 02:35:29,220 - --- validate (epoch=242)-----------
2025-04-28 02:35:29,220 - 2245 samples (100 per mini-batch)
2025-04-28 02:35:33,879 - Epoch: [242][   23/   23]    Loss 0.281957    Top1 93.763920    Top5 98.930958    
2025-04-28 02:35:33,900 - ==> Top1: 93.764    Top5: 98.931    Loss: 0.282

2025-04-28 02:35:33,900 - ==> Confusion:
[[ 94   0   0   1   0   0   1   0   0   1   1   0   0   0   0   1   0   1   1   1]
 [  0 110   0   0   0   0   0   2   0   3   0   0   0   0   0   0   2   0   2   1]
 [  0   0  98   0   2   1   1   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   1   0   0   0   3   0   1   0   0   0   0   3   0]
 [  0   0   0   0 190   1   0   0   0   0   0   0   2   0   0   1   0   0   3   1]
 [  0   0   0   0   1  77   0   0   0   0   0   1   1   0   0   1   1   1   1   4]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   0   0  99   0   1   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  0   1   0   4   0   0   0   0   0  80   0   1   0   0   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  0   1   0   1   0   0   0   0   0   0   0  76   0   0   0   0   2   1   0   0]
 [  0   0   1   0   1   0   0   0   0   0   0   0  80   0   0   0   0   0   1   0]
 [  0   1   0   5   0   0   0   0   0   6   1   2   0  96   0   1   1   0   2   0]
 [  0   0   0   0   0   0   0   0   0   1   0   0   3   0  55   0   0   0   0   0]
 [  0   1   0   1   1   0   0   2   0   0   0   0   0   0   0  92   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   1   0   2   0   0   0   0  56   1   1   0]
 [  0   2   0   1   0   0   0   0   0   0   1   0   0   0   0   0   1  90   2   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   1   1   0   0   0   3  96   1]
 [  0   0   0   0   1   4   2   0   0   0   3   0   0   0   0   0   1   0   0 128]]

2025-04-28 02:35:33,902 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:35:33,902 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:35:33,910 - 

2025-04-28 02:35:33,910 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:36:06,596 - Epoch: [243][   90/   90]    Overall Loss 0.053218    Objective Loss 0.053218    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.363152    
2025-04-28 02:36:06,623 - --- validate (epoch=243)-----------
2025-04-28 02:36:06,623 - 2245 samples (100 per mini-batch)
2025-04-28 02:36:11,174 - Epoch: [243][   23/   23]    Loss 0.285063    Top1 93.674833    Top5 98.930958    
2025-04-28 02:36:11,195 - ==> Top1: 93.675    Top5: 98.931    Loss: 0.285

2025-04-28 02:36:11,195 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   1   0   1   1]
 [  0 111   1   0   1   0   0   2   0   0   0   0   1   1   0   0   3   0   0   0]
 [  0   0  95   0   4   0   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 137   0   0   0   0   0   0   0   3   0   5   0   0   0   0   4   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   0   0   0   0   2   1]
 [  0   0   0   0   3  75   0   0   0   0   0   0   1   0   0   1   1   1   0   6]
 [  0   0   0   0   0   0 123   0   0   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   1   0  96   0   0   1   0   0   0   0   3   0   1   0   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   1   0   0   0   0   0]
 [  1   1   0   1   0   1   0   0   0  78   0   2   0   1   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 109   0   0   0   0   0   2   2   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   1   0   0]
 [  0   0   0   0   2   1   0   0   0   0   0   0  79   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   0   0   0   1   0   0   0 112   0   0   1   0   0   1]
 [  0   0   0   0   4   0   0   0   0   0   0   0   3   0  52   0   0   0   0   0]
 [  0   1   0   0   4   0   1   2   0   0   0   1   0   0   0  88   0   0   1   0]
 [  0   1   0   0   1   1   0   0   0   0   0   3   0   0   0   0  55   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   2   1   0   0   0   0   1  89   3   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   1   1   0   0   1   3  94   0]
 [  0   0   0   0   1   5   1   0   0   0   2   0   0   0   0   0   1   0   0 129]]

2025-04-28 02:36:11,197 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:36:11,197 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:36:11,204 - 

2025-04-28 02:36:11,204 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:36:43,553 - Epoch: [244][   90/   90]    Overall Loss 0.030191    Objective Loss 0.030191    Top1 98.561151    Top5 100.000000    LR 0.000125    Time 0.359398    
2025-04-28 02:36:43,586 - --- validate (epoch=244)-----------
2025-04-28 02:36:43,586 - 2245 samples (100 per mini-batch)
2025-04-28 02:36:48,105 - Epoch: [244][   23/   23]    Loss 0.299970    Top1 94.031180    Top5 99.109131    
2025-04-28 02:36:48,127 - ==> Top1: 94.031    Top5: 99.109    Loss: 0.300

2025-04-28 02:36:48,128 - ==> Confusion:
[[ 98   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   1]
 [  0 114   0   0   1   0   0   2   0   0   0   1   0   0   0   0   2   0   0   0]
 [  0   0  94   0   4   0   2   0   3   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 137   0   0   0   1   0   0   0   4   0   5   0   0   0   0   2   0]
 [  0   0   0   0 196   0   0   0   0   0   0   0   1   0   0   0   0   0   0   1]
 [  0   0   0   0   3  74   0   1   0   0   0   0   0   0   0   1   1   2   0   6]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   0   0 100   0   1   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   3   0   0   0   1   0  75   0   1   0   1   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   2   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   2   0   0   1   1   0   0]
 [  1   0   0   0   2   0   0   0   0   0   0   0  79   0   1   0   0   0   0   0]
 [  0   0   0   1   1   0   0   1   0   0   0   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   3   0   0   0   0   0   0   0   2   0  54   0   0   0   0   0]
 [  0   1   0   1   4   0   0   2   1   0   0   0   0   0   0  88   0   0   1   0]
 [  0   1   0   0   3   1   0   0   0   0   0   2   0   0   0   0  54   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   3   0   0   0   0   0   1  89   2   0]
 [  1   1   0   0   2   0   0   0   0   0   0   0   1   3   0   0   1   1  94   0]
 [  0   0   0   0   4   2   1   0   0   0   2   0   0   0   0   0   0   0   0 130]]

2025-04-28 02:36:48,130 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:36:48,130 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:36:48,137 - 

2025-04-28 02:36:48,138 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:37:20,894 - Epoch: [245][   90/   90]    Overall Loss 0.024222    Objective Loss 0.024222    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.363928    
2025-04-28 02:37:20,919 - --- validate (epoch=245)-----------
2025-04-28 02:37:20,919 - 2245 samples (100 per mini-batch)
2025-04-28 02:37:25,466 - Epoch: [245][   23/   23]    Loss 0.279360    Top1 94.432071    Top5 98.930958    
2025-04-28 02:37:25,486 - ==> Top1: 94.432    Top5: 98.931    Loss: 0.279

2025-04-28 02:37:25,487 - ==> Confusion:
[[ 96   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   1   3]
 [  0 111   2   0   0   0   0   3   0   0   0   0   0   0   0   0   3   0   1   0]
 [  0   0  96   0   2   1   2   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   0   0   0   0   2   0   3   0   0   0   0   3   0]
 [  0   0   0   0 191   1   0   0   0   0   0   0   1   0   1   0   0   0   2   2]
 [  0   0   0   0   0  78   0   0   0   0   0   0   0   0   0   1   0   2   0   7]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   1   0  97   0   1   1   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   1   0   0   0  77   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   1   0   0]
 [  1   0   0   0   0   1   0   0   0   0   0   0  80   0   1   0   0   0   0   0]
 [  0   0   1   1   0   0   0   0   0   1   1   0   0 111   0   0   0   0   0   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   2   0  56   0   0   0   0   0]
 [  0   1   0   1   2   1   0   2   0   0   0   0   0   0   0  89   0   0   2   0]
 [  0   1   0   0   1   1   0   0   0   0   0   2   0   0   0   0  54   2   2   0]
 [  1   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0  93   1   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   1   1   0   0   0   3  97   0]
 [  0   0   0   0   1   4   2   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 02:37:25,489 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:37:25,489 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:37:25,496 - 

2025-04-28 02:37:25,496 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:37:58,411 - Epoch: [246][   90/   90]    Overall Loss 0.018186    Objective Loss 0.018186    Top1 97.841727    Top5 100.000000    LR 0.000125    Time 0.365695    
2025-04-28 02:37:58,446 - --- validate (epoch=246)-----------
2025-04-28 02:37:58,446 - 2245 samples (100 per mini-batch)
2025-04-28 02:38:02,963 - Epoch: [246][   23/   23]    Loss 0.264274    Top1 94.209354    Top5 98.975501    
2025-04-28 02:38:02,986 - ==> Top1: 94.209    Top5: 98.976    Loss: 0.264

2025-04-28 02:38:02,987 - ==> Confusion:
[[ 97   0   0   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   2]
 [  0 108   2   0   0   0   0   3   0   0   0   3   0   1   0   0   2   0   1   0]
 [  0   0  98   0   3   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 142   0   0   0   0   0   0   0   3   0   2   0   0   0   0   2   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   0   1   0   0   2   1]
 [  0   0   0   0   2  76   0   0   0   0   0   1   1   0   0   1   1   1   0   5]
 [  0   0   0   1   0   0 120   0   1   0   2   0   0   0   1   1   0   0   0   2]
 [  0   0   0   2   0   0   0  98   0   0   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   6   0   0   0   0   0  78   0   1   0   0   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  77   0   1   0   1   1   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   4   0   0   0   1   0   0   1   1   0 108   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   2   0   0   2   0   0   0   0   0   0   0  91   0   0   0   0]
 [  0   2   0   0   1   1   0   0   0   0   0   3   0   0   0   0  54   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   1   0  89   4   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   2   2   0   0   0   2  94   1]
 [  0   0   1   0   1   3   2   0   0   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 02:38:02,989 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:38:02,989 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:38:02,996 - 

2025-04-28 02:38:02,996 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:38:35,616 - Epoch: [247][   90/   90]    Overall Loss 0.028319    Objective Loss 0.028319    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.362410    
2025-04-28 02:38:35,645 - --- validate (epoch=247)-----------
2025-04-28 02:38:35,645 - 2245 samples (100 per mini-batch)
2025-04-28 02:38:40,193 - Epoch: [247][   23/   23]    Loss 0.290607    Top1 94.120267    Top5 99.020045    
2025-04-28 02:38:40,215 - ==> Top1: 94.120    Top5: 99.020    Loss: 0.291

2025-04-28 02:38:40,215 - ==> Confusion:
[[ 99   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 111   1   1   0   0   0   2   0   0   0   0   0   1   0   0   3   0   1   0]
 [  0   0  96   0   1   1   3   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 144   0   0   0   0   0   0   0   1   0   2   0   0   0   0   2   0]
 [  0   0   0   1 190   0   0   0   0   0   0   0   1   0   2   0   0   0   2   2]
 [  0   0   0   1   0  75   0   0   0   0   0   0   0   0   0   1   1   1   0   9]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   3   0   1   0  97   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   6   0   0   0   0   0  77   0   1   0   1   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   0  75   0   2   0   0   2   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   4   0   0   0   0   0   2   1   0   0 108   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   4   1   0   0   2   0   0   0   1   0   1   0  86   0   0   2   0]
 [  0   1   0   0   0   1   0   0   0   0   0   1   0   0   0   0  58   1   1   0]
 [  1   1   0   1   0   0   0   0   0   0   4   0   0   0   0   0   0  88   2   0]
 [  0   0   0   0   0   1   1   0   0   1   0   0   1   2   0   0   1   2  94   1]
 [  0   0   0   0   1   3   1   0   0   0   3   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:38:40,217 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:38:40,217 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:38:40,224 - 

2025-04-28 02:38:40,224 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:39:12,721 - Epoch: [248][   90/   90]    Overall Loss 0.023276    Objective Loss 0.023276    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.361046    
2025-04-28 02:39:12,745 - --- validate (epoch=248)-----------
2025-04-28 02:39:12,745 - 2245 samples (100 per mini-batch)
2025-04-28 02:39:17,235 - Epoch: [248][   23/   23]    Loss 0.305839    Top1 93.585746    Top5 98.708241    
2025-04-28 02:39:17,260 - ==> Top1: 93.586    Top5: 98.708    Loss: 0.306

2025-04-28 02:39:17,260 - ==> Confusion:
[[ 98   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 110   2   0   0   0   0   3   0   0   1   1   0   0   0   0   2   0   1   0]
 [  0   0  98   0   2   1   1   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 134   0   1   1   3   0   0   0   2   0   4   0   0   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   1   2]
 [  0   0   1   0   2  74   0   1   0   0   0   0   0   0   0   1   1   1   0   7]
 [  0   0   2   0   0   0 121   0   1   0   1   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   1   0  99   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   1 214   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   1   0   1   0   3   0  75   1   2   0   0   0   0   1   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   1]
 [  2   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  80   0   2   0   0   0   0   0]
 [  0   0   1   0   0   0   0   2   0   0   1   0   0 110   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   3   2   0   0   0   0   0   0  88   0   0   1   0]
 [  0   1   0   0   1   2   0   1   0   0   0   1   0   0   0   0  53   1   3   0]
 [  1   2   0   1   0   1   0   0   1   0   1   0   0   0   0   0   1  87   2   0]
 [  0   0   0   0   2   1   0   0   0   1   0   0   0   1   1   0   0   2  95   1]
 [  0   0   1   0   2   2   1   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:39:17,262 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:39:17,262 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:39:17,269 - 

2025-04-28 02:39:17,269 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:39:49,843 - Epoch: [249][   90/   90]    Overall Loss 0.025639    Objective Loss 0.025639    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.361899    
2025-04-28 02:39:49,875 - --- validate (epoch=249)-----------
2025-04-28 02:39:49,875 - 2245 samples (100 per mini-batch)
2025-04-28 02:39:54,540 - Epoch: [249][   23/   23]    Loss 0.278368    Top1 94.298441    Top5 99.020045    
2025-04-28 02:39:54,566 - ==> Top1: 94.298    Top5: 99.020    Loss: 0.278

2025-04-28 02:39:54,567 - ==> Confusion:
[[100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 109   1   0   0   0   1   3   0   0   0   1   0   1   0   0   3   0   1   0]
 [  0   0  96   0   1   1   3   0   1   0   0   0   0   0   0   0   0   0   0   1]
 [  0   0   0 139   0   0   0   0   0   0   0   3   0   3   0   0   0   0   4   0]
 [  1   0   0   0 189   0   1   0   0   0   0   0   1   0   2   0   0   0   2   2]
 [  0   0   0   0   0  76   1   0   0   0   0   1   0   0   0   1   1   1   0   7]
 [  0   0   0   0   0   0 123   0   1   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   0   1   0   1   0  98   0   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   4   0   1   0   0   0  77   0   1   0   1   0   0   0   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   2   0   0   1   1   0   0]
 [  1   0   0   0   0   1   0   0   0   0   0   0  80   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   0   1   0   0 113   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   1   0   0   2   0   0   0   0   0   0   0  90   0   0   2   0]
 [  0   1   0   0   0   2   0   0   0   0   0   2   0   0   0   0  56   1   1   0]
 [  2   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1  91   1   0]
 [  2   0   0   0   0   0   0   0   0   1   0   0   1   2   2   0   0   2  94   0]
 [  1   0   0   0   1   3   2   0   0   0   2   0   0   0   0   0   0   0   0 130]]

2025-04-28 02:39:54,569 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:39:54,569 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:39:54,577 - 

2025-04-28 02:39:54,577 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:40:27,023 - Epoch: [250][   90/   90]    Overall Loss 0.027324    Objective Loss 0.027324    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.360479    
2025-04-28 02:40:27,056 - --- validate (epoch=250)-----------
2025-04-28 02:40:27,056 - 2245 samples (100 per mini-batch)
2025-04-28 02:40:31,774 - Epoch: [250][   23/   23]    Loss 0.256018    Top1 94.342984    Top5 99.287305    
2025-04-28 02:40:31,799 - ==> Top1: 94.343    Top5: 99.287    Loss: 0.256

2025-04-28 02:40:31,799 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   2]
 [  0 115   0   0   0   0   0   2   0   0   0   1   0   0   0   0   1   0   0   1]
 [  0   0  96   0   1   2   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 138   0   0   1   1   0   0   0   3   0   3   0   0   0   0   3   0]
 [  0   1   0   0 189   1   0   0   0   0   0   0   1   0   1   1   0   0   2   2]
 [  0   0   0   0   0  78   0   0   0   0   0   0   0   0   0   1   1   0   0   8]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   1   0  98   0   1   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   1   0   0   0  77   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   2   0   0   0   0   0   1   0   0   0  74   0   1   0   0   2   0   0   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0  80   0   1   0   0   0   1   0]
 [  0   0   0   0   0   0   0   1   0   2   1   0   0 110   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   1   2   0   0   0   0   0   0   0  91   0   0   0   0]
 [  0   2   0   0   1   1   0   0   0   0   0   1   0   0   0   0  56   1   1   0]
 [  1   2   0   0   0   0   0   0   0   0   3   0   0   0   0   0   1  88   2   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   2  96   1]
 [  0   0   0   0   1   5   2   0   0   0   1   0   0   0   0   0   0   0   0 130]]

2025-04-28 02:40:31,801 - ==> Best [Top1: 94.610   Top5: 98.931   Params: 306880 on epoch: 235]
2025-04-28 02:40:31,801 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:40:31,808 - 

2025-04-28 02:40:31,808 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:41:04,132 - Epoch: [251][   90/   90]    Overall Loss 0.024728    Objective Loss 0.024728    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.359117    
2025-04-28 02:41:04,164 - --- validate (epoch=251)-----------
2025-04-28 02:41:04,164 - 2245 samples (100 per mini-batch)
2025-04-28 02:41:08,976 - Epoch: [251][   23/   23]    Loss 0.267854    Top1 94.743875    Top5 98.841871    
2025-04-28 02:41:09,005 - ==> Top1: 94.744    Top5: 98.842    Loss: 0.268

2025-04-28 02:41:09,006 - ==> Confusion:
[[ 99   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 112   1   0   1   0   0   2   0   0   0   2   0   0   0   0   2   0   0   0]
 [  0   0  95   0   2   1   2   0   1   0   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0 143   0   0   0   0   0   0   0   1   0   2   0   0   0   0   3   0]
 [  0   0   0   0 191   0   0   0   0   0   0   0   1   0   1   1   0   0   2   2]
 [  0   0   0   0   2  75   1   0   0   0   0   0   0   0   0   1   1   2   0   6]
 [  0   0   0   0   0   0 125   0   0   0   1   0   0   0   0   0   0   0   0   2]
 [  0   0   0   0   0   1   0  99   0   0   1   0   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   0   0   0   0  78   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   1   0   0]
 [  1   0   0   0   1   0   0   0   0   0   0   0  81   0   0   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   3   1   0   0 110   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   4   0   0   1   0   0   0   0   0   0   0  90   0   0   1   0]
 [  0   1   0   1   1   1   0   0   0   0   0   1   0   0   0   0  55   1   2   0]
 [  1   1   0   1   0   0   0   0   0   0   1   0   0   0   0   0   1  89   3   0]
 [  1   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   2  96   0]
 [  0   0   0   0   1   3   2   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:41:09,008 - ==> Best [Top1: 94.744   Top5: 98.842   Params: 306880 on epoch: 251]
2025-04-28 02:41:09,008 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:41:09,018 - 

2025-04-28 02:41:09,018 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:41:41,789 - Epoch: [252][   90/   90]    Overall Loss 0.016387    Objective Loss 0.016387    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.364096    
2025-04-28 02:41:41,817 - --- validate (epoch=252)-----------
2025-04-28 02:41:41,817 - 2245 samples (100 per mini-batch)
2025-04-28 02:41:46,327 - Epoch: [252][   23/   23]    Loss 0.266804    Top1 94.521158    Top5 98.930958    
2025-04-28 02:41:46,347 - ==> Top1: 94.521    Top5: 98.931    Loss: 0.267

2025-04-28 02:41:46,348 - ==> Confusion:
[[ 97   0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   1   2]
 [  0 109   1   0   0   0   0   3   0   0   0   2   0   1   0   2   1   0   1   0]
 [  0   0  96   0   2   1   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   0   0   0   0   3   0   2   0   0   0   0   3   0]
 [  0   0   0   0 191   0   0   0   0   0   1   0   1   0   0   1   0   0   2   2]
 [  0   0   0   0   1  80   2   0   0   0   0   0   0   0   0   1   1   1   0   2]
 [  0   0   0   0   1   0 121   0   1   0   2   0   0   0   1   1   0   0   0   1]
 [  0   0   0   0   0   1   0  97   0   0   1   0   0   0   0   1   0   1   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   5   0   0   0   0   0  79   0   2   0   0   0   0   0   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   0   0   1   0   0   0   0   0  78   0   1   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   4   1   1   0 107   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   1   1   0   0   1   0   0   0   0   0   0   0  94   0   0   0   0]
 [  0   1   0   0   1   1   0   0   0   0   0   2   0   0   0   0  55   1   2   0]
 [  0   1   0   1   0   1   0   0   0   0   2   0   0   0   0   0   1  87   4   0]
 [  0   0   0   0   1   1   0   0   0   1   1   0   1   1   0   0   0   0  98   0]
 [  0   0   1   0   1   5   2   0   0   0   2   0   0   0   0   0   1   0   0 127]]

2025-04-28 02:41:46,350 - ==> Best [Top1: 94.744   Top5: 98.842   Params: 306880 on epoch: 251]
2025-04-28 02:41:46,350 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:41:46,357 - 

2025-04-28 02:41:46,357 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:42:18,830 - Epoch: [253][   90/   90]    Overall Loss 0.019726    Objective Loss 0.019726    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.360789    
2025-04-28 02:42:18,860 - --- validate (epoch=253)-----------
2025-04-28 02:42:18,861 - 2245 samples (100 per mini-batch)
2025-04-28 02:42:23,349 - Epoch: [253][   23/   23]    Loss 0.265251    Top1 94.253898    Top5 98.975501    
2025-04-28 02:42:23,373 - ==> Top1: 94.254    Top5: 98.976    Loss: 0.265

2025-04-28 02:42:23,374 - ==> Confusion:
[[ 95   0   0   0   0   0   1   0   0   0   0   0   0   0   1   0   0   1   1   3]
 [  0 110   2   0   0   0   0   3   0   0   0   0   0   1   0   0   3   0   1   0]
 [  0   0  95   0   3   0   2   0   2   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 138   0   0   0   0   0   0   0   2   0   5   0   0   0   0   4   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   1   0   1   0   0   0   2   2]
 [  0   0   0   0   1  76   0   0   0   0   0   0   0   0   0   1   1   1   1   7]
 [  0   0   1   0   0   0 123   0   0   0   0   0   0   0   2   0   0   0   0   2]
 [  0   0   0   0   0   0   0  98   0   1   1   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   2   0   0   0   0   0  81   0   0   0   0   0   0   1   0   1   1]
 [  0   0   0   0   0   0   0   0   1   1 108   0   0   0   0   0   1   1   2   0]
 [  0   1   0   0   0   0   0   0   0   0   0  75   0   4   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   1   0   0   0 113   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   3   0   0   2   0   0   0   0   0   0   0  90   0   0   1   0]
 [  0   1   0   0   2   1   0   0   0   0   0   2   0   0   0   0  54   1   2   0]
 [  0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1  90   4   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   2  96   1]
 [  0   0   0   0   1   4   2   0   0   0   2   0   0   0   0   0   0   0   0 130]]

2025-04-28 02:42:23,376 - ==> Best [Top1: 94.744   Top5: 98.842   Params: 306880 on epoch: 251]
2025-04-28 02:42:23,376 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:42:23,383 - 

2025-04-28 02:42:23,384 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:42:55,677 - Epoch: [254][   90/   90]    Overall Loss 0.016270    Objective Loss 0.016270    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.358784    
2025-04-28 02:42:55,704 - --- validate (epoch=254)-----------
2025-04-28 02:42:55,704 - 2245 samples (100 per mini-batch)
2025-04-28 02:43:00,390 - Epoch: [254][   23/   23]    Loss 0.278838    Top1 94.743875    Top5 99.064588    
2025-04-28 02:43:00,412 - ==> Top1: 94.744    Top5: 99.065    Loss: 0.279

2025-04-28 02:43:00,412 - ==> Confusion:
[[ 98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   2]
 [  0 112   1   0   0   0   0   2   0   0   0   0   0   0   0   0   3   0   1   1]
 [  0   0  96   0   1   2   2   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   0   0   0   0   0   1   0   3   0   0   0   0   5   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   1   0   0   1   0   0   2   2]
 [  0   0   0   0   1  77   0   0   0   0   0   0   0   0   0   1   1   1   0   7]
 [  0   1   0   0   0   0 121   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   0   0  99   0   1   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   2   0   1   0   0   0  79   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 111   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   1   0   0   2   0   0   0   0   0   0   0  90   0   0   2   0]
 [  0   1   0   0   0   2   0   0   0   0   0   0   0   0   0   0  57   1   2   0]
 [  0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1  89   5   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   1   1   0   0   0   2  98   0]
 [  0   0   0   0   1   4   0   0   0   0   3   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:43:00,414 - ==> Best [Top1: 94.744   Top5: 99.065   Params: 306880 on epoch: 254]
2025-04-28 02:43:00,414 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:43:00,425 - 

2025-04-28 02:43:00,426 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:43:32,885 - Epoch: [255][   90/   90]    Overall Loss 0.018760    Objective Loss 0.018760    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.360625    
2025-04-28 02:43:32,917 - --- validate (epoch=255)-----------
2025-04-28 02:43:32,917 - 2245 samples (100 per mini-batch)
2025-04-28 02:43:37,559 - Epoch: [255][   23/   23]    Loss 0.263390    Top1 94.610245    Top5 98.886414    
2025-04-28 02:43:37,582 - ==> Top1: 94.610    Top5: 98.886    Loss: 0.263

2025-04-28 02:43:37,583 - ==> Confusion:
[[100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 112   1   1   0   0   0   2   0   0   0   0   0   0   0   0   3   0   1   0]
 [  0   0  98   0   2   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   0   0   0   0   1   0   2   0   0   0   0   5   0]
 [  0   0   0   0 189   0   1   0   0   0   0   0   1   0   2   0   0   0   2   3]
 [  0   0   0   0   2  76   0   0   0   0   0   0   0   0   0   1   0   2   0   7]
 [  0   0   0   0   0   0 124   0   0   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   0   0   0   0   0 100   0   1   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   2   0   0   0   0   0  80   0   1   0   0   0   0   2   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   1   0   0   0   0   0   0   0  74   0   2   0   0   1   1   0   0]
 [  1   0   0   0   0   1   0   0   0   0   0   0  80   0   1   0   0   0   0   0]
 [  0   0   0   3   0   0   0   1   0   1   1   0   0 109   0   0   0   0   0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   0   2   0  56   0   0   0   0   0]
 [  0   1   0   2   1   0   0   2   0   0   0   0   0   0   0  90   0   0   2   0]
 [  0   1   0   1   1   1   0   0   0   0   0   1   0   0   0   0  54   1   3   0]
 [  1   1   0   1   0   0   0   0   1   0   0   0   0   0   0   0   1  90   2   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   1   1   0   0   0   2  97   1]
 [  0   0   1   0   1   3   2   0   0   0   2   0   0   0   0   0   0   1   0 129]]

2025-04-28 02:43:37,585 - ==> Best [Top1: 94.744   Top5: 99.065   Params: 306880 on epoch: 254]
2025-04-28 02:43:37,585 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:43:37,593 - 

2025-04-28 02:43:37,594 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:44:10,142 - Epoch: [256][   90/   90]    Overall Loss 0.021665    Objective Loss 0.021665    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.361619    
2025-04-28 02:44:10,168 - --- validate (epoch=256)-----------
2025-04-28 02:44:10,168 - 2245 samples (100 per mini-batch)
2025-04-28 02:44:14,878 - Epoch: [256][   23/   23]    Loss 0.308230    Top1 93.719376    Top5 98.975501    
2025-04-28 02:44:14,902 - ==> Top1: 93.719    Top5: 98.976    Loss: 0.308

2025-04-28 02:44:14,903 - ==> Confusion:
[[ 97   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   1   2]
 [  0 110   1   0   1   0   0   3   0   0   0   0   0   1   0   0   3   0   1   0]
 [  0   0  97   0   3   1   0   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 133   0   0   1   2   0   0   1   3   0   3   0   0   0   0   6   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   1   0   0   1   0   0   2   2]
 [  0   0   0   0   3  76   0   0   0   0   0   0   0   0   0   1   1   2   1   4]
 [  0   0   1   0   0   0 121   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   0   0  98   1   0   1   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   2   0   0   0   0   0  77   1   1   0   0   0   0   3   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   0  73   0   1   0   1   2   2   0   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0  80   0   1   0   0   0   1   0]
 [  0   0   1   1   0   0   0   0   0   1   1   0   0 111   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   3   0  55   0   0   0   0   0]
 [  0   1   0   1   3   0   0   2   0   0   0   0   0   0   0  90   0   0   1   0]
 [  0   1   0   0   1   1   0   0   0   0   0   1   0   0   0   0  55   1   3   0]
 [  0   1   0   0   0   0   0   0   1   0   0   0   0   0   0   0   1  89   5   0]
 [  0   0   0   0   1   1   0   0   0   1   1   0   1   1   0   0   0   2  96   0]
 [  0   0   1   0   1   3   2   0   0   0   2   0   0   0   0   1   0   1   0 128]]

2025-04-28 02:44:14,905 - ==> Best [Top1: 94.744   Top5: 99.065   Params: 306880 on epoch: 254]
2025-04-28 02:44:14,905 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:44:14,913 - 

2025-04-28 02:44:14,913 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:44:47,313 - Epoch: [257][   90/   90]    Overall Loss 0.016930    Objective Loss 0.016930    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.359974    
2025-04-28 02:44:47,344 - --- validate (epoch=257)-----------
2025-04-28 02:44:47,344 - 2245 samples (100 per mini-batch)
2025-04-28 02:44:51,883 - Epoch: [257][   23/   23]    Loss 0.305615    Top1 94.075724    Top5 98.886414    
2025-04-28 02:44:51,908 - ==> Top1: 94.076    Top5: 98.886    Loss: 0.306

2025-04-28 02:44:51,909 - ==> Confusion:
[[ 95   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   1   1   3]
 [  0 111   1   0   1   0   0   2   0   0   0   0   0   1   0   1   2   0   1   0]
 [  0   0  96   0   3   0   2   0   1   0   0   0   0   0   1   0   0   0   0   0]
 [  0   0   0 137   1   0   1   0   0   0   0   2   0   3   0   0   0   0   5   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   0   0   0   0   2   2]
 [  0   0   0   0   3  74   0   0   0   0   0   0   1   0   0   1   1   2   0   6]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   1   0  97   0   1   1   0   0   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   2   0   1   0   0   0  78   0   1   0   0   0   0   2   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   0  74   0   1   0   0   2   2   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   1   0   0]
 [  0   0   0   0   0   0   0   1   0   3   0   0   0 109   0   0   0   0   1   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   0   0   0   0   0   0   0  92   0   0   1   0]
 [  0   1   0   0   1   1   0   0   0   0   0   0   0   0   0   0  56   1   3   0]
 [  0   1   0   0   0   0   0   0   1   0   0   0   0   0   0   0   1  90   4   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   2  97   0]
 [  0   0   0   0   1   4   0   0   0   0   3   0   0   0   0   0   0   1   1 129]]

2025-04-28 02:44:51,911 - ==> Best [Top1: 94.744   Top5: 99.065   Params: 306880 on epoch: 254]
2025-04-28 02:44:51,911 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:44:51,918 - 

2025-04-28 02:44:51,918 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:45:24,542 - Epoch: [258][   90/   90]    Overall Loss 0.015613    Objective Loss 0.015613    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.362464    
2025-04-28 02:45:24,570 - --- validate (epoch=258)-----------
2025-04-28 02:45:24,570 - 2245 samples (100 per mini-batch)
2025-04-28 02:45:28,973 - Epoch: [258][   23/   23]    Loss 0.278187    Top1 94.432071    Top5 99.109131    
2025-04-28 02:45:28,997 - ==> Top1: 94.432    Top5: 99.109    Loss: 0.278

2025-04-28 02:45:28,997 - ==> Confusion:
[[ 97   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   3]
 [  0 111   1   0   0   0   0   3   0   0   0   1   0   1   0   1   2   0   0   0]
 [  0   0  97   0   1   1   3   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   0   0   0   0   3   0   2   0   0   0   0   3   0]
 [  0   1   0   0 189   0   0   0   0   0   0   0   1   0   1   1   1   0   2   2]
 [  0   0   0   0   0  77   0   0   0   0   0   0   0   0   0   1   1   1   0   8]
 [  0   0   0   0   0   0 121   0   1   0   2   0   0   0   1   0   0   0   0   3]
 [  0   0   0   0   0   0   0  99   0   1   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   1   0   1   0   0   0  80   0   2   0   0   0   0   1   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  75   0   3   0   0   1   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   3   1   0   0 110   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   1   0   0   2   0   0   0   0   0   0   0  91   0   0   1   0]
 [  0   2   0   0   0   2   0   0   0   0   0   2   0   0   0   0  55   1   1   0]
 [  1   3   0   0   0   0   0   0   1   0   1   0   0   0   0   0   1  89   1   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   1   2  95   1]
 [  0   0   0   0   1   5   2   0   0   0   1   0   0   0   0   0   0   0   0 130]]

2025-04-28 02:45:28,999 - ==> Best [Top1: 94.744   Top5: 99.065   Params: 306880 on epoch: 254]
2025-04-28 02:45:29,000 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:45:29,006 - 

2025-04-28 02:45:29,006 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:46:01,617 - Epoch: [259][   90/   90]    Overall Loss 0.015740    Objective Loss 0.015740    Top1 98.561151    Top5 100.000000    LR 0.000125    Time 0.362314    
2025-04-28 02:46:01,645 - --- validate (epoch=259)-----------
2025-04-28 02:46:01,645 - 2245 samples (100 per mini-batch)
2025-04-28 02:46:05,901 - Epoch: [259][   23/   23]    Loss 0.297082    Top1 94.075724    Top5 99.109131    
2025-04-28 02:46:05,929 - ==> Top1: 94.076    Top5: 99.109    Loss: 0.297

2025-04-28 02:46:05,929 - ==> Confusion:
[[ 96   0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   3]
 [  0 111   1   0   0   0   0   2   0   0   0   0   0   1   0   0   3   0   1   1]
 [  0   0  99   0   2   1   0   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   1   0   0   0   0   2   0   3   0   0   0   0   3   0]
 [  0   0   0   0 190   1   0   0   0   0   0   0   1   0   1   1   0   0   2   2]
 [  0   0   0   0   0  79   0   0   0   0   0   0   0   0   0   1   1   1   0   6]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   1   0   1   0  95   0   1   2   1   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   1   0   2   0   0   0  76   1   2   0   0   0   0   3   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  0   1   0   0   0   1   1   0   0   0   0  74   0   1   0   0   2   1   0   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   1   1   0   1   0   0   0   1   2   1   0 108   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   3   0   0   1   0   0   0   0   0   0   0  90   0   0   1   0]
 [  0   1   0   0   1   2   0   0   0   0   0   1   0   0   0   0  56   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   3   0   0   0   0   0   1  89   2   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   1   0   0   3  94   1]
 [  0   0   0   0   1   5   1   0   0   0   2   0   0   0   0   0   0   0   0 130]]

2025-04-28 02:46:05,931 - ==> Best [Top1: 94.744   Top5: 99.065   Params: 306880 on epoch: 254]
2025-04-28 02:46:05,931 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:46:05,938 - 

2025-04-28 02:46:05,938 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:46:38,704 - Epoch: [260][   90/   90]    Overall Loss 0.017029    Objective Loss 0.017029    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.364029    
2025-04-28 02:46:38,743 - --- validate (epoch=260)-----------
2025-04-28 02:46:38,743 - 2245 samples (100 per mini-batch)
2025-04-28 02:46:43,262 - Epoch: [260][   23/   23]    Loss 0.296330    Top1 94.342984    Top5 98.975501    
2025-04-28 02:46:43,284 - ==> Top1: 94.343    Top5: 98.976    Loss: 0.296

2025-04-28 02:46:43,285 - ==> Confusion:
[[100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 111   1   0   0   0   0   3   0   0   0   1   0   0   0   0   2   0   1   1]
 [  0   0  97   0   2   0   3   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 137   0   0   0   0   0   0   0   2   0   3   0   0   0   0   7   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   1   0   1   0   0   0   2   2]
 [  0   0   0   0   1  77   0   0   0   0   0   0   0   0   0   1   1   2   0   6]
 [  1   0   0   0   0   0 121   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   0   0  99   0   0   1   0   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   1   0   1   0  74   1   1   0   0   0   0   3   0   1   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  76   0   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   1   0   1   0   1   0   1   0   0   1   1   0 109   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   4   0   0   2   0   0   0   0   0   0   0  88   0   0   1   0]
 [  0   1   0   0   0   3   0   0   0   0   0   0   0   0   0   0  55   1   3   0]
 [  1   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0  92   2   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   3  96   0]
 [  0   0   0   0   1   4   1   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:46:43,287 - ==> Best [Top1: 94.744   Top5: 99.065   Params: 306880 on epoch: 254]
2025-04-28 02:46:43,287 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:46:43,295 - 

2025-04-28 02:46:43,295 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:47:15,862 - Epoch: [261][   90/   90]    Overall Loss 0.027464    Objective Loss 0.027464    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.361826    
2025-04-28 02:47:15,901 - --- validate (epoch=261)-----------
2025-04-28 02:47:15,901 - 2245 samples (100 per mini-batch)
2025-04-28 02:47:20,365 - Epoch: [261][   23/   23]    Loss 0.290567    Top1 94.298441    Top5 98.797327    
2025-04-28 02:47:20,396 - ==> Top1: 94.298    Top5: 98.797    Loss: 0.291

2025-04-28 02:47:20,396 - ==> Confusion:
[[ 98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   3]
 [  0 113   1   0   0   0   0   2   0   0   0   1   0   1   0   0   2   0   0   0]
 [  0   0  98   0   2   1   2   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 142   0   0   0   0   0   0   0   1   0   5   0   0   0   0   1   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   0   1   0   1   0   0   1   2]
 [  0   0   0   0   3  75   0   0   0   0   0   0   0   0   0   1   1   2   0   6]
 [  0   0   0   0   0   0 120   0   0   0   1   1   0   0   2   0   0   0   0   4]
 [  0   1   0   3   0   0   0  95   0   0   1   0   0   1   0   1   0   0   0   0]
 [  0   0   1   0   0   0   0   0 214   0   0   0   0   0   0   0   0   0   1   0]
 [  1   0   0   6   0   0   0   0   0  75   1   1   0   1   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  75   0   3   0   0   1   1   0   0]
 [  1   0   0   0   2   0   0   0   0   0   0   0  78   0   1   0   0   1   0   0]
 [  0   0   0   2   0   0   0   0   0   0   0   0   0 113   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   2   0  56   0   0   0   0   0]
 [  0   1   0   2   3   0   0   2   0   0   0   0   0   0   0  90   0   0   0   0]
 [  0   1   0   0   2   2   0   0   0   0   0   1   0   0   0   0  55   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1  90   3   0]
 [  0   1   0   1   2   0   0   0   0   1   0   0   0   2   0   0   0   3  94   0]
 [  0   0   0   0   1   2   0   0   0   0   3   0   0   0   0   0   0   0   0 133]]

2025-04-28 02:47:20,399 - ==> Best [Top1: 94.744   Top5: 99.065   Params: 306880 on epoch: 254]
2025-04-28 02:47:20,399 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:47:20,409 - 

2025-04-28 02:47:20,410 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:47:52,899 - Epoch: [262][   90/   90]    Overall Loss 0.028865    Objective Loss 0.028865    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.360964    
2025-04-28 02:47:52,932 - --- validate (epoch=262)-----------
2025-04-28 02:47:52,932 - 2245 samples (100 per mini-batch)
2025-04-28 02:47:57,410 - Epoch: [262][   23/   23]    Loss 0.300755    Top1 94.476615    Top5 99.020045    
2025-04-28 02:47:57,434 - ==> Top1: 94.477    Top5: 99.020    Loss: 0.301

2025-04-28 02:47:57,435 - ==> Confusion:
[[ 95   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   1   4]
 [  0 114   0   0   0   0   0   2   0   0   0   0   0   0   0   0   2   0   1   1]
 [  0   0  94   0   1   1   3   0   1   0   2   0   0   0   0   0   0   0   0   1]
 [  0   0   0 138   0   0   0   0   0   0   0   2   0   5   0   0   1   0   3   0]
 [  0   0   0   0 191   0   0   0   0   0   0   0   1   0   2   0   0   0   2   2]
 [  0   0   0   0   0  76   0   1   0   0   0   0   0   0   0   1   1   2   0   7]
 [  0   0   0   0   0   0 117   0   1   0   2   1   0   0   1   0   0   0   0   6]
 [  0   0   0   0   0   0   0  98   0   0   1   0   0   0   0   2   0   1   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   1   0   0   0   0   0  79   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  75   0   3   0   0   1   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   0   1   0   0 113   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   2   0   1   2   0   0   2   0   0   0   1   0   0   0  90   0   0   0   0]
 [  0   1   0   0   0   1   0   0   0   0   0   2   0   0   0   0  57   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1  92   1   1]
 [  0   1   0   0   0   0   0   0   0   1   1   0   2   1   0   0   0   2  96   0]
 [  0   0   0   0   1   2   1   0   0   0   2   0   0   0   0   0   0   0   0 133]]

2025-04-28 02:47:57,437 - ==> Best [Top1: 94.744   Top5: 99.065   Params: 306880 on epoch: 254]
2025-04-28 02:47:57,437 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:47:57,444 - 

2025-04-28 02:47:57,444 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:48:29,849 - Epoch: [263][   90/   90]    Overall Loss 0.035923    Objective Loss 0.035923    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.360025    
2025-04-28 02:48:29,877 - --- validate (epoch=263)-----------
2025-04-28 02:48:29,878 - 2245 samples (100 per mini-batch)
2025-04-28 02:48:34,426 - Epoch: [263][   23/   23]    Loss 0.274882    Top1 94.209354    Top5 99.064588    
2025-04-28 02:48:34,446 - ==> Top1: 94.209    Top5: 99.065    Loss: 0.275

2025-04-28 02:48:34,447 - ==> Confusion:
[[ 96   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2   1   3]
 [  0 110   2   0   0   0   0   2   0   1   0   2   0   1   0   0   2   0   0   0]
 [  0   0  96   0   3   0   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 137   0   0   0   0   0   0   0   4   0   5   0   0   1   0   2   0]
 [  0   0   1   0 193   0   0   0   0   0   0   0   1   0   0   1   0   0   2   0]
 [  0   0   0   0   2  77   1   0   0   0   0   0   0   0   0   1   1   2   0   4]
 [  0   0   0   0   1   0 122   0   1   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   0   1   0   0   0  98   0   0   1   0   0   0   0   1   0   1   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   2   0   0   0   0   0  77   1   3   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   1   0   0   0   0   1   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  77   0   1   0   0   2   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   2   0   0   0   0   0   1   0   2   0 108   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   0   1   0   0   2   1   0   0   1   0   0   0  92   0   0   0   0]
 [  0   1   0   0   0   1   0   0   0   0   0   2   0   0   0   0  56   1   2   0]
 [  1   2   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1  90   2   0]
 [  0   1   0   0   1   0   0   0   0   1   0   0   1   2   0   0   1   2  94   1]
 [  0   0   0   0   2   2   2   0   0   0   2   0   0   0   0   1   1   1   0 128]]

2025-04-28 02:48:34,449 - ==> Best [Top1: 94.744   Top5: 99.065   Params: 306880 on epoch: 254]
2025-04-28 02:48:34,449 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:48:34,457 - 

2025-04-28 02:48:34,457 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:49:07,047 - Epoch: [264][   90/   90]    Overall Loss 0.041892    Objective Loss 0.041892    Top1 97.841727    Top5 100.000000    LR 0.000125    Time 0.362084    
2025-04-28 02:49:07,074 - --- validate (epoch=264)-----------
2025-04-28 02:49:07,074 - 2245 samples (100 per mini-batch)
2025-04-28 02:49:11,596 - Epoch: [264][   23/   23]    Loss 0.303689    Top1 93.674833    Top5 98.752784    
2025-04-28 02:49:11,620 - ==> Top1: 93.675    Top5: 98.753    Loss: 0.304

2025-04-28 02:49:11,620 - ==> Confusion:
[[ 97   0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   1   0   2]
 [  0 109   1   0   0   0   1   3   0   0   0   1   0   1   0   0   2   0   1   1]
 [  0   0  97   0   1   0   4   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   1   0   0   0   0   2   0   2   0   0   1   0   3   0]
 [  0   0   1   0 190   2   0   0   0   0   0   0   1   0   1   1   0   0   1   1]
 [  0   0   0   0   2  78   1   0   0   0   0   0   0   0   0   1   1   2   0   3]
 [  0   0   0   0   0   0 123   0   1   0   2   0   0   0   0   0   0   0   0   2]
 [  0   0   0   0   0   0   0  97   0   1   2   0   0   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   1   0   0   0   0   0]
 [  0   0   0   2   0   2   0   0   0  76   1   1   0   0   0   0   3   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   2   0   0   0   0   0   0   0   0   0  74   0   1   0   1   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  77   0   5   0   0   0   1   0]
 [  0   0   1   2   0   0   0   0   0   1   0   1   0 108   0   1   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   2   3   0   0   2   0   0   0   0   0   0   0  89   0   0   1   0]
 [  0   1   0   1   1   2   0   0   0   0   0   1   0   0   0   0  54   1   2   0]
 [  1   1   0   0   0   0   0   0   1   0   1   0   0   0   0   0   1  90   2   0]
 [  0   0   0   1   1   1   0   0   0   1   1   0   1   1   1   0   0   1  94   1]
 [  0   0   1   0   1   3   4   0   0   0   2   0   0   0   0   0   0   0   0 128]]

2025-04-28 02:49:11,622 - ==> Best [Top1: 94.744   Top5: 99.065   Params: 306880 on epoch: 254]
2025-04-28 02:49:11,622 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:49:11,631 - 

2025-04-28 02:49:11,631 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:49:44,250 - Epoch: [265][   90/   90]    Overall Loss 0.022460    Objective Loss 0.022460    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.362403    
2025-04-28 02:49:44,276 - --- validate (epoch=265)-----------
2025-04-28 02:49:44,276 - 2245 samples (100 per mini-batch)
2025-04-28 02:49:48,982 - Epoch: [265][   23/   23]    Loss 0.272932    Top1 94.877506    Top5 98.841871    
2025-04-28 02:49:49,008 - ==> Top1: 94.878    Top5: 98.842    Loss: 0.273

2025-04-28 02:49:49,008 - ==> Confusion:
[[ 97   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   3]
 [  0 110   1   0   0   0   1   3   0   0   0   0   0   1   0   1   2   0   1   0]
 [  0   0  97   0   1   0   4   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   1   0   0   0   3   0   2   0   0   0   0   2   0]
 [  0   0   0   0 191   0   0   0   0   0   0   0   1   0   0   2   0   0   2   2]
 [  0   0   0   0   3  72   1   1   0   1   0   0   0   0   1   1   1   2   1   4]
 [  0   0   0   0   1   0 125   0   0   0   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0  98   0   1   1   0   0   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   2   0   0   0   0   0  80   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   1   0   0   0  75   0   1   0   0   2   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   3   0   0   0 110   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   2   1   0   0   1   0   0   0   0   0   0   0  92   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0   1   0   0   0   0  58   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0  92   3   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   1   1   0   0   0   2  97   1]
 [  0   0   0   0   0   3   2   0   0   0   3   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:49:49,011 - ==> Best [Top1: 94.878   Top5: 98.842   Params: 306880 on epoch: 265]
2025-04-28 02:49:49,011 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:49:49,022 - 

2025-04-28 02:49:49,022 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:50:21,567 - Epoch: [266][   90/   90]    Overall Loss 0.016965    Objective Loss 0.016965    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.361578    
2025-04-28 02:50:21,592 - --- validate (epoch=266)-----------
2025-04-28 02:50:21,593 - 2245 samples (100 per mini-batch)
2025-04-28 02:50:26,297 - Epoch: [266][   23/   23]    Loss 0.291021    Top1 94.298441    Top5 98.886414    
2025-04-28 02:50:26,318 - ==> Top1: 94.298    Top5: 98.886    Loss: 0.291

2025-04-28 02:50:26,318 - ==> Confusion:
[[ 96   0   0   1   0   0   1   0   1   0   0   0   0   0   0   0   0   0   1   2]
 [  0 110   1   0   0   0   0   2   0   0   0   1   0   1   0   0   3   0   1   1]
 [  0   0  96   0   2   1   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 138   0   0   0   0   0   0   0   2   0   5   0   0   0   0   4   0]
 [  0   0   0   0 189   0   0   0   0   0   1   0   1   1   1   1   0   0   2   2]
 [  0   0   0   0   1  76   0   0   0   0   0   0   0   0   0   1   1   2   0   7]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   0   0  99   0   1   2   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   1   0   0   0   0   0  81   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   0   1   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   1   1   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  56   0   0   0   1   0]
 [  0   1   0   2   4   0   0   2   0   0   0   0   0   1   0  87   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0   2   0   0   0   0  56   1   2   0]
 [  0   2   0   0   0   0   0   0   0   0   3   0   0   0   0   0   0  89   3   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   1   2   0   0   0   2  96   1]
 [  0   0   0   0   1   2   2   0   0   0   3   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:50:26,321 - ==> Best [Top1: 94.878   Top5: 98.842   Params: 306880 on epoch: 265]
2025-04-28 02:50:26,321 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:50:26,329 - 

2025-04-28 02:50:26,330 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:50:59,552 - Epoch: [267][   90/   90]    Overall Loss 0.016661    Objective Loss 0.016661    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.369107    
2025-04-28 02:50:59,585 - --- validate (epoch=267)-----------
2025-04-28 02:50:59,585 - 2245 samples (100 per mini-batch)
2025-04-28 02:51:04,175 - Epoch: [267][   23/   23]    Loss 0.279829    Top1 94.565702    Top5 99.020045    
2025-04-28 02:51:04,196 - ==> Top1: 94.566    Top5: 99.020    Loss: 0.280

2025-04-28 02:51:04,196 - ==> Confusion:
[[100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 111   1   0   0   0   0   2   0   0   0   0   0   1   0   0   3   0   1   1]
 [  0   0  97   0   1   1   3   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 138   0   0   0   0   0   0   0   2   0   5   0   0   0   0   4   0]
 [  0   0   0   0 191   0   0   0   0   0   0   0   1   0   1   0   0   0   2   3]
 [  0   0   0   0   2  77   0   0   0   0   0   0   0   0   0   1   1   1   0   6]
 [  1   0   0   0   0   0 120   0   1   0   2   0   0   0   1   0   0   0   0   3]
 [  0   0   0   1   0   1   0  97   0   1   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   2   0   2   0   0   0  79   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   0   0   0   0 113   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   3   0   0   1   0   0   0   0   0   1   0  88   0   0   2   0]
 [  0   1   0   0   0   2   0   0   0   0   0   1   0   0   0   0  56   1   2   0]
 [  1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1  91   3   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   1   1   0   0   1   2  96   1]
 [  0   0   0   0   1   3   2   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:51:04,199 - ==> Best [Top1: 94.878   Top5: 98.842   Params: 306880 on epoch: 265]
2025-04-28 02:51:04,199 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:51:04,206 - 

2025-04-28 02:51:04,206 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:51:37,027 - Epoch: [268][   90/   90]    Overall Loss 0.012957    Objective Loss 0.012957    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.364645    
2025-04-28 02:51:37,057 - --- validate (epoch=268)-----------
2025-04-28 02:51:37,058 - 2245 samples (100 per mini-batch)
2025-04-28 02:51:41,698 - Epoch: [268][   23/   23]    Loss 0.269104    Top1 94.743875    Top5 99.020045    
2025-04-28 02:51:41,730 - ==> Top1: 94.744    Top5: 99.020    Loss: 0.269

2025-04-28 02:51:41,731 - ==> Confusion:
[[100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 109   0   1   1   0   0   3   0   0   0   1   0   1   0   0   3   0   1   0]
 [  0   0  96   0   2   1   3   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 142   0   0   0   0   0   0   0   2   0   3   0   0   0   0   2   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   1   0   1   0   0   0   2   2]
 [  0   0   0   1   3  75   0   0   0   0   0   0   0   0   0   1   1   2   0   5]
 [  0   0   0   0   0   0 121   0   1   0   2   0   0   0   1   0   0   0   0   3]
 [  0   0   0   3   0   1   0  96   0   0   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   1   0   0   0  78   0   1   0   0   0   0   1   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  2   1   0   0   0   0   0   0   0   0   0  75   0   2   0   0   1   0   0   0]
 [  1   0   0   0   0   1   0   0   0   0   0   0  80   0   1   0   0   0   0   0]
 [  0   0   0   3   0   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   2   0   0   1   0   0   0   1   0   0   0  91   0   0   0   0]
 [  0   1   0   1   1   1   0   0   0   0   0   2   0   0   0   0  55   1   1   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  95   1   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   2  96   1]
 [  0   0   0   0   1   3   2   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:51:41,733 - ==> Best [Top1: 94.878   Top5: 98.842   Params: 306880 on epoch: 265]
2025-04-28 02:51:41,733 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:51:41,739 - 

2025-04-28 02:51:41,740 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:52:14,262 - Epoch: [269][   90/   90]    Overall Loss 0.018625    Objective Loss 0.018625    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.361337    
2025-04-28 02:52:14,294 - --- validate (epoch=269)-----------
2025-04-28 02:52:14,294 - 2245 samples (100 per mini-batch)
2025-04-28 02:52:18,809 - Epoch: [269][   23/   23]    Loss 0.279268    Top1 94.432071    Top5 99.064588    
2025-04-28 02:52:18,834 - ==> Top1: 94.432    Top5: 99.065    Loss: 0.279

2025-04-28 02:52:18,834 - ==> Confusion:
[[100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 110   1   0   1   0   0   2   0   0   0   1   0   1   0   0   3   0   1   0]
 [  0   0  96   0   2   1   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 139   0   0   0   0   0   0   0   3   0   3   0   0   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   0   0   0   0   2   2]
 [  0   0   0   0   3  76   1   0   0   0   0   0   0   0   0   1   1   1   0   5]
 [  0   0   0   0   1   0 121   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   1   0   0   0  97   0   0   1   0   0   0   0   2   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   3   0   0   0   0   0  77   0   1   0   0   0   0   3   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   0   1   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0  80   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   0   1   0   0 113   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   2   2   0   0   1   0   0   0   0   0   0   0  91   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0   2   0   0   0   0  55   2   2   0]
 [  0   1   0   0   0   0   0   0   1   0   0   0   0   0   0   0   1  89   5   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   3  96   0]
 [  1   0   0   0   1   3   2   0   1   0   2   0   0   0   0   1   0   0   0 128]]

2025-04-28 02:52:18,836 - ==> Best [Top1: 94.878   Top5: 98.842   Params: 306880 on epoch: 265]
2025-04-28 02:52:18,836 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:52:18,843 - 

2025-04-28 02:52:18,843 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:52:51,558 - Epoch: [270][   90/   90]    Overall Loss 0.016496    Objective Loss 0.016496    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.363466    
2025-04-28 02:52:51,585 - --- validate (epoch=270)-----------
2025-04-28 02:52:51,586 - 2245 samples (100 per mini-batch)
2025-04-28 02:52:56,157 - Epoch: [270][   23/   23]    Loss 0.278113    Top1 94.476615    Top5 99.109131    
2025-04-28 02:52:56,181 - ==> Top1: 94.477    Top5: 99.109    Loss: 0.278

2025-04-28 02:52:56,181 - ==> Confusion:
[[ 99   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   2]
 [  0 111   1   0   1   0   0   2   0   0   0   1   0   0   0   0   3   0   1   0]
 [  0   0  97   0   2   1   2   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 137   0   0   0   1   0   0   0   6   0   1   0   0   0   0   4   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   1   0   1   0   0   0   2   2]
 [  0   0   0   0   3  75   0   0   0   0   0   0   1   0   0   1   1   1   0   6]
 [  1   0   0   0   0   0 121   0   0   0   2   0   0   0   1   0   0   0   0   3]
 [  0   0   0   0   0   0   0 100   0   1   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 214   0   0   0   0   0   1   0   0   0   0   0]
 [  1   1   0   1   0   1   0   1   0  77   0   2   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  76   0   0   0   0   2   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   2   1   0   0   1   0   0   0   1   0 108   0   0   2   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   0   3   0   0   1   0   0   0   1   0   0   0  91   0   0   1   0]
 [  0   1   0   0   0   2   0   0   0   0   0   2   0   0   0   0  55   1   2   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1  93   2   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   2  96   1]
 [  0   0   0   0   1   3   2   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:52:56,184 - ==> Best [Top1: 94.878   Top5: 98.842   Params: 306880 on epoch: 265]
2025-04-28 02:52:56,184 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:52:56,193 - 

2025-04-28 02:52:56,193 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:53:28,994 - Epoch: [271][   90/   90]    Overall Loss 0.017368    Objective Loss 0.017368    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.364425    
2025-04-28 02:53:29,026 - --- validate (epoch=271)-----------
2025-04-28 02:53:29,026 - 2245 samples (100 per mini-batch)
2025-04-28 02:53:33,610 - Epoch: [271][   23/   23]    Loss 0.268426    Top1 95.011136    Top5 98.975501    
2025-04-28 02:53:33,634 - ==> Top1: 95.011    Top5: 98.976    Loss: 0.268

2025-04-28 02:53:33,635 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   2]
 [  0 113   1   0   1   0   0   2   0   0   0   0   0   0   0   0   2   0   1   0]
 [  0   0  97   0   2   1   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   0   0   0   0   1   0   3   0   0   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   2   1]
 [  0   0   0   0   2  77   0   0   0   0   0   1   0   0   0   1   1   2   0   4]
 [  0   0   0   0   1   0 122   0   1   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   0   0   0   1   0  99   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   0   0   0   0  80   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   2   0   0   1   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   1   1   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   4   0   0   1   0   0   0   0   0   0   0  89   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0   1   0   0   0   0  58   1   1   0]
 [  1   2   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1  91   0   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   3  96   0]
 [  0   0   0   0   1   4   1   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 02:53:33,637 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 02:53:33,637 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:53:33,647 - 

2025-04-28 02:53:33,647 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:54:06,538 - Epoch: [272][   90/   90]    Overall Loss 0.026742    Objective Loss 0.026742    Top1 97.841727    Top5 100.000000    LR 0.000125    Time 0.365421    
2025-04-28 02:54:06,568 - --- validate (epoch=272)-----------
2025-04-28 02:54:06,568 - 2245 samples (100 per mini-batch)
2025-04-28 02:54:11,094 - Epoch: [272][   23/   23]    Loss 0.318562    Top1 94.253898    Top5 99.064588    
2025-04-28 02:54:11,119 - ==> Top1: 94.254    Top5: 99.065    Loss: 0.319

2025-04-28 02:54:11,119 - ==> Confusion:
[[100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 111   1   0   0   0   0   2   0   0   0   0   0   1   0   0   3   0   1   1]
 [  0   0  96   0   1   1   2   0   1   0   0   0   0   0   0   0   0   1   0   1]
 [  0   0   0 135   1   0   0   0   0   0   0   2   0   2   0   0   1   0   6   2]
 [  0   0   0   0 192   0   0   0   0   0   0   0   1   0   1   0   0   0   2   2]
 [  0   0   0   0   2  74   0   0   0   0   0   0   1   0   0   1   1   2   0   7]
 [  1   0   0   0   0   0 120   0   1   0   2   0   0   0   0   0   0   0   0   4]
 [  1   0   0   0   0   1   0  97   0   1   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   1   0   1   0   0   0  77   0   1   0   0   0   0   4   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 107   0   0   0   0   0   1   4   0   1]
 [  2   1   0   0   0   0   0   0   0   0   0  74   0   0   0   0   2   2   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   0   0   0   0 109   0   0   2   0   0   3]
 [  0   0   1   0   0   0   0   0   0   0   0   0   3   0  55   0   0   0   0   0]
 [  0   1   0   1   5   0   0   1   0   0   0   0   0   0   0  89   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0   0   0   0   0   0  59   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  93   2   0]
 [  1   0   0   0   0   1   0   0   0   0   0   0   1   1   0   0   0   2  97   1]
 [  0   0   0   0   1   1   1   0   0   0   1   0   0   0   0   0   0   0   0 135]]

2025-04-28 02:54:11,121 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 02:54:11,121 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:54:11,130 - 

2025-04-28 02:54:11,130 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:54:43,837 - Epoch: [273][   90/   90]    Overall Loss 0.027725    Objective Loss 0.027725    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.363389    
2025-04-28 02:54:43,864 - --- validate (epoch=273)-----------
2025-04-28 02:54:43,865 - 2245 samples (100 per mini-batch)
2025-04-28 02:54:48,383 - Epoch: [273][   23/   23]    Loss 0.295567    Top1 94.342984    Top5 98.752784    
2025-04-28 02:54:48,405 - ==> Top1: 94.343    Top5: 98.753    Loss: 0.296

2025-04-28 02:54:48,406 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   1   0   1]
 [  0 107   2   0   0   0   0   4   0   0   0   3   0   1   0   0   2   0   1   0]
 [  0   0  96   0   3   0   2   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   1   0   0   0   2   0   2   0   0   0   0   3   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   0   0   1   2   0   0   1   0]
 [  1   0   0   1   2  74   0   1   0   1   0   1   0   0   0   1   0   2   0   4]
 [  0   0   0   0   1   0 123   0   0   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   0   1   0   0   0 100   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   6   0   0   0   1   0  76   0   1   0   0   0   0   0   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  76   0   2   0   0   0   0   1   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   3   0   0   0   0   0   0   1   0   0 111   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   0   0   0   2   0   0   0   0   0   0   0  92   0   0   1   0]
 [  0   2   0   1   1   1   0   0   0   0   0   1   0   0   0   1  53   1   2   0]
 [  1   1   0   1   0   0   0   0   0   0   3   0   0   0   0   0   1  88   2   0]
 [  1   0   0   0   2   1   0   0   0   1   0   0   0   2   0   0   0   2  95   0]
 [  1   0   0   0   1   2   2   0   0   0   2   0   0   0   0   1   0   0   0 130]]

2025-04-28 02:54:48,408 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 02:54:48,408 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:54:48,416 - 

2025-04-28 02:54:48,416 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:55:21,257 - Epoch: [274][   90/   90]    Overall Loss 0.016484    Objective Loss 0.016484    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.364874    
2025-04-28 02:55:21,291 - --- validate (epoch=274)-----------
2025-04-28 02:55:21,292 - 2245 samples (100 per mini-batch)
2025-04-28 02:55:26,030 - Epoch: [274][   23/   23]    Loss 0.273688    Top1 94.521158    Top5 99.109131    
2025-04-28 02:55:26,056 - ==> Top1: 94.521    Top5: 99.109    Loss: 0.274

2025-04-28 02:55:26,057 - ==> Confusion:
[[ 97   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0   3]
 [  0 113   2   0   0   0   0   2   0   0   0   0   0   0   0   0   3   0   0   0]
 [  0   0  99   0   1   0   2   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 138   0   1   1   1   0   0   0   2   0   2   0   0   0   0   4   0]
 [  0   1   0   0 189   0   0   0   0   0   0   0   2   0   1   1   0   0   2   2]
 [  0   0   0   0   2  77   0   0   0   0   0   0   0   0   0   1   1   2   0   5]
 [  0   1   1   0   0   0 122   0   0   0   1   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   1   0  97   0   0   1   0   0   0   0   2   0   1   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   3   0   1   0   0   0  77   0   1   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 109   0   0   0   0   0   1   3   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  75   0   3   0   0   1   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   1   2   0   0   0   0   0   0   0   0   0 111   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   1   0   0   2   0   0   0   0   0   0   0  93   0   0   0   0]
 [  0   1   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   2   0]
 [  0   2   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1  91   2   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   2   0   0   0   2  95   1]
 [  0   0   0   0   1   4   2   0   0   0   2   0   0   0   0   0   0   0   0 130]]

2025-04-28 02:55:26,059 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 02:55:26,059 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:55:26,066 - 

2025-04-28 02:55:26,067 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:55:58,893 - Epoch: [275][   90/   90]    Overall Loss 0.030948    Objective Loss 0.030948    Top1 98.561151    Top5 100.000000    LR 0.000125    Time 0.364703    
2025-04-28 02:55:58,921 - --- validate (epoch=275)-----------
2025-04-28 02:55:58,921 - 2245 samples (100 per mini-batch)
2025-04-28 02:56:03,597 - Epoch: [275][   23/   23]    Loss 0.300927    Top1 93.942094    Top5 98.886414    
2025-04-28 02:56:03,625 - ==> Top1: 93.942    Top5: 98.886    Loss: 0.301

2025-04-28 02:56:03,626 - ==> Confusion:
[[ 97   0   0   0   0   0   0   0   1   0   1   0   0   0   0   0   0   1   0   2]
 [  0 109   0   0   0   0   0   3   0   0   0   0   0   1   0   0   5   0   1   1]
 [  0   0  92   0   1   1   1   0   3   0   2   0   0   0   2   0   0   0   0   1]
 [  0   0   0 136   0   0   1   1   0   0   1   2   0   2   0   0   1   0   4   1]
 [  0   0   0   0 192   0   0   0   0   0   0   0   0   0   1   1   0   0   2   2]
 [  0   0   0   0   2  75   0   0   0   0   0   0   0   0   0   1   1   2   0   7]
 [  1   0   0   0   0   0 118   0   1   0   2   0   0   0   1   1   0   0   0   4]
 [  0   0   0   0   0   1   0  97   0   1   1   0   0   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0  81   0   1   0   0   0   0   2   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   0   0   2   0  73   0   1   0   0   2   1   0   0]
 [  1   0   0   0   1   0   0   0   0   0   0   0  79   0   2   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   5   1   0   0 108   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   1   0  58   0   0   0   0   0]
 [  0   1   0   1   1   0   0   1   0   0   0   0   0   0   0  93   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0   1   0   0   0   0  58   1   1   0]
 [  0   1   0   0   0   0   0   0   0   0   3   0   0   0   0   1   0  89   3   0]
 [  0   0   0   0   2   1   0   0   0   1   1   0   0   1   1   0   0   1  95   1]
 [  0   0   0   0   2   1   0   0   0   0   3   0   0   0   0   0   0   0   0 133]]

2025-04-28 02:56:03,628 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 02:56:03,628 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:56:03,636 - 

2025-04-28 02:56:03,636 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:56:36,229 - Epoch: [276][   90/   90]    Overall Loss 0.043675    Objective Loss 0.043675    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.362112    
2025-04-28 02:56:36,261 - --- validate (epoch=276)-----------
2025-04-28 02:56:36,261 - 2245 samples (100 per mini-batch)
2025-04-28 02:56:40,849 - Epoch: [276][   23/   23]    Loss 0.307614    Top1 93.763920    Top5 98.841871    
2025-04-28 02:56:40,870 - ==> Top1: 93.764    Top5: 98.842    Loss: 0.308

2025-04-28 02:56:40,871 - ==> Confusion:
[[ 91   0   0   2   0   1   1   1   1   1   0   0   0   0   0   0   0   0   1   3]
 [  0 110   0   1   1   0   0   2   0   0   0   1   0   1   0   0   3   0   1   0]
 [  0   0  94   0   2   1   2   0   4   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 145   0   0   0   0   0   0   0   1   0   2   0   0   0   0   1   0]
 [  0   0   0   0 191   0   0   0   0   1   0   0   0   0   1   1   0   0   2   2]
 [  0   0   0   0   1  79   0   0   0   0   0   0   0   0   0   1   1   2   0   4]
 [  0   0   0   1   0   0 116   0   1   0   2   0   0   0   1   0   1   0   1   5]
 [  0   0   0   2   0   0   0  96   0   1   1   1   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   5   0   0   0   0   0  78   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  0   1   0   1   0   0   0   0   0   0   0  75   0   2   0   0   2   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   2   0   0   0 110   0   0   1   0   0   1]
 [  0   0   0   0   1   0   0   0   0   0   0   0   2   0  56   0   0   0   0   0]
 [  0   1   0   2   2   0   0   2   0   0   0   0   0   0   0  91   0   0   0   0]
 [  0   0   0   0   0   1   0   0   0   1   0   2   0   0   0   0  56   1   2   0]
 [  0   1   0   2   0   0   0   0   1   0   1   0   0   0   0   0   3  85   4   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   1   3   0   0   0   2  95   1]
 [  0   1   0   1   2   2   0   0   0   0   3   0   0   0   0   0   0   0   1 129]]

2025-04-28 02:56:40,873 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 02:56:40,873 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:56:40,880 - 

2025-04-28 02:56:40,880 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:57:13,415 - Epoch: [277][   90/   90]    Overall Loss 0.028647    Objective Loss 0.028647    Top1 98.561151    Top5 100.000000    LR 0.000125    Time 0.361469    
2025-04-28 02:57:13,447 - --- validate (epoch=277)-----------
2025-04-28 02:57:13,448 - 2245 samples (100 per mini-batch)
2025-04-28 02:57:17,977 - Epoch: [277][   23/   23]    Loss 0.324347    Top1 94.031180    Top5 98.797327    
2025-04-28 02:57:17,998 - ==> Top1: 94.031    Top5: 98.797    Loss: 0.324

2025-04-28 02:57:17,999 - ==> Confusion:
[[ 99   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   2]
 [  0 109   0   1   1   0   0   3   0   0   0   2   0   1   0   0   2   0   1   0]
 [  0   0  96   0   3   0   2   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   1   1   0   0   0   2   0   1   0   0   0   0   3   0]
 [  1   0   0   0 193   0   0   1   0   0   0   0   0   0   0   0   0   0   1   2]
 [  1   0   0   0   3  75   0   0   0   0   0   0   0   0   0   1   0   2   1   5]
 [  0   0   0   0   1   0 122   0   1   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   0   0   0   1   0  98   0   1   1   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   2   0   2   0   2   0  76   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   0   1   0]
 [  0   0   1   0   3   0   0   0   0   0   0   0  78   0   0   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   0   0   0   0 112   0   0   0   0   1   1]
 [  0   0   1   0   4   0   0   0   0   0   0   0   2   0  52   0   0   0   0   0]
 [  0   1   0   1   4   0   0   2   0   0   0   0   0   0   0  89   0   0   1   0]
 [  0   1   0   0   2   1   0   0   0   0   0   2   0   0   0   0  54   1   2   0]
 [  1   1   0   0   0   0   0   0   1   0   2   0   0   0   0   0   1  89   2   0]
 [  1   0   0   0   2   1   0   0   0   0   1   0   0   2   0   0   0   1  96   0]
 [  0   0   1   0   2   2   1   0   1   0   3   0   0   0   0   0   0   0   0 129]]

2025-04-28 02:57:18,001 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 02:57:18,001 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:57:18,008 - 

2025-04-28 02:57:18,008 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:57:50,547 - Epoch: [278][   90/   90]    Overall Loss 0.019937    Objective Loss 0.019937    Top1 98.561151    Top5 100.000000    LR 0.000125    Time 0.361516    
2025-04-28 02:57:50,574 - --- validate (epoch=278)-----------
2025-04-28 02:57:50,574 - 2245 samples (100 per mini-batch)
2025-04-28 02:57:55,186 - Epoch: [278][   23/   23]    Loss 0.272093    Top1 94.788419    Top5 98.930958    
2025-04-28 02:57:55,212 - ==> Top1: 94.788    Top5: 98.931    Loss: 0.272

2025-04-28 02:57:55,213 - ==> Confusion:
[[ 97   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   3]
 [  0 112   0   1   0   0   0   2   0   0   0   0   0   0   0   1   3   0   1   0]
 [  0   0  95   0   1   2   3   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 142   0   0   0   0   0   0   0   2   0   2   0   0   0   0   3   0]
 [  0   0   0   0 190   1   0   0   0   1   0   0   0   0   1   1   1   0   1   2]
 [  0   0   0   0   0  79   0   0   0   0   0   1   0   0   0   1   1   2   0   4]
 [  0   0   0   1   1   0 120   0   1   0   2   1   0   0   1   0   0   0   0   1]
 [  0   0   0   2   0   0   0  98   0   0   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   3   0   0   0   0   0  78   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   2   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  77   0   1   0   0   2   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   3   0   0   0   0   0   1   1   0   0 110   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   1   0   0   0   0   2   0  56   0   0   0   0   0]
 [  0   1   0   2   1   0   0   1   0   0   0   0   0   0   0  93   0   0   0   0]
 [  0   1   0   0   0   1   0   0   0   0   0   1   0   0   0   0  58   1   1   0]
 [  1   1   0   1   0   0   0   0   0   0   2   0   0   0   0   0   1  90   1   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   1   1   0   1   0   2  96   1]
 [  0   0   0   0   0   5   2   0   0   0   2   0   0   0   0   0   0   0   0 130]]

2025-04-28 02:57:55,215 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 02:57:55,215 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:57:55,224 - 

2025-04-28 02:57:55,224 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:58:27,759 - Epoch: [279][   90/   90]    Overall Loss 0.020066    Objective Loss 0.020066    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.361475    
2025-04-28 02:58:27,789 - --- validate (epoch=279)-----------
2025-04-28 02:58:27,790 - 2245 samples (100 per mini-batch)
2025-04-28 02:58:32,464 - Epoch: [279][   23/   23]    Loss 0.304782    Top1 94.120267    Top5 98.841871    
2025-04-28 02:58:32,490 - ==> Top1: 94.120    Top5: 98.842    Loss: 0.305

2025-04-28 02:58:32,491 - ==> Confusion:
[[ 98   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1   0   1   1]
 [  0 111   1   0   1   0   0   3   0   0   0   1   0   0   0   0   2   0   1   0]
 [  0   0  96   0   3   0   2   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 136   1   0   1   2   0   0   0   2   0   2   0   0   0   0   5   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   7  71   0   1   0   1   0   0   0   0   0   0   1   2   1   4]
 [  0   0   0   0   1   0 123   0   1   0   2   0   0   0   1   0   0   0   0   0]
 [  0   0   0   0   0   0   0 100   0   1   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0   3   0   0   0   0   0  80   0   1   0   0   0   0   1   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   2   0   0   1   0   1   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0  79   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   2   1   0   0 111   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   2   0  56   0   0   0   0   0]
 [  0   1   0   1   4   0   0   1   0   0   0   0   0   0   0  90   0   0   1   0]
 [  0   1   0   0   3   0   0   0   0   0   0   2   0   0   0   0  54   1   2   0]
 [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1  92   3   0]
 [  1   0   0   0   2   1   0   0   0   1   0   0   0   1   0   0   0   2  96   0]
 [  1   0   0   0   4   1   2   0   0   0   4   0   0   0   1   0   0   0   1 125]]

2025-04-28 02:58:32,493 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 02:58:32,493 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:58:32,500 - 

2025-04-28 02:58:32,500 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:59:04,902 - Epoch: [280][   90/   90]    Overall Loss 0.021330    Objective Loss 0.021330    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.359988    
2025-04-28 02:59:04,928 - --- validate (epoch=280)-----------
2025-04-28 02:59:04,928 - 2245 samples (100 per mini-batch)
2025-04-28 02:59:09,578 - Epoch: [280][   23/   23]    Loss 0.293937    Top1 94.432071    Top5 98.886414    
2025-04-28 02:59:09,600 - ==> Top1: 94.432    Top5: 98.886    Loss: 0.294

2025-04-28 02:59:09,601 - ==> Confusion:
[[ 97   0   0   0   1   2   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 108   2   0   0   1   0   2   0   0   0   2   0   1   0   1   3   0   0   0]
 [  0   0  95   0   3   0   2   0   1   0   1   0   0   0   0   0   0   0   0   1]
 [  0   0   0 142   0   0   0   0   0   0   0   2   0   2   0   0   0   0   3   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   1   2]
 [  0   0   0   0   1  80   0   0   0   0   0   0   0   0   0   1   1   0   0   5]
 [  0   0   1   0   1   0 120   0   1   0   0   0   0   0   2   0   0   0   0   3]
 [  0   0   0   1   0   1   0  97   1   0   1   0   0   0   0   1   0   0   0   0]
 [  0   0   1   0   0   0   1   0 214   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   4   0   2   0   0   1  76   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   1   0   0   0   0   0  75   0   2   0   0   1   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  80   0   2   0   0   0   0   0]
 [  0   0   0   2   0   0   0   0   0   0   0   0   0 112   0   0   1   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   2   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   0   0   0   0   0   0   0  92   0   0   1   0]
 [  0   1   0   1   1   2   0   0   0   0   0   1   0   0   0   0  54   1   2   0]
 [  1   1   0   1   0   1   0   0   0   0   0   0   0   0   0   1   0  90   2   0]
 [  1   0   0   0   3   1   0   0   0   0   0   0   0   1   0   0   0   2  95   1]
 [  0   0   0   0   1   3   1   0   0   0   1   0   0   0   0   0   0   0   0 133]]

2025-04-28 02:59:09,603 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 02:59:09,603 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:59:09,610 - 

2025-04-28 02:59:09,610 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 02:59:42,068 - Epoch: [281][   90/   90]    Overall Loss 0.014683    Objective Loss 0.014683    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.360616    
2025-04-28 02:59:42,095 - --- validate (epoch=281)-----------
2025-04-28 02:59:42,096 - 2245 samples (100 per mini-batch)
2025-04-28 02:59:46,670 - Epoch: [281][   23/   23]    Loss 0.275886    Top1 94.610245    Top5 98.975501    
2025-04-28 02:59:46,690 - ==> Top1: 94.610    Top5: 98.976    Loss: 0.276

2025-04-28 02:59:46,691 - ==> Confusion:
[[ 98   0   0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   1   0   2]
 [  0 110   1   0   1   0   0   3   0   0   0   0   0   1   0   0   3   0   1   0]
 [  0   0  97   0   3   0   1   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   1   0 138   0   0   0   0   0   0   0   3   0   3   0   0   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   1   2]
 [  0   0   0   0   3  76   0   1   0   0   0   0   0   0   0   0   1   1   0   6]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   1   0   0   0 100   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   5   0   0   0   1   0  78   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   2   0   0   1   1   0   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0  80   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   0   1   0   0 113   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   2   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   2   1   0   0   0   0   0   0  90   0   0   1   0]
 [  0   1   0   0   2   1   0   0   0   0   0   2   0   0   0   0  54   1   2   0]
 [  0   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1  91   4   0]
 [  0   0   1   0   1   1   0   0   0   1   0   0   0   1   0   0   0   2  96   1]
 [  0   0   0   0   2   2   2   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 02:59:46,693 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 02:59:46,693 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 02:59:46,700 - 

2025-04-28 02:59:46,700 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:00:19,618 - Epoch: [282][   90/   90]    Overall Loss 0.013661    Objective Loss 0.013661    Top1 97.122302    Top5 100.000000    LR 0.000125    Time 0.365723    
2025-04-28 03:00:19,649 - --- validate (epoch=282)-----------
2025-04-28 03:00:19,649 - 2245 samples (100 per mini-batch)
2025-04-28 03:00:24,242 - Epoch: [282][   23/   23]    Loss 0.304222    Top1 94.075724    Top5 98.975501    
2025-04-28 03:00:24,264 - ==> Top1: 94.076    Top5: 98.976    Loss: 0.304

2025-04-28 03:00:24,265 - ==> Confusion:
[[ 99   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   2]
 [  0 112   1   0   1   0   0   2   0   0   0   1   0   0   0   0   2   0   1   0]
 [  0   0  98   0   3   0   1   0   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   1   0 135   1   0   0   1   0   0   1   2   0   4   0   0   1   0   3   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   1   2]
 [  0   0   0   0   3  75   0   0   0   0   0   0   0   0   0   1   1   2   0   6]
 [  0   0   1   0   0   0 119   0   1   0   2   0   0   0   1   0   0   0   0   4]
 [  0   0   0   0   0   1   0  98   0   0   1   0   0   0   0   0   0   1   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   1   0   1   0   0   0  78   0   1   0   0   0   0   3   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   1   0   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0  80   0   1   0   0   1   0   0]
 [  0   0   0   0   1   0   0   1   0   1   0   0   0 110   0   0   1   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   6   0   0   2   0   0   0   0   0   0   0  87   0   0   1   0]
 [  0   2   0   0   1   1   0   0   0   0   0   1   0   0   0   0  55   1   2   0]
 [  0   1   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1  92   1   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   2   1   0   0   0   2  95   1]
 [  0   0   0   0   2   3   2   0   0   0   2   0   0   0   0   0   0   0   0 130]]

2025-04-28 03:00:24,267 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:00:24,267 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:00:24,274 - 

2025-04-28 03:00:24,274 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:00:57,133 - Epoch: [283][   90/   90]    Overall Loss 0.024341    Objective Loss 0.024341    Top1 97.841727    Top5 100.000000    LR 0.000125    Time 0.365071    
2025-04-28 03:00:57,160 - --- validate (epoch=283)-----------
2025-04-28 03:00:57,160 - 2245 samples (100 per mini-batch)
2025-04-28 03:01:01,648 - Epoch: [283][   23/   23]    Loss 0.298639    Top1 93.986637    Top5 98.663697    
2025-04-28 03:01:01,680 - ==> Top1: 93.987    Top5: 98.664    Loss: 0.299

2025-04-28 03:01:01,680 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   2]
 [  0 106   1   1   0   4   0   2   1   0   0   2   0   1   0   0   2   0   0   0]
 [  0   0  90   0   4   0   3   0   6   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 144   0   0   0   0   0   0   0   1   0   2   0   0   0   0   2   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   0   0   0   0   1   2]
 [  0   0   0   0   3  78   0   0   0   0   0   0   0   0   0   1   1   0   0   5]
 [  0   0   0   0   0   0 122   0   1   0   1   0   0   0   2   0   0   0   0   2]
 [  0   0   0   1   0   1   0  96   1   0   2   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   5   0   2   0   0   0  77   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   0   1   0]
 [  0   0   0   0   3   0   0   0   0   0   0   0  78   0   1   0   0   0   1   0]
 [  0   0   0   3   0   0   0   0   0   0   0   0   0 111   0   0   1   0   0   0]
 [  0   0   1   0   1   0   0   0   0   0   0   0   2   0  55   0   0   0   0   0]
 [  0   1   0   2   3   0   0   2   0   0   0   0   0   0   0  89   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0   1   0   0   0   0  58   0   2   0]
 [  1   0   0   1   0   1   0   0   0   0   3   0   0   0   0   0   1  88   2   0]
 [  0   0   0   0   2   1   0   0   0   1   1   0   0   2   1   0   0   1  94   1]
 [  0   0   0   0   1   3   1   0   1   0   2   0   0   0   0   0   1   0   0 130]]

2025-04-28 03:01:01,682 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:01:01,682 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:01:01,691 - 

2025-04-28 03:01:01,691 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:01:35,099 - Epoch: [284][   90/   90]    Overall Loss 0.016490    Objective Loss 0.016490    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.371173    
2025-04-28 03:01:35,134 - --- validate (epoch=284)-----------
2025-04-28 03:01:35,134 - 2245 samples (100 per mini-batch)
2025-04-28 03:01:39,751 - Epoch: [284][   23/   23]    Loss 0.286742    Top1 94.432071    Top5 99.064588    
2025-04-28 03:01:39,774 - ==> Top1: 94.432    Top5: 99.065    Loss: 0.287

2025-04-28 03:01:39,775 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   2]
 [  0 110   2   0   0   0   0   2   0   0   0   2   0   1   0   0   2   0   1   0]
 [  0   0  96   0   2   0   3   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   1   0   0   0   1   3   0   2   0   0   0   0   2   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   1   2]
 [  0   0   0   0   2  73   1   0   0   0   0   0   0   0   0   1   1   1   0   9]
 [  0   0   0   0   0   0 123   0   1   0   1   0   0   0   1   0   0   0   0   2]
 [  0   0   0   1   0   1   0  97   0   1   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   2   0   1   0   0   0  77   1   2   0   0   0   0   1   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  76   0   1   0   0   2   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   0   0   0   0   1   0   1   1   1   0 110   0   0   0   0   0   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   3   0   0   1   0   0   0   0   0   0   0  91   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   2   0]
 [  1   1   0   1   0   0   0   0   1   0   2   0   0   0   0   0   1  88   2   0]
 [  1   0   0   0   1   1   0   0   0   1   0   0   2   2   0   0   0   1  95   0]
 [  0   0   1   0   1   1   2   0   0   0   1   0   0   0   0   0   1   0   0 132]]

2025-04-28 03:01:39,777 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:01:39,777 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:01:39,784 - 

2025-04-28 03:01:39,784 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:02:12,939 - Epoch: [285][   90/   90]    Overall Loss 0.015455    Objective Loss 0.015455    Top1 97.841727    Top5 100.000000    LR 0.000125    Time 0.368355    
2025-04-28 03:02:12,967 - --- validate (epoch=285)-----------
2025-04-28 03:02:12,967 - 2245 samples (100 per mini-batch)
2025-04-28 03:02:17,659 - Epoch: [285][   23/   23]    Loss 0.300058    Top1 94.432071    Top5 99.020045    
2025-04-28 03:02:17,687 - ==> Top1: 94.432    Top5: 99.020    Loss: 0.300

2025-04-28 03:02:17,688 - ==> Confusion:
[[ 98   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1   1   1]
 [  0 114   0   0   0   0   0   2   0   0   0   0   0   0   0   0   3   0   0   1]
 [  0   0  96   0   3   0   1   0   2   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0 139   0   0   0   0   0   0   0   2   0   5   0   0   1   0   2   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   0   2   0]
 [  0   0   0   0   5  76   0   0   0   0   0   1   0   0   0   1   1   2   0   2]
 [  0   0   0   0   1   0 117   0   1   0   4   1   1   0   1   0   0   0   0   2]
 [  0   0   0   0   0   0   0  98   0   1   1   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0 215   0   0   0   0   0   0   0   0   0   1   0]
 [  0   1   0   2   0   0   0   0   0  80   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  76   0   1   0   0   2   1   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0  80   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   1   0   0   0 112   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   1   0   0   1   0   0   0   0   0   0   0  93   0   0   1   0]
 [  0   2   0   0   1   1   0   0   0   0   0   1   0   0   0   0  56   1   1   0]
 [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1  90   4   0]
 [  0   1   0   0   1   0   0   0   0   1   0   0   2   2   0   0   0   1  95   1]
 [  0   0   0   0   4   3   0   0   1   0   4   0   1   0   0   0   0   1   1 124]]

2025-04-28 03:02:17,690 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:02:17,690 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:02:17,697 - 

2025-04-28 03:02:17,697 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:02:50,645 - Epoch: [286][   90/   90]    Overall Loss 0.025303    Objective Loss 0.025303    Top1 98.561151    Top5 100.000000    LR 0.000125    Time 0.366055    
2025-04-28 03:02:50,672 - --- validate (epoch=286)-----------
2025-04-28 03:02:50,672 - 2245 samples (100 per mini-batch)
2025-04-28 03:02:55,231 - Epoch: [286][   23/   23]    Loss 0.273603    Top1 94.654788    Top5 98.930958    
2025-04-28 03:02:55,251 - ==> Top1: 94.655    Top5: 98.931    Loss: 0.274

2025-04-28 03:02:55,252 - ==> Confusion:
[[ 97   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   1   1   2]
 [  0 113   1   0   0   0   0   2   0   0   0   1   0   0   0   0   1   0   1   1]
 [  0   0  97   0   3   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 138   0   0   0   0   0   0   0   2   0   5   0   0   0   0   4   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   1   0   1   0   0   0   2   2]
 [  0   1   0   0   2  77   0   0   0   0   0   0   0   0   0   1   1   2   0   4]
 [  0   0   1   0   0   0 120   0   1   0   2   0   0   0   1   0   0   0   0   3]
 [  0   0   0   0   0   1   0  97   0   0   1   0   0   0   0   2   0   0   1   0]
 [  0   0   1   0   0   0   1   0 213   0   0   0   0   0   0   0   0   0   1   0]
 [  0   1   0   1   0   0   0   0   0  81   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  75   0   3   0   0   1   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   1   0   0   0   0   0   1   1   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   2   0   0   1   0   0   0   0   0   0   0  93   0   0   0   0]
 [  0   1   0   0   0   2   0   0   0   0   0   1   0   0   0   0  55   1   3   0]
 [  0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   0   1  89   5   0]
 [  0   1   0   0   0   0   0   0   0   1   0   0   1   1   0   0   0   2  97   1]
 [  0   0   0   0   2   2   2   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 03:02:55,254 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:02:55,254 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:02:55,261 - 

2025-04-28 03:02:55,261 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:03:28,194 - Epoch: [287][   90/   90]    Overall Loss 0.025594    Objective Loss 0.025594    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.365898    
2025-04-28 03:03:28,228 - --- validate (epoch=287)-----------
2025-04-28 03:03:28,228 - 2245 samples (100 per mini-batch)
2025-04-28 03:03:32,996 - Epoch: [287][   23/   23]    Loss 0.266217    Top1 94.654788    Top5 99.287305    
2025-04-28 03:03:33,024 - ==> Top1: 94.655    Top5: 99.287    Loss: 0.266

2025-04-28 03:03:33,025 - ==> Confusion:
[[ 95   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   1   1   3]
 [  0 110   2   0   0   0   0   3   0   0   0   2   0   0   0   0   2   0   1   0]
 [  0   0  98   0   2   1   2   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 138   0   0   1   1   0   0   0   3   0   2   0   0   0   0   4   0]
 [  0   0   0   0 196   0   0   1   0   0   0   0   0   0   0   0   0   0   1   0]
 [  0   0   0   0   2  77   1   0   0   0   0   0   0   0   0   1   1   1   0   5]
 [  0   0   0   0   1   0 121   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   0   0   1   0  99   0   1   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   1   0   1   0   1   0  78   0   2   0   0   0   0   1   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  76   0   1   0   0   1   1   0   0]
 [  0   0   0   0   1   1   0   0   0   0   0   0  80   0   1   0   0   0   0   0]
 [  0   0   0   0   0   1   0   0   0   0   0   0   0 112   0   0   0   0   1   1]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   0   4   0   0   2   0   0   0   1   0   0   0  90   0   0   0   0]
 [  0   1   0   0   2   1   0   0   0   0   0   1   0   0   0   0  55   1   2   0]
 [  0   1   0   1   0   1   0   0   0   0   0   1   0   0   0   0   0  91   2   0]
 [  1   0   0   0   1   1   0   0   0   1   0   0   3   2   0   0   0   1  94   0]
 [  0   0   0   0   2   2   1   0   0   0   2   0   0   0   0   0   0   0   0 132]]

2025-04-28 03:03:33,027 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:03:33,027 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:03:33,034 - 

2025-04-28 03:03:33,034 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:04:06,097 - Epoch: [288][   90/   90]    Overall Loss 0.013847    Objective Loss 0.013847    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.367331    
2025-04-28 03:04:06,129 - --- validate (epoch=288)-----------
2025-04-28 03:04:06,130 - 2245 samples (100 per mini-batch)
2025-04-28 03:04:10,811 - Epoch: [288][   23/   23]    Loss 0.260919    Top1 94.253898    Top5 99.064588    
2025-04-28 03:04:10,832 - ==> Top1: 94.254    Top5: 99.065    Loss: 0.261

2025-04-28 03:04:10,833 - ==> Confusion:
[[ 95   0   0   0   1   0   1   0   0   0   0   0   0   0   0   0   0   1   1   3]
 [  0 111   1   1   0   0   0   2   0   0   0   2   0   0   0   0   2   0   1   0]
 [  0   0  97   0   2   1   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   0   0   0   0   0   3   0   2   0   0   0   0   4   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   0   0   0   0   1   2]
 [  0   0   0   0   1  76   0   0   0   0   0   0   0   0   0   1   1   2   0   7]
 [  0   0   0   0   0   0 121   0   1   0   2   0   0   0   1   0   0   0   0   3]
 [  0   0   0   1   0   1   0  96   0   1   1   1   0   0   0   0   0   0   1   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   2   0   0   0   0   0  78   0   1   0   0   0   0   3   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   1   0   0   2   0   1   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0  79   0   1   0   0   0   1   0]
 [  0   0   0   3   0   0   0   0   0   1   1   0   0 110   0   0   0   0   0   0]
 [  0   0   1   0   1   0   0   0   0   0   0   0   2   0  55   0   0   0   0   0]
 [  0   1   0   0   3   0   0   2   1   0   0   1   0   0   0  90   0   0   0   0]
 [  0   1   0   0   0   1   0   0   0   0   0   1   0   0   0   0  58   1   1   0]
 [  0   1   0   1   0   0   0   0   0   0   2   0   0   0   0   0   1  88   4   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   2   0   0   0   2  95   1]
 [  0   0   0   0   2   2   1   0   0   0   2   0   0   0   0   0   1   0   0 131]]

2025-04-28 03:04:10,835 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:04:10,835 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:04:10,842 - 

2025-04-28 03:04:10,842 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:04:43,652 - Epoch: [289][   90/   90]    Overall Loss 0.014069    Objective Loss 0.014069    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.364529    
2025-04-28 03:04:43,683 - --- validate (epoch=289)-----------
2025-04-28 03:04:43,683 - 2245 samples (100 per mini-batch)
2025-04-28 03:04:48,285 - Epoch: [289][   23/   23]    Loss 0.267872    Top1 94.699332    Top5 99.153675    
2025-04-28 03:04:48,304 - ==> Top1: 94.699    Top5: 99.154    Loss: 0.268

2025-04-28 03:04:48,305 - ==> Confusion:
[[ 99   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   0   1   1]
 [  0 113   0   1   0   0   0   2   0   0   0   0   0   0   0   0   3   0   1   0]
 [  0   0  95   0   2   1   3   0   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 142   0   0   1   0   0   0   0   2   0   1   0   0   0   0   3   0]
 [  1   0   0   0 192   0   0   0   0   0   0   0   1   0   0   0   0   0   2   2]
 [  0   0   0   0   1  78   1   0   0   0   0   1   0   0   0   1   1   2   0   3]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   2   0   1   0  95   0   0   1   1   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   5   0   0   0   0   0  77   0   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  76   0   1   0   0   2   1   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   4   0   1   0   0   0   2   1   0   0 107   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   1   1   0   0   1   0   0   0   0   0   0   0  92   0   0   2   0]
 [  0   1   0   0   0   1   0   0   0   0   0   1   0   0   0   0  57   1   2   0]
 [  1   1   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1  90   3   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   1   1   0   0   0   2  97   1]
 [  0   0   0   0   1   4   2   0   0   0   3   0   0   0   0   0   1   0   0 128]]

2025-04-28 03:04:48,307 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:04:48,307 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:04:48,314 - 

2025-04-28 03:04:48,314 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:05:21,103 - Epoch: [290][   90/   90]    Overall Loss 0.013611    Objective Loss 0.013611    Top1 97.841727    Top5 100.000000    LR 0.000125    Time 0.364287    
2025-04-28 03:05:21,129 - --- validate (epoch=290)-----------
2025-04-28 03:05:21,129 - 2245 samples (100 per mini-batch)
2025-04-28 03:05:25,692 - Epoch: [290][   23/   23]    Loss 0.283477    Top1 94.253898    Top5 99.153675    
2025-04-28 03:05:25,713 - ==> Top1: 94.254    Top5: 99.154    Loss: 0.283

2025-04-28 03:05:25,714 - ==> Confusion:
[[100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 111   1   0   1   0   0   3   0   0   0   1   0   0   0   0   2   0   1   0]
 [  0   0  98   0   3   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 142   0   0   0   0   0   0   0   2   0   2   0   0   0   0   3   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   0   0   0   1   1]
 [  0   0   0   0   3  76   0   0   0   0   0   0   0   0   0   1   1   2   0   5]
 [  0   0   1   1   0   0 119   0   1   0   2   0   0   0   1   0   0   0   0   3]
 [  0   0   0   1   0   1   0  96   1   0   2   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   4   0   1   0   0   0  76   1   1   0   0   0   0   1   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   1   0   0   0  75   0   2   0   0   1   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0  80   0   1   0   0   0   1   0]
 [  0   0   0   3   0   1   0   0   0   0   1   0   0 110   0   0   0   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   2   0  56   0   0   0   0   0]
 [  0   1   0   2   4   0   0   2   0   0   0   0   0   0   0  88   0   0   1   0]
 [  0   1   0   1   1   2   0   0   0   0   0   1   0   0   0   0  54   1   2   0]
 [  0   1   0   1   0   0   0   0   2   0   2   0   0   0   0   0   0  88   3   0]
 [  1   0   1   0   1   1   0   0   0   0   2   0   0   2   0   0   0   1  95   0]
 [  0   0   0   0   4   1   1   0   0   0   2   0   0   0   0   0   0   0   1 130]]

2025-04-28 03:05:25,716 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:05:25,716 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:05:25,723 - 

2025-04-28 03:05:25,723 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:05:58,634 - Epoch: [291][   90/   90]    Overall Loss 0.016656    Objective Loss 0.016656    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.365652    
2025-04-28 03:05:58,664 - --- validate (epoch=291)-----------
2025-04-28 03:05:58,664 - 2245 samples (100 per mini-batch)
2025-04-28 03:06:03,214 - Epoch: [291][   23/   23]    Loss 0.279593    Top1 94.432071    Top5 99.153675    
2025-04-28 03:06:03,233 - ==> Top1: 94.432    Top5: 99.154    Loss: 0.280

2025-04-28 03:06:03,234 - ==> Confusion:
[[ 94   0   1   0   1   1   1   0   0   0   0   0   0   0   0   0   0   0   1   3]
 [  0 113   2   0   0   0   0   2   0   0   0   1   0   0   0   0   1   0   1   0]
 [  0   0 100   0   2   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   0   0   0   0   0   3   0   3   0   0   0   0   3   0]
 [  0   0   1   0 193   0   0   0   0   0   0   0   1   0   0   0   0   0   2   1]
 [  0   0   0   0   1  79   1   0   0   0   0   1   0   0   0   1   1   0   0   4]
 [  0   0   1   0   1   0 122   0   1   0   1   0   0   0   1   0   0   0   0   1]
 [  0   0   1   2   0   1   0  96   0   0   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   4   0   0   0   0   0  76   1   1   0   0   0   0   2   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   1   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  77   0   2   0   0   1   0   0   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0  79   0   1   0   0   0   1   0]
 [  0   0   0   3   0   0   0   0   0   0   0   0   0 111   0   0   0   0   1   0]
 [  0   0   0   0   2   0   0   0   0   0   0   0   2   0  55   0   0   0   0   0]
 [  0   2   0   2   4   0   0   2   0   0   0   0   0   0   0  88   0   0   0   0]
 [  0   1   0   0   2   1   0   0   0   0   0   2   0   0   0   0  54   1   2   0]
 [  0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   0   1  90   4   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   2  96   1]
 [  0   0   0   0   1   4   1   0   0   0   2   0   0   0   0   0   0   0   0 131]]

2025-04-28 03:06:03,236 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:06:03,236 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:06:03,243 - 

2025-04-28 03:06:03,243 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:06:35,870 - Epoch: [292][   90/   90]    Overall Loss 0.021027    Objective Loss 0.021027    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.362492    
2025-04-28 03:06:35,903 - --- validate (epoch=292)-----------
2025-04-28 03:06:35,903 - 2245 samples (100 per mini-batch)
2025-04-28 03:06:40,639 - Epoch: [292][   23/   23]    Loss 0.272951    Top1 94.476615    Top5 99.064588    
2025-04-28 03:06:40,666 - ==> Top1: 94.477    Top5: 99.065    Loss: 0.273

2025-04-28 03:06:40,666 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   2]
 [  0 109   0   1   0   0   0   3   0   1   0   1   0   1   0   2   1   0   1   0]
 [  0   0  97   0   2   1   1   0   2   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 140   0   0   0   1   0   0   0   1   0   3   0   0   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   0   1   0   1   0   0   1   2]
 [  0   0   0   0   2  76   0   0   0   0   0   1   0   0   0   1   0   2   0   6]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   1   0   1   0  96   0   1   1   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  0   1   0   4   0   0   0   0   0  77   1   1   0   0   0   0   1   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   2   0   0   1   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   2   0   0   0   1   0   1   1   0   0 110   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   1   1   0   0   2   0   0   0   0   0   0   0  93   0   0   0   0]
 [  0   2   0   0   0   1   0   0   0   0   0   1   0   0   0   0  56   1   2   0]
 [  0   1   0   0   0   0   0   0   0   0   1   0   0   0   0   1   0  90   4   0]
 [  0   0   0   0   0   1   0   0   0   1   0   0   2   3   0   0   0   1  95   1]
 [  0   0   0   0   1   4   2   0   0   0   3   0   0   0   0   0   0   0   1 128]]

2025-04-28 03:06:40,668 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:06:40,668 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:06:40,676 - 

2025-04-28 03:06:40,676 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:07:13,707 - Epoch: [293][   90/   90]    Overall Loss 0.011326    Objective Loss 0.011326    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.366978    
2025-04-28 03:07:13,733 - --- validate (epoch=293)-----------
2025-04-28 03:07:13,733 - 2245 samples (100 per mini-batch)
2025-04-28 03:07:18,681 - Epoch: [293][   23/   23]    Loss 0.281114    Top1 94.521158    Top5 99.198218    
2025-04-28 03:07:18,708 - ==> Top1: 94.521    Top5: 99.198    Loss: 0.281

2025-04-28 03:07:18,708 - ==> Confusion:
[[ 95   0   0   1   0   0   1   0   1   0   0   0   0   0   0   0   0   0   1   3]
 [  0 112   0   3   0   0   0   2   0   0   0   1   0   0   0   0   1   0   1   0]
 [  0   0  98   0   1   1   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 144   0   0   0   0   0   0   0   2   0   1   0   0   0   0   2   0]
 [  0   0   0   0 191   1   0   0   0   0   0   0   0   1   0   1   0   0   2   2]
 [  0   0   0   0   1  79   1   0   0   0   0   0   0   0   0   1   0   2   0   4]
 [  0   0   0   0   0   0 123   0   1   0   1   0   0   0   1   0   0   0   0   2]
 [  0   0   0   3   0   1   0  96   0   0   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   5   0   0   0   0   0  77   0   1   0   1   0   0   1   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   1   0   0   0   0   0   0   0  76   0   2   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   4   0   0   0   0   0   1   1   0   0 109   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   2   1   0   0   2   0   0   0   0   0   0   0  91   0   0   1   0]
 [  0   2   0   1   0   2   0   0   0   0   0   1   0   0   0   0  54   1   2   0]
 [  0   1   0   2   0   0   0   0   0   0   2   0   0   0   0   1   0  88   3   0]
 [  0   0   1   0   0   1   0   0   0   1   0   0   0   3   0   0   0   2  95   1]
 [  0   0   0   0   1   5   2   0   0   0   2   0   0   0   0   0   0   0   0 129]]

2025-04-28 03:07:18,711 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:07:18,711 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:07:18,720 - 

2025-04-28 03:07:18,720 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:07:51,595 - Epoch: [294][   90/   90]    Overall Loss 0.020928    Objective Loss 0.020928    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.365245    
2025-04-28 03:07:51,622 - --- validate (epoch=294)-----------
2025-04-28 03:07:51,622 - 2245 samples (100 per mini-batch)
2025-04-28 03:07:56,295 - Epoch: [294][   23/   23]    Loss 0.292472    Top1 94.476615    Top5 98.930958    
2025-04-28 03:07:56,320 - ==> Top1: 94.477    Top5: 98.931    Loss: 0.292

2025-04-28 03:07:56,320 - ==> Confusion:
[[ 94   0   0   1   0   1   1   0   1   0   0   0   0   0   0   0   0   0   1   3]
 [  0 112   2   0   0   0   0   1   0   0   0   1   0   0   0   1   2   0   1   0]
 [  0   0  99   0   2   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 142   0   0   0   0   0   0   0   2   0   2   0   0   0   0   3   0]
 [  0   0   0   0 192   0   0   0   0   0   0   0   0   0   2   1   0   0   1   2]
 [  0   0   0   0   1  80   0   0   0   0   0   0   0   0   0   1   1   1   0   4]
 [  0   0   0   0   0   0 122   0   1   0   2   0   0   0   1   0   0   0   0   2]
 [  0   0   0   2   0   1   0  95   0   0   1   1   0   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   3   0   1   0   0   0  76   1   1   0   0   0   0   2   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   0   0   1   0   0   0   0   0  76   0   1   0   0   2   0   0   0]
 [  0   0   1   0   1   2   0   0   0   0   0   0  78   0   0   0   0   1   0   0]
 [  0   0   0   3   0   0   0   0   0   1   0   0   0 110   0   0   1   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   1   1   1   0   1   0   0   0   0   0   0   0  93   0   0   0   0]
 [  0   1   0   0   0   2   0   0   0   0   0   1   0   0   0   0  57   0   2   0]
 [  0   2   0   1   0   0   0   0   0   0   2   0   0   0   0   0   1  89   2   0]
 [  0   0   0   0   1   2   0   0   0   1   0   0   2   1   0   0   0   1  95   1]
 [  0   0   0   0   1   6   2   0   0   0   2   0   0   0   0   0   0   0   1 127]]

2025-04-28 03:07:56,322 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:07:56,323 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:07:56,330 - 

2025-04-28 03:07:56,330 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:08:29,274 - Epoch: [295][   90/   90]    Overall Loss 0.016393    Objective Loss 0.016393    Top1 100.000000    Top5 100.000000    LR 0.000125    Time 0.366010    
2025-04-28 03:08:29,299 - --- validate (epoch=295)-----------
2025-04-28 03:08:29,299 - 2245 samples (100 per mini-batch)
2025-04-28 03:08:33,884 - Epoch: [295][   23/   23]    Loss 0.274100    Top1 94.699332    Top5 99.153675    
2025-04-28 03:08:33,907 - ==> Top1: 94.699    Top5: 99.154    Loss: 0.274

2025-04-28 03:08:33,907 - ==> Confusion:
[[ 96   0   0   0   0   0   1   0   0   1   0   0   0   0   0   0   0   1   0   3]
 [  0 111   2   0   0   0   0   2   0   1   0   2   0   0   0   0   1   0   1   0]
 [  0   0  97   0   1   1   1   0   1   0   1   0   0   0   1   0   0   0   0   0]
 [  0   0   0 144   0   0   0   0   0   0   0   2   0   1   0   0   0   0   2   0]
 [  0   0   0   0 191   0   0   0   0   0   0   0   0   0   0   3   0   0   2   2]
 [  0   0   0   0   1  79   0   0   0   0   0   1   0   0   0   1   1   1   0   4]
 [  0   0   0   0   0   0 121   0   1   0   2   0   0   0   1   0   0   0   0   3]
 [  0   0   0   1   0   1   0  96   0   1   1   0   0   0   0   2   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   4   0   0   0   0   0  80   0   1   0   0   0   0   0   0   0   1]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  0   1   0   0   0   0   0   0   0   0   0  76   0   3   0   0   0   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   4   0   0   0   0   0   2   1   0   0 108   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   2   0  57   0   0   0   0   0]
 [  0   1   0   1   1   0   0   2   0   0   0   0   0   0   0  93   0   0   0   0]
 [  0   2   0   1   0   1   0   0   0   0   0   1   1   0   0   0  54   1   2   0]
 [  0   1   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0  91   2   1]
 [  0   0   0   0   1   1   0   0   0   1   0   0   3   2   0   0   0   1  94   1]
 [  0   0   0   0   1   3   2   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 03:08:33,909 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:08:33,910 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:08:33,918 - 

2025-04-28 03:08:33,918 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:09:07,071 - Epoch: [296][   90/   90]    Overall Loss 0.012965    Objective Loss 0.012965    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.368332    
2025-04-28 03:09:07,102 - --- validate (epoch=296)-----------
2025-04-28 03:09:07,102 - 2245 samples (100 per mini-batch)
2025-04-28 03:09:11,713 - Epoch: [296][   23/   23]    Loss 0.276808    Top1 94.476615    Top5 99.020045    
2025-04-28 03:09:11,732 - ==> Top1: 94.477    Top5: 99.020    Loss: 0.277

2025-04-28 03:09:11,733 - ==> Confusion:
[[100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 108   0   1   0   0   0   3   0   0   0   2   0   2   0   1   1   0   1   1]
 [  0   0  94   0   2   1   2   0   1   0   2   0   0   0   0   1   0   0   0   0]
 [  0   0   0 141   0   0   0   1   0   0   0   1   0   3   0   0   0   0   3   0]
 [  0   0   0   0 191   0   0   0   0   0   0   0   1   0   1   1   0   0   2   2]
 [  0   0   0   0   1  79   0   0   0   0   0   0   0   0   0   1   1   1   0   5]
 [  0   0   0   0   0   0 120   0   1   0   2   1   0   0   1   0   0   0   0   3]
 [  0   0   0   0   0   0   0  99   0   1   1   0   0   0   0   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0 216   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   4   0   1   0   0   0  78   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  2   1   0   0   0   0   0   0   0   0   0  75   0   2   0   0   1   0   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   3   0   0   0   1   0   1   1   0   0 109   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   1   0   0   0   3   0   0   0   0   0   0   0  92   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0   2   0   0   0   0  56   1   2   0]
 [  0   1   0   1   0   0   0   0   1   0   0   0   0   0   0   1   0  89   4   0]
 [  0   0   0   0   0   1   0   0   0   1   1   0   2   2   0   0   0   0  96   1]
 [  0   0   0   0   1   5   1   0   0   0   2   0   0   0   0   0   0   0   1 129]]

2025-04-28 03:09:11,735 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:09:11,735 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:09:11,743 - 

2025-04-28 03:09:11,743 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:09:44,593 - Epoch: [297][   90/   90]    Overall Loss 0.014877    Objective Loss 0.014877    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.364976    
2025-04-28 03:09:44,623 - --- validate (epoch=297)-----------
2025-04-28 03:09:44,623 - 2245 samples (100 per mini-batch)
2025-04-28 03:09:49,427 - Epoch: [297][   23/   23]    Loss 0.331081    Top1 93.496659    Top5 98.797327    
2025-04-28 03:09:49,459 - ==> Top1: 93.497    Top5: 98.797    Loss: 0.331

2025-04-28 03:09:49,460 - ==> Confusion:
[[100   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2]
 [  0 113   0   0   0   0   0   3   0   0   0   0   0   0   0   0   3   0   0   1]
 [  0   0  97   0   3   0   1   0   1   0   0   0   0   0   0   0   0   1   0   0]
 [  0   0   0 138   0   0   0   0   0   0   1   3   0   1   0   0   1   0   4   1]
 [  1   0   0   0 192   0   0   1   0   0   0   0   0   0   0   0   0   0   2   2]
 [  0   0   0   0   1  78   0   1   0   0   2   0   0   0   0   0   1   1   1   3]
 [  0   0   0   0   0   0 122   0   1   0   2   1   0   0   0   0   0   0   0   2]
 [  0   0   0   0   0   1   0  98   0   0   1   1   0   0   0   0   0   1   0   0]
 [  0   0   0   0   0   0   1   1 213   0   0   0   0   0   0   0   0   1   0   0]
 [  1   3   0   1   0   1   0   2   0  72   1   2   0   0   0   0   3   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 111   0   0   0   0   0   0   2   0   0]
 [  0   1   0   0   0   0   0   0   0   0   1  76   0   0   0   0   1   2   0   0]
 [  0   0   0   0   3   0   0   0   0   0   0   0  78   0   1   0   0   1   0   0]
 [  0   1   0   2   1   0   0   2   0   1   2   3   0 102   0   0   1   0   0   0]
 [  0   1   0   0   3   1   0   0   0   0   0   0   2   0  52   0   0   0   0   0]
 [  0   1   0   0   5   1   0   2   0   0   0   1   0   0   0  87   0   0   1   0]
 [  0   3   0   0   0   2   0   0   0   0   0   1   0   0   0   0  55   1   1   0]
 [  0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  95   0   0]
 [  1   0   0   0   2   1   0   0   0   0   1   0   1   1   0   0   0   7  90   0]
 [  0   0   0   0   1   3   2   0   0   0   2   0   0   0   0   0   0   1   0 130]]

2025-04-28 03:09:49,462 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:09:49,462 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:09:49,470 - 

2025-04-28 03:09:49,470 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:10:22,158 - Epoch: [298][   90/   90]    Overall Loss 0.031971    Objective Loss 0.031971    Top1 98.561151    Top5 100.000000    LR 0.000125    Time 0.363167    
2025-04-28 03:10:22,184 - --- validate (epoch=298)-----------
2025-04-28 03:10:22,184 - 2245 samples (100 per mini-batch)
2025-04-28 03:10:26,821 - Epoch: [298][   23/   23]    Loss 0.343506    Top1 93.273942    Top5 98.841871    
2025-04-28 03:10:26,848 - ==> Top1: 93.274    Top5: 98.842    Loss: 0.344

2025-04-28 03:10:26,849 - ==> Confusion:
[[ 93   0   0   0   1   1   1   0   0   0   0   0   0   0   1   1   0   1   2   1]
 [  0 107   0   1   0   0   0   3   0   0   0   1   0   3   0   2   1   0   2   0]
 [  0   0  97   0   4   0   1   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   0   0   0   0   1   0   3   0   0   0   0   4   0]
 [  0   0   0   0 194   0   0   0   0   0   0   0   1   0   1   1   0   0   1   0]
 [  0   0   0   0   4  73   0   0   0   0   0   1   0   0   1   1   1   2   1   4]
 [  0   0   0   0   1   0 122   0   1   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   0   0   0   1   0  97   0   1   1   0   0   0   0   1   0   0   1   0]
 [  0   0   0   0   0   0   0   0 213   0   0   0   0   0   0   0   0   0   3   0]
 [  1   0   0   2   0   2   0   1   0  78   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   1   0   0   1   1   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   3   0   0   0   0   1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   1   0]
 [  0   0   0   2   0   0   0   0   0   1   0   0   0 110   0   1   0   0   1   0]
 [  0   0   0   0   1   0   0   0   0   0   0   0   3   0  55   0   0   0   0   0]
 [  0   1   0   2   2   0   0   2   0   0   0   0   0   0   1  90   0   0   0   0]
 [  0   0   0   1   3   1   0   0   0   1   0   1   0   1   0   0  52   1   2   0]
 [  0   0   0   1   0   0   0   0   0   0   1   0   0   0   0   1   0  88   6   0]
 [  0   0   0   0   2   1   0   0   0   0   0   0   1   3   0   0   0   1  95   1]
 [  0   0   0   1   3   3   2   0   0   0   3   0   0   0   1   0   0   2   1 123]]

2025-04-28 03:10:26,851 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:10:26,851 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:10:26,858 - 

2025-04-28 03:10:26,858 - Training epoch: 8939 samples (100 per mini-batch, world size: 1)
2025-04-28 03:10:59,620 - Epoch: [299][   90/   90]    Overall Loss 0.027532    Objective Loss 0.027532    Top1 99.280576    Top5 100.000000    LR 0.000125    Time 0.363989    
2025-04-28 03:10:59,645 - --- validate (epoch=299)-----------
2025-04-28 03:10:59,645 - 2245 samples (100 per mini-batch)
2025-04-28 03:11:04,237 - Epoch: [299][   23/   23]    Loss 0.314923    Top1 94.031180    Top5 98.930958    
2025-04-28 03:11:04,264 - ==> Top1: 94.031    Top5: 98.931    Loss: 0.315

2025-04-28 03:11:04,265 - ==> Confusion:
[[ 97   0   0   0   0   0   2   0   0   0   0   1   0   0   0   0   0   1   0   1]
 [  0 112   1   0   0   0   0   1   0   0   0   2   0   1   0   1   1   0   1   0]
 [  0   0  99   0   3   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 137   1   0   1   0   0   0   0   3   0   4   0   0   0   0   3   0]
 [  0   0   0   0 196   0   0   0   0   0   0   0   1   0   0   0   0   1   0   0]
 [  0   0   1   0   1  81   1   0   0   0   1   0   0   0   0   1   1   1   0   0]
 [  0   0   0   0   1   0 124   0   1   0   1   0   0   0   0   0   0   0   0   1]
 [  0   0   0   1   0   1   0  95   0   1   1   1   0   0   0   1   0   0   1   0]
 [  0   0   1   0   0   0   1   0 214   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   1   0   1   1   0   0  79   0   2   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  76   0   1   0   0   1   1   0   0]
 [  0   0   1   0   1   1   0   0   0   0   0   0  80   0   0   0   0   0   0   0]
 [  0   0   1   0   0   1   1   0   0   1   0   0   0 110   0   0   1   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   1   0   3   0  54   0   0   0   0   0]
 [  0   2   0   0   4   0   0   1   0   0   0   1   0   0   0  90   0   0   0   0]
 [  0   2   0   0   2   1   0   0   0   0   0   1   0   0   0   0  55   1   1   0]
 [  0   2   0   0   0   0   0   0   1   0   3   0   0   0   0   1   0  90   0   0]
 [  0   0   1   0   2   1   0   0   0   0   2   0   0   3   0   0   0   2  93   0]
 [  0   0   3   0   7   3   3   0   0   1   3   0   0   0   0   0   1   1   0 117]]

2025-04-28 03:11:04,267 - ==> Best [Top1: 95.011   Top5: 98.976   Params: 306880 on epoch: 271]
2025-04-28 03:11:04,267 - Saving checkpoint to: logs/2025.04.28-004559/qat_checkpoint.pth.tar
2025-04-28 03:11:04,275 - --- test (ckpt) ---------------------
2025-04-28 03:11:04,275 - 2245 samples (100 per mini-batch)
2025-04-28 03:11:08,832 - Test: [   23/   23]    Loss 0.315622    Top1 94.031180    Top5 98.930958    
2025-04-28 03:11:08,852 - ==> Top1: 94.031    Top5: 98.931    Loss: 0.316

2025-04-28 03:11:08,853 - ==> Confusion:
[[ 97   0   0   0   0   0   2   0   0   0   0   1   0   0   0   0   0   1   0   1]
 [  0 112   1   0   0   0   0   1   0   0   0   2   0   1   0   1   1   0   1   0]
 [  0   0  99   0   3   0   1   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 137   1   0   1   0   0   0   0   3   0   4   0   0   0   0   3   0]
 [  0   0   0   0 196   0   0   0   0   0   0   0   1   0   0   0   0   1   0   0]
 [  0   0   1   0   1  81   1   0   0   0   1   0   0   0   0   1   1   1   0   0]
 [  0   0   0   0   1   0 124   0   1   0   1   0   0   0   0   0   0   0   0   1]
 [  0   0   0   1   0   1   0  95   0   1   1   1   0   0   0   1   0   0   1   0]
 [  0   0   1   0   0   0   1   0 214   0   0   0   0   0   0   0   0   0   0   0]
 [  1   0   0   1   0   1   1   0   0  79   0   2   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 112   0   0   0   0   0   0   1   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  76   0   1   0   0   1   1   0   0]
 [  0   0   1   0   1   1   0   0   0   0   0   0  80   0   0   0   0   0   0   0]
 [  0   0   1   0   0   1   1   0   0   1   0   0   0 110   0   0   1   0   0   0]
 [  0   0   0   0   1   0   0   0   0   0   1   0   3   0  54   0   0   0   0   0]
 [  0   2   0   0   4   0   0   1   0   0   0   1   0   0   0  90   0   0   0   0]
 [  0   2   0   0   2   1   0   0   0   0   0   1   0   0   0   0  55   1   1   0]
 [  0   2   0   0   0   0   0   0   1   0   3   0   0   0   0   1   0  90   0   0]
 [  0   0   1   0   2   1   0   0   0   0   2   0   0   3   0   0   0   2  93   0]
 [  0   0   3   0   7   3   3   0   0   1   3   0   0   0   0   0   1   1   0 117]]

2025-04-28 03:11:08,853 - --- test (best) ---------------------
2025-04-28 03:11:08,853 - => loading checkpoint logs/2025.04.28-004559/qat_best.pth.tar
2025-04-28 03:11:08,858 - => Checkpoint contents:
+----------------------+-------------+-----------------+
| Key                  | Type        | Value           |
|----------------------+-------------+-----------------|
| arch                 | str         | ai85nasfunnynet |
| compression_sched    | dict        |                 |
| epoch                | int         | 271             |
| extras               | dict        |                 |
| optimizer_state_dict | dict        |                 |
| optimizer_type       | type        | Adam            |
| state_dict           | OrderedDict |                 |
+----------------------+-------------+-----------------+

2025-04-28 03:11:08,858 - => Checkpoint['extras'] contents:
+--------------+--------+----------+
| Key          | Type   |    Value |
|--------------+--------+----------|
| best_epoch   | int    | 271      |
| best_mAP     | int    |   0      |
| best_top1    | float  |  95.0111 |
| current_mAP  | int    |   0      |
| current_top1 | float  |  95.0111 |
+--------------+--------+----------+

2025-04-28 03:11:08,859 - Loaded compression schedule from checkpoint (epoch 271)
2025-04-28 03:11:08,861 - => loaded 'state_dict' from checkpoint 'logs/2025.04.28-004559/qat_best.pth.tar'
2025-04-28 03:11:08,862 - 2245 samples (100 per mini-batch)
2025-04-28 03:11:13,467 - Test: [   23/   23]    Loss 0.260171    Top1 95.011136    Top5 98.975501    
2025-04-28 03:11:13,489 - ==> Top1: 95.011    Top5: 98.976    Loss: 0.260

2025-04-28 03:11:13,490 - ==> Confusion:
[[ 98   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   2]
 [  0 113   1   0   1   0   0   2   0   0   0   0   0   0   0   0   2   0   1   0]
 [  0   0  97   0   2   1   2   0   1   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0 141   0   0   0   0   0   0   0   1   0   3   0   0   0   0   4   0]
 [  0   0   0   0 193   0   0   0   0   0   0   0   1   0   1   0   0   0   2   1]
 [  0   0   0   0   2  77   0   0   0   0   0   1   0   0   0   1   1   2   0   4]
 [  0   0   0   0   1   0 122   0   1   0   2   0   0   0   1   0   0   0   0   1]
 [  0   0   0   0   0   1   0  99   1   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   1   0 215   0   0   0   0   0   0   0   0   0   0   0]
 [  1   1   0   2   0   0   0   0   0  80   0   1   0   0   0   0   1   0   0   0]
 [  0   1   0   0   0   0   0   0   0   0 110   0   0   0   0   0   1   2   0   0]
 [  1   1   0   0   0   0   0   0   0   0   0  75   0   2   0   0   1   1   0   0]
 [  1   0   0   0   0   0   0   0   0   0   0   0  81   0   1   0   0   0   0   0]
 [  0   0   0   1   0   0   0   0   0   1   1   0   0 112   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3   0  56   0   0   0   0   0]
 [  0   1   0   2   4   0   0   1   0   0   0   0   0   0   0  89   0   0   1   0]
 [  0   1   0   0   0   1   0   0   0   0   0   1   0   0   0   0  58   1   1   0]
 [  1   2   0   0   0   0   0   0   0   0   2   0   0   0   0   0   1  91   0   0]
 [  0   0   0   0   1   1   0   0   0   1   0   0   1   1   0   0   0   3  96   0]
 [  0   0   0   0   1   4   1   0   0   0   3   0   0   0   0   0   0   0   0 130]]

2025-04-28 03:11:13,493 - 
2025-04-28 03:11:13,493 - Log file for this run: /home/lutet/78k/ai8x-training/logs/2025.04.28-004559/2025.04.28-004559.log
