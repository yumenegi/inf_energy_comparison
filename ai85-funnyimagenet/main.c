/*******************************************************************************
* Copyright (C) 2019-2024 Maxim Integrated Products, Inc., All rights Reserved.
*
* This software is protected by copyright laws of the United States and
* of foreign countries. This material may also be protected by patent laws
* and technology transfer regulations of the United States and of foreign
* countries. This software is furnished under a license agreement and/or a
* nondisclosure agreement and may only be used or reproduced in accordance
* with the terms of those agreements. Dissemination of this information to
* any party or parties not specified in the license agreement and/or
* nondisclosure agreement is expressly prohibited.
*
* The above copyright notice and this permission notice shall be included
* in all copies or substantial portions of the Software.
*
* THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS
* OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
* MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.
* IN NO EVENT SHALL MAXIM INTEGRATED BE LIABLE FOR ANY CLAIM, DAMAGES
* OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE,
* ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR
* OTHER DEALINGS IN THE SOFTWARE.
*
* Except as contained in this notice, the name of Maxim Integrated
* Products, Inc. shall not be used except as stated in the Maxim Integrated
* Products, Inc. Branding Policy.
*
* The mere transfer of this software does not imply any licenses
* of trade secrets, proprietary technology, copyrights, patents,
* trademarks, maskwork rights, or any other form of intellectual
* property whatsoever. Maxim Integrated Products, Inc. retains all
* ownership rights.
*******************************************************************************/

// ai85-funnyimagenet
// This file was @generated by ai8xize.py --verbose --test-dir demos --prefix ai85-funnyimagenet --checkpoint-file trained/ai85-funnyimagenet-qat8-q.pth.tar --config-file networks/funnyimagenet-nas.yaml --device MAX78000 --compact-data --softmax --fifo --overwrite

#include <stdlib.h>
#include <stdint.h>
#include <string.h>
#include <stdio.h>
#include "mxc.h"
#include "camera.h"
#include "cnn.h"
#include "sampledata.h"
#include "sampleoutput.h"

volatile uint32_t cnn_time; // Stopwatch

#define IMAGE_XRES 80
#define IMAGE_YRES 80
#define CAMERA_FREQ (10 * 1000 * 1000)
#define CON_BAUD 115200 
#define CNN_INFERENCE_TIMER

void fail(void)
{
  printf("\n*** FAIL ***\n\n");
  while (1);
}

// Data input: HWC 3x80x80 (19200 bytes total / 6400 bytes per channel):
static uint32_t input_0[] = SAMPLE_INPUT_0;
void* input_0_ptr = input_0;
void load_input(void)
{
  // This function loads the sample data input -- replace with actual data

  int i;
  const uint32_t *in0 = input_0;

  for (i = 0; i < 6400; i++) {
    // Remove the following line if there is no risk that the source would overrun the FIFO:
    while (((*((volatile uint32_t *) 0x50000004) & 1)) != 0); // Wait for FIFO 0
    *((volatile uint32_t *) 0x50000008) = *in0++; // Write FIFO 0
  }
}

// Expected output of layer 10 for ai85-funnyimagenet given the sample input (known-answer test)
// Delete this function for production code
static const uint32_t sample_output[] = SAMPLE_OUTPUT;
int check_output(void)
{
  int i;
  uint32_t mask, len;
  volatile uint32_t *addr;
  const uint32_t *ptr = sample_output;

  while ((addr = (volatile uint32_t *) *ptr++) != 0) {
    mask = *ptr++;
    len = *ptr++;
    for (i = 0; i < len; i++)
      if ((*addr++ & mask) != *ptr++) {
        printf("Data mismatch (%d/%d) at address 0x%08x: Expected 0x%08x, read 0x%08x.\n",
               i + 1, len, addr - 1, *(ptr - 1), *(addr - 1) & mask);
        return CNN_FAIL;
      }
  }

  return CNN_OK;
}

// Classification layer:
static int32_t ml_data[CNN_NUM_OUTPUTS];
static q15_t ml_softmax[CNN_NUM_OUTPUTS];

void softmax_layer(void)
{
  cnn_unload((uint32_t *) ml_data);
  softmax_q17p14_q15((const q31_t *) ml_data, CNN_NUM_OUTPUTS, ml_softmax);
}

void print_image(void){
  uint8_t* ptr = input_0_ptr;
  printf("\n\nimage:\n");
  for (int i = 0; i < 25600; i++) {
    if (i % 80 == 0) printf("\n");
    printf("%c", ((*ptr) >> 2) + 33);
    ptr += 1;
  }
  printf("\nend image");
}

void capture_image(void){
  uint8_t *raw;
  uint32_t imgLen;
  uint32_t w, h;

  // Get the details of the image from the camera driver.
  camera_get_image(&raw, &imgLen, &w, &h);
    
  // write 80x80 subimage into data
  uint8_t* ptr = raw;
  for (int i =0 ; i < imgLen; i+=4) {
    int pix1 = (i / 2) + 1;
    int pix2 = (i / 2);
    int x1 = pix1 % 80;
    int y1 = pix1 / 80;
    int x2 = pix2 % 80;
    int y2 = pix2 / 80;
    
    uint16_t data1 = ((*ptr << 8)) | *(ptr+1);
    uint16_t data2 = ((*(ptr+2) << 8) | *(ptr+3));

    uint8_t r1 = ((data1 >> 11) & 0b11111) << 3;
    uint8_t g1 = ((data1 >> 5) & 0b111111) << 2;
    uint8_t b1 = (data1 & 0b11111) << 3;

    uint8_t r2 = ((data1 >> 11) & 0b11111) << 3;
    uint8_t g2 = ((data2 >> 5) & 0b111111) << 2;
    uint8_t b2 = (data2 & 0b11111) << 3;
    uint8_t* p = input_0_ptr;

    int8_t ir1 = (int8_t) r1 - 127;

    *(p + 4 * (80 * y1 + x1)) = r1;
    *(p + 4 * (80 * y1 + x1) + 1) = g1;
    *(p + 4 * (80 * y1 + x1) + 2) = b1;

    *(p + 4 * (80 * y2 + x2)) = r2;
    *(p + 4 * (80 * y2 + x2) + 1) = g2;
    *(p + 4 * (80 * y2 + x2) + 2) = b2;

    ptr += 4;
  }
}

int main(void)
{
  int i;
  int digs, tens;
  int dma_channel;
  int slaveAddress;
  int ret;
  int id;

  MXC_ICC_Enable(MXC_ICC0); // Enable cache

  // Switch to 100 MHz clock
  MXC_SYS_Clock_Select(MXC_SYS_CLOCK_IPO);
  SystemCoreClockUpdate();

  // Initialize DMA for camera interface
  MXC_DMA_Init();
  dma_channel = MXC_DMA_AcquireChannel();

  camera_init(CAMERA_FREQ);

  slaveAddress = camera_get_slave_address();
  printf("Camera I2C slave address: %02x\n", slaveAddress);

  // Obtain product ID of the camera.
  ret = camera_get_product_id(&id);

  if (ret != 0) {
      printf("Error returned from reading camera id. Error %d\n", ret);
      return -1;
  }

  printf("Camera ID detected: %04x\n", id);

  ret = camera_setup(IMAGE_XRES, IMAGE_YRES, PIXFORMAT_RGB565, FIFO_FOUR_BYTE, USE_DMA,
    dma_channel); // RGB565

  if (ret != STATUS_OK) {
      printf("Error returned from setting up camera. Error %d\n", ret);
      return -1;
  }

  MXC_Delay(SEC(1));

  printf("Waiting...\n");

  // DO NOT DELETE THIS LINE:
  MXC_Delay(SEC(2)); // Let debugger interrupt if needed

  // Enable peripheral, enable CNN interrupt, turn on CNN clock
  // CNN clock: APB (50 MHz) div 1
  cnn_enable(MXC_S_GCR_PCLKDIV_CNNCLKSEL_PCLK, MXC_S_GCR_PCLKDIV_CNNCLKDIV_DIV1);

  printf("\n*** CNN Inference Test ai85-funnyimagenet ***\n");

  camera_start_capture_image();
  while (!camera_is_image_rcv());
  printf("Image Received!\n");
  capture_image();
  print_image();

  cnn_init(); // Bring state machine into consistent state
  cnn_load_weights(); // Load kernels
  cnn_load_bias();
  cnn_configure(); // Configure state machine
  cnn_start(); // Start CNN processing
  load_input(); // Load data input via FIFO

  while (cnn_time == 0)
    MXC_LP_EnterSleepMode(); // Wait for CNN

  //if (check_output() != CNN_OK) fail();
  softmax_layer();

  printf("\n*** PASS ***\n\n");

#ifdef CNN_INFERENCE_TIMER
  printf("Approximate data loading and inference time: %u us\n\n", cnn_time);
#endif

  cnn_disable(); // Shut down CNN clock, disable peripheral

  printf("Classification results:\n");
  for (i = 0; i < CNN_NUM_OUTPUTS; i++) {
    digs = (1000 * ml_softmax[i] + 0x4000) >> 15;
    tens = digs % 10;
    digs = digs / 10;
    printf("[%7d] -> Class %d: %d.%d%%\n", ml_data[i], i, digs, tens);
  }

  return 0;
}

/*
  SUMMARY OF OPS
  Hardware: 92,191,936 ops (91,006,976 macc; 1,184,960 comp; 0 add; 0 mul; 0 bitwise)
    Layer 0: 11,468,800 ops (11,059,200 macc; 409,600 comp; 0 add; 0 mul; 0 bitwise)
    Layer 1: 29,952,000 ops (29,491,200 macc; 460,800 comp; 0 add; 0 mul; 0 bitwise)
    Layer 2: 29,593,600 ops (29,491,200 macc; 102,400 comp; 0 add; 0 mul; 0 bitwise)
    Layer 3: 7,488,000 ops (7,372,800 macc; 115,200 comp; 0 add; 0 mul; 0 bitwise)
    Layer 4: 844,800 ops (819,200 macc; 25,600 comp; 0 add; 0 mul; 0 bitwise)
    Layer 5: 7,411,200 ops (7,372,800 macc; 38,400 comp; 0 add; 0 mul; 0 bitwise)
    Layer 6: 1,651,200 ops (1,638,400 macc; 12,800 comp; 0 add; 0 mul; 0 bitwise)
    Layer 7: 1,857,600 ops (1,843,200 macc; 14,400 comp; 0 add; 0 mul; 0 bitwise)
    Layer 8: 1,846,400 ops (1,843,200 macc; 3,200 comp; 0 add; 0 mul; 0 bitwise)
    Layer 9: 68,096 ops (65,536 macc; 2,560 comp; 0 add; 0 mul; 0 bitwise)
    Layer 10: 10,240 ops (10,240 macc; 0 comp; 0 add; 0 mul; 0 bitwise)

  RESOURCE USAGE
  Weight memory: 323,264 bytes out of 442,368 bytes total (73.1%)
  Bias memory:   853 bytes out of 2,048 bytes total (41.7%)
*/

